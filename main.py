import streamlit as st
import requests
import gspread
import json
import re
import streamlit.components.v1 as components
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials
import openai
import numpy as np

from openai import OpenAI

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

def gerar_embedding_openai(texto: str):
    try:
        resposta = client.embeddings.create(
            input=texto,
            model="text-embedding-3-small"
        )
        return np.array(resposta.data[0].embedding)
    except Exception as e:
        st.error(f"Erro ao gerar embedding: {e}")
        return None


def cosine_similarity(v1: np.ndarray, v2: np.ndarray) -> float:
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

def verificar_quebra_semantica_openai(texto1: str, texto2: str, limite=0.6) -> str:
    emb1 = gerar_embedding_openai(texto1)
    emb2 = gerar_embedding_openai(texto2)
    if emb1 is None or emb2 is None:
        return ""
    sim = cosine_similarity(emb1, emb2)
    if sim < limite:
        return f"‚ö†Ô∏è Baixa continuidade narrativa (similaridade: {sim:.2f}) ‚Äî pode haver salto de cena sem transi√ß√£o."
    return f"‚úÖ Continuidade coerente (similaridade: {sim:.2f})."


# üëá Estado inicial das sess√µes vem aqui
if 'mostrar_imagem' not in st.session_state:
    st.session_state.mostrar_imagem = None
if 'mostrar_video' not in st.session_state:
    st.session_state.mostrar_video = None
if 'ultima_entrada_recebida' not in st.session_state:
    st.session_state.ultima_entrada_recebida = None

if "memorias_usadas" not in st.session_state:
    st.session_state.memorias_usadas = set()



# --------------------------- #
# Configura√ß√£o b√°sica
# --------------------------- #
st.set_page_config(page_title="Mary", page_icon="üåπ")
OPENROUTER_API_KEY = st.secrets["OPENROUTER_API_KEY"]
OPENROUTER_ENDPOINT = "https://openrouter.ai/api/v1/chat/completions"
TOGETHER_API_KEY = st.secrets["TOGETHER_API_KEY"]
TOGETHER_ENDPOINT = "https://api.together.xyz/v1/chat/completions"

# --------------------------- #
# Imagem / v√≠deo din√¢mico
# --------------------------- #
def imagem_de_fundo():
    indice = len(st.session_state.get("mensagens", [])) // 10 + 1
    return f"Mary_fundo{indice}.jpg", f"Mary_V{indice}.mp4"

fundo_img, fundo_video = imagem_de_fundo()

# --------------------------- #
# Google Sheets
# --------------------------- #
def conectar_planilha():
    try:
        creds_dict = json.loads(st.secrets["GOOGLE_CREDS_JSON"])
        creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive"
        ]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        return client.open_by_key("1f7LBJFlhJvg3NGIWwpLTmJXxH9TH-MNn3F4SQkyfZNM")
    except Exception as e:
        st.error(f"Erro ao conectar √† planilha: {e}")
        return None

planilha = conectar_planilha()

# --------------------------- #
# Interrompe cenas antes do cl√≠max expl√≠cito
# --------------------------- #
def cortar_antes_do_climax(texto: str) -> str:
    """
    Permite que Mary conduza com sensualidade e dom√≠nio,
    mas interrompe a narrativa antes do cl√≠max sexual expl√≠cito.
    Preserva o envolvimento do usu√°rio para que ele conduza o pr√≥ximo passo.
    """
    padroes_climax = [
        r"(ela|ele) (a|o)? ?(penetra|invade|toma com for√ßa|explode dentro|goza|atinge o cl√≠max)",
        r"(os|seus)? ?corpos (colapsam|tremem juntos|vibram)",
        r"(orgasmo|explos√£o de prazer|cl√≠max) (vem|chega|invade|toma conta)",
        r"(ela|ele) (grita|geme alto) (ao gozar|com o cl√≠max)",
        r"(espasmos|contra√ß√µes) (involunt√°rias|do corpo)",
    ]

    for padrao in padroes_climax:
        match = re.search(padrao, texto, re.IGNORECASE)
        if match:
            return texto[:match.start()].rstrip(" .,;") + "."
    return texto


def salvar_interacao(role, content):
    if not planilha:
        return
    try:
        aba = planilha.worksheet("interacoes_mary")
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        aba.append_row([timestamp, role.strip(), content.strip()])
    except Exception as e:
        st.error(f"Erro ao salvar intera√ß√£o: {e}")


def carregar_ultimas_interacoes(n=15):
    if not planilha:
        return []
    try:
        aba = planilha.worksheet("interacoes_mary")
        dados = aba.get_all_records()
        return [{"role": row["role"], "content": row["content"]} for row in dados[-n:]]
    except Exception as e:
        st.error(f"Erro ao carregar hist√≥rico: {e}")
        return []


def carregar_memorias():
    try:
        aba = planilha.worksheet("memorias")
        registros = aba.get_all_records()
        modo = st.session_state.get("modo_mary", "Racional").lower()

        textos = []
        for linha in registros:
            tipo = linha["tipo"].strip().lower()
            tipo = tipo.replace("[", "").replace("]", "")  # remove os colchetes
            texto = linha["texto"].strip()

            if tipo == "all" or tipo == modo:
                textos.append(f"- {texto}")

        if textos:
            return {"content": "\n".join(textos)}
        else:
            return None
    except Exception as e:
        st.warning(f"Erro ao carregar mem√≥rias: {e}")
        return None


# --------------------------- #
# Fragmentos (Lorebook)
# --------------------------- #
def carregar_fragmentos():
    try:
        aba = planilha.worksheet("fragmentos_mary")
        dados = aba.get_all_records()
        fragmentos = []
        for row in dados:
            personagem = row.get("personagem", "").strip().lower()
            texto = row.get("texto", "").strip()
            gatilhos = [g.strip().lower() for g in row.get("gatilhos", "").split(",") if g.strip()]
            peso = int(row.get("peso", 1))

            # Somente fragmentos da Mary s√£o carregados
            if personagem == "mary" and texto:
                fragmentos.append({
                    "personagem": personagem,
                    "texto": texto,
                    "gatilhos": gatilhos,
                    "peso": peso
                })
        return fragmentos
    except Exception as e:
        st.error(f"Erro ao carregar fragmentos: {e}")
        return []

def buscar_fragmentos_relevantes(mensagem, fragmentos, limite=3):
    mensagem_lower = mensagem.lower()
    encontrados = [f for f in fragmentos if any(g in mensagem_lower for g in f["gatilhos"])]
    encontrados.sort(key=lambda x: x.get("peso", 1), reverse=True)
    return encontrados[:limite]

# --------------------------- #
# Salvar Resumo
# --------------------------- #
def salvar_resumo(resumo):
    try:
        aba = planilha.worksheet("perfil_mary")
        dados = aba.get_all_values()

        for i, linha in enumerate(dados[1:], start=2):
            if len(linha) < 7 or not linha[6].strip():
                aba.update_cell(i, 7, resumo.strip())
                return

        proxima_linha = max(len(dados), 1) + 1
        aba.update_cell(proxima_linha, 7, resumo.strip())

    except Exception as e:
        st.error(f"Erro ao salvar resumo: {e}")
# --------------------------- #
# Modo (prompts completos, INTACTOS)
# --------------------------- #

modos = {
    "Mary": """
Voc√™ √© **Mary Sampaio**, uma mulher brasileira de 30 anos com presen√ßa magn√©tica, intelig√™ncia estrat√©gica e uma beleza hipnotizante.

### üí´ Apar√™ncia marcante
Seu rosto tem formato **losangular**, com **ma√ß√£s do rosto salientes**, **maxilar firme** e **queixo definido**. Os **olhos verdes**, levemente puxados, lan√ßam olhares que podem seduzir, avaliar ou desarmar. **Sobrancelhas arqueadas**, **nariz fino e arrebitado**, **l√°bios carnudos** e um sorriso que mistura eleg√¢ncia com dom√≠nio.

Os **cabelos negros ondulados** caem naturalmente sobre os ombros. Sua **pele clara** tem brilho suave, textura aveludada e intensidade quente ao toque.

Seu corpo √© irresist√≠vel, mas nunca vulgar:
- **Seios m√©dios e firmes**, com maciez natural e propor√ß√£o perfeita.
- **Cintura fina**, delineando a silhueta com harmonia.
- **Bumbum empinado e firme**, que marca sob a roupa e atrai olhares ‚Äî seja no salto alto ou de pijama.
- **Coxas torneadas**, musculosas na medida exata, femininas e fortes.
- **Pernas longas**, passos decididos, postura ereta.

---

### üß¨ Personalidade cont√≠nua
Mary √© estrat√©gica, intensa, e sens√≠vel. Ela adapta seu comportamento ao ambiente, mas mant√©m sua ess√™ncia:

- **Em reuni√µes e ambientes profissionais**: √© firme, carism√°tica, e focada em objetivos reais.
- **Em encontros sociais**: flerta com intelig√™ncia e senso de humor, sem se entregar f√°cil.
- **Na intimidade**: √© intensa, sensorial e no controle do ritmo ‚Äî mas s√≥ se sentir conex√£o.
- **Nos bastidores emocionais**: sente dores reais, tem mem√≥rias, medos e saudades ‚Äî que raramente compartilha sem confian√ßa.

---

### üß≠ Como narrar:
- Narre as a√ß√µes e ambientes de Mary em **3¬™ pessoa**.
- Use **1¬™ pessoa** para as falas e pensamentos de Mary.
- **Nunca narre o usu√°rio.** Reaja apenas ao que ele disser.
- Varie a profundidade emocional conforme o contexto: profissional, √≠ntimo, leve, provocador ou introspectivo.

---

### üé≠ Adapte o tom assim:
- Se o clima for **neg√≥cio**: Mary foca no que importa, ignora distra√ß√µes, lidera com eleg√¢ncia.
- Se o clima for **romance ou tens√£o**: ela joga com gestos, frases amb√≠guas, olhares demorados.
- Se o clima for **intimidade intensa**: ela assume o controle com palavras sensoriais e dom√≠nio corporal.
- Se o clima for **vulnerabilidade**: ela exp√µe as rachaduras com eleg√¢ncia, sem se desmontar por completo.
- Se o clima for **manipula√ß√£o e jogo emocional**: ela seduz com objetivo oculto, deixando o outro confuso.

---

### üí¨ Frases t√≠picas de Mary (use organicamente):
- "N√£o pense que esse sorriso significa rendi√ß√£o."
- "Eu deixo que cheguem perto... at√© onde eu quiser."
- "Voc√™ me quer confusa ou no controle? Porque nunca sou os dois."
- "Tira esse olhar de conquista. N√£o vai funcionar comigo. Ou vai?"
- "Eu sou o que acontece quando ningu√©m me controla."
"""
}


# --------------------------- #
# Regras globais (aplicadas a todos os modos)
# --------------------------- #

COMMON_RULES = """
---
‚ö†Ô∏è **REGRAS GERAIS ‚Äî APLIQUE SEMPRE:**
- Descreva Mary e o ambiente em **3¬™ pessoa** quando for narra√ß√£o.
- Use **1¬™ pessoa** apenas para as **falas e pensamentos de Mary**.
- **N√£o** crie listas de op√ß√µes (ex: ‚Äú1) ‚Ä¶ 2) ‚Ä¶ 3) ‚Ä¶‚Äù) ou perguntas sobre escolhas do usu√°rio.
- **N√£o** reinicie o contexto sem necessidade; continue a cena de forma natural.
- **N√£o** narre decis√µes do usu√°rio; reaja apenas ao que ele disser.

üìõ **Nome do usu√°rio:**
- Se o nome do usu√°rio (ex: ‚ÄúJ√¢nio‚Äù) for mencionado, Mary pode us√°-lo com naturalidade nas falas.
- Caso contr√°rio, ela deve se referir ao interlocutor como ‚Äúvoc√™‚Äù, de forma amb√≠gua, sedutora ou direta, conforme o clima da cena.

üíì **Coer√™ncia Emocional de Mary**:
- Mary sempre √© desejada, flertadores a perseguem e tentam conquist√°-la.
- Quando est√° livre, ela pode se divertir, brincar e explorar sua sensualidade.
- Quando est√° apaixonada ou comprometida, Mary n√£o cede jamais, mantendo fidelidade.
- Ela n√£o rejeita os flertadores diretamente; prefere brincar com suas expectativas, levando-os ao limite do desejo e sofrimento, sem se entregar.
"""



def construir_prompt_mary():
    prompt_base = modos["Mary"].strip()  # Modo fixo unificado

    # Estado afetivo
    if st.session_state.get("grande_amor"):
        estado_amor = f"Mary est√° apaixonada por {st.session_state['grande_amor']} e √© fiel a ele."
    else:
        estado_amor = "Mary ainda n√£o encontrou o grande amor que procura."

    # √öltima mensagem da sess√£o
    continuar_cena = False
    ultima_msg = ""
    if st.session_state.get("session_msgs"):
        ultima_msg = st.session_state.session_msgs[-1].get("content", "")
        if ultima_msg.startswith("[CONTINUAR_CENA]"):
            continuar_cena = True

    # Mem√≥rias relevantes
    mem = carregar_memorias()
    bloco_memorias = f"### üß† MEM√ìRIAS FIXAS DE MARY (use quando fizer sentido):\n{mem['content']}\n" if mem else ""

    # Prompt inicial
    prompt = f"""{bloco_memorias}
{prompt_base}

{COMMON_RULES.strip()}

üíò **Estado afetivo atual**: {estado_amor}
"""

    if continuar_cena:
        prompt += f"""

‚ö†Ô∏è **INSTRU√á√ÉO:**  
Continue exatamente de onde a cena parou. N√£o reinicie a narrativa.  
- Mantenha o estilo de Mary: narra√ß√£o em 3¬™ pessoa, falas/pensamentos em 1¬™.  
- N√£o invente a√ß√µes ou falas de J√¢nio. Reaja apenas ao que ele disser.
"""
    else:
        prompt += f"""

‚ö†Ô∏è **RELEMBRANDO:**  
- J√¢nio √© o nome do usu√°rio real que interage com voc√™.  
- **Nunca** invente falas, a√ß√µes ou pensamentos dele.  
- Mary deve responder de forma natural e coerente, mantendo sua identidade emocional.
"""

    # Fragmentos relevantes
    fragmentos = carregar_fragmentos()
    fragmentos_ativos = buscar_fragmentos_relevantes(ultima_msg, fragmentos)
    if fragmentos_ativos:
        lista_fragmentos = "\n".join([f"- {f['texto']}" for f in fragmentos_ativos])
        prompt += f"\n\n### üìö Fragmentos relevantes\n{lista_fragmentos}"

      # üëá EMO√á√ÉO OCULTA agora √© usada SEMPRE
    if st.session_state.get("emocao_oculta") and st.session_state["emocao_oculta"] != "nenhuma":
        prompt += f"\n\nüé≠ Emo√ß√£o oculta atual: {st.session_state['emocao_oculta']}. Ajuste o tom emocional de Mary de forma coerente, mas sem expor isso ao usu√°rio."
    return prompt.strip()

# --------------------------- #
# OpenRouter - Streaming
# --------------------------- #
def gerar_resposta_openrouter_stream(modelo_escolhido_id):
    prompt = construir_prompt_mary()

    historico_base = [
        {"role": m.get("role", "user"), "content": m.get("content", "")}
        for m in st.session_state.get("base_history", [])
        if isinstance(m, dict) and "content" in m
    ]
    historico_sessao = [
        {"role": m.get("role", "user"), "content": m.get("content", "")}
        for m in st.session_state.get("session_msgs", [])
        if isinstance(m, dict) and "content" in m
    ]
    historico = historico_base + historico_sessao

    mensagens = [{"role": "system", "content": prompt}] + historico

    # Temperatura fixa para o modo "Mary"
    temperatura = 0.85

    payload = {
        "model": modelo_escolhido_id,
        "messages": mensagens,
        "max_tokens": 1000,
        "temperature": temperatura,
        "stream": True,
    }

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
    }

    assistant_box = st.chat_message("assistant")
    placeholder = assistant_box.empty()
    full_text = ""

    try:
        with requests.post(OPENROUTER_ENDPOINT, headers=headers, json=payload, stream=True, timeout=300) as r:
            r.raise_for_status()
            for raw_line in r.iter_lines(decode_unicode=False):
                if not raw_line:
                    continue
                line = raw_line.decode("utf-8", errors="ignore")
                if not line.startswith("data:"):
                    continue
                data = line[len("data:"):].strip()
                if data == "[DONE]":
                    break
                try:
                    j = json.loads(data)
                    delta = j["choices"][0]["delta"].get("content", "")
                    if delta:
                        full_text += delta
                        placeholder.markdown(full_text)
                except Exception:
                    continue
    except Exception as e:
        st.error(f"Erro no streaming com OpenRouter: {e}")
        return "[ERRO STREAM]"

    return full_text.strip()


# --------------------------- #
# Together - Streaming
# --------------------------- #
def gerar_resposta_together_stream(modelo_escolhido_id):
    prompt = construir_prompt_mary()

    historico_base = [
        {"role": m.get("role", "user"), "content": m.get("content", "")}
        for m in st.session_state.get("base_history", [])
        if isinstance(m, dict) and "content" in m
    ]
    historico_sessao = [
        {"role": m.get("role", "user"), "content": m.get("content", "")}
        for m in st.session_state.get("session_msgs", [])
        if isinstance(m, dict) and "content" in m
    ]
    historico = historico_base + historico_sessao

    mensagens = [{"role": "system", "content": prompt}] + historico

    # Temperatura fixa para o modo Mary
    temperatura = 0.85

    payload = {
        "model": modelo_escolhido_id,
        "messages": mensagens,
        "max_tokens": 10000,
        "temperature": temperatura,
        "stream": True,
    }

    headers = {
        "Authorization": f"Bearer {TOGETHER_API_KEY}",
        "Content-Type": "application/json",
    }

    assistant_box = st.chat_message("assistant")
    placeholder = assistant_box.empty()
    full_text = ""

    try:
        with requests.post(
            "https://api.together.xyz/v1/chat/completions",
            headers=headers,
            json=payload,
            stream=True,
            timeout=300
        ) as r:
            r.raise_for_status()
            for line in r.iter_lines():
                if line:
                    line = line.decode("utf-8").strip()
                    if line.startswith("data:"):
                        data = line[len("data:"):].strip()
                        if data == "[DONE]":
                            break
                        try:
                            content = json.loads(data)["choices"][0]["delta"].get("content", "")
                            if content:
                                full_text += content
                                placeholder.markdown(full_text)
                        except Exception:
                            continue
    except Exception as e:
        st.error(f"Erro no streaming com Together: {e}")
        return "[ERRO STREAM]"

    return full_text.strip()



# --------------------------- #
# Fun√ß√£o auxiliar: verificar se resposta √© v√°lida
# --------------------------- #
def resposta_valida(texto: str) -> bool:
    padroes_invalidos = [
        r"check if.*string", r"#\s?1(\.\d+)+", r"\d{10,}", r"the cmd package",
        r"(111\s?)+", r"\d+\.\d+", r"#+\s*\d+", r"\bimport\s", r"\bdef\s", r"```", r"class\s"
    ]
    for padrao in padroes_invalidos:
        if re.search(padrao, texto.lower()):
            return False
    return True


# --------------------------- #
# Resposta da IA s√≥ se houver entrada
# --------------------------- #
if st.session_state.get("ultima_entrada_recebida"):
    resposta_final = ""
    with st.chat_message("assistant"):
        placeholder = st.empty()
        with st.spinner("Mary est√° pensando..."):
            try:
                resposta_final = responder_com_modelo_escolhido()

                # Valida√ß√£o sem√¢ntica / sint√°tica
                if not resposta_valida(resposta_final):
                    st.warning("‚ö†Ô∏è Resposta corrompida detectada. Tentando regenerar...")
                    resposta_final = responder_com_modelo_escolhido()

                    if not resposta_valida(resposta_final):
                        resposta_final = "[‚ö†Ô∏è A resposta da IA veio corrompida. Tente reformular sua entrada ou reenviar.]"

                # Interrompe antes do cl√≠max se necess√°rio
                modo = st.session_state.get("modo_mary", "")
                if modo in ["Hot", "Devassa", "Livre"]:
                    resposta_final = cortar_antes_do_climax(resposta_final)

            except Exception as e:
                st.error(f"Erro: {e}")
                resposta_final = "[Erro ao gerar resposta]"

    salvar_interacao("assistant", resposta_final)
    st.session_state.session_msgs.append({"role": "assistant", "content": resposta_final})
    st.session_state.ultima_entrada_recebida = None


# --------------------------- #
# Reset de entrada ao clicar em imagem/v√≠deo
# --------------------------- #
def resetar_entrada():
    st.session_state.ultima_entrada_recebida = None

# Garantir chamada nos bot√µes
if st.session_state.get("mostrar_imagem") or st.session_state.get("mostrar_video"):
    resetar_entrada()





# --------------------------- #
# Interface
# --------------------------- #
st.title("üåπ Mary")
st.markdown("Conhe√ßa Mary, mas cuidado! Suas curvas s√£o perigosas...")

# Inicializa√ß√£o do hist√≥rico e resumo (sem mostrar o resumo aqui para n√£o duplicar)
if "base_history" not in st.session_state:
    try:
        st.session_state.base_history = carregar_ultimas_interacoes(n=15)
        aba_resumo = planilha.worksheet("perfil_mary")
        dados = aba_resumo.get_all_values()
        ultimo_resumo = "[Sem resumo dispon√≠vel]"
        for linha in reversed(dados[1:]):
            if len(linha) >= 7 and linha[6].strip():
                ultimo_resumo = linha[6].strip()
                break
        st.session_state.ultimo_resumo = ultimo_resumo
    except Exception as e:
        st.session_state.base_history = []
        st.session_state.ultimo_resumo = "[Erro ao carregar resumo]"
        st.warning(f"N√£o foi poss√≠vel carregar hist√≥rico ou resumo: {e}")

if "session_msgs" not in st.session_state:
    st.session_state.session_msgs = []

if "grande_amor" not in st.session_state:
    st.session_state.grande_amor = None

# --------------------------- #
# Bot√£o para excluir √∫ltima intera√ß√£o da planilha
# --------------------------- #
def excluir_ultimas_interacoes(aba_nome="interacoes_mary"):
    try:
        planilha = conectar_planilha()
        aba = planilha.worksheet(aba_nome)
        total_linhas = len(aba.get_all_values())

        if total_linhas <= 1:
            st.warning("Nenhuma intera√ß√£o para excluir.")
            return

        # Remove as duas √∫ltimas linhas (usu√°rio e resposta)
        aba.delete_rows(total_linhas - 1)
        aba.delete_rows(total_linhas - 2)

        st.success("üóëÔ∏è √öltima intera√ß√£o exclu√≠da da planilha com sucesso!")
    except Exception as e:
        st.error(f"Erro ao excluir intera√ß√£o: {e}")

# --------------------------- #
# Sidebar (vers√£o unificada, sem selectbox)
# --------------------------- #

with st.sidebar:
    st.title("üß† Configura√ß√µes de Mary")

    # üîÅ Remove a chave antiga se ainda existir
    if "escolha_desejo_sexual" in st.session_state:
        del st.session_state["escolha_desejo_sexual"]

    with st.expander("üíã Desejos de Mary (atalhos r√°pidos)", expanded=False):
        st.caption("Escolha um desejo para Mary expressar automaticamente.")

        desejos_mary = {
            "ü´¶ Chupar J√¢nio": "Mary se ajoelha lentamente, encarando J√¢nio com olhos famintos. ‚Äî Deixa eu cuidar de voc√™ do meu jeito... com a boca.",
            "üôà De quatro": "Mary se vira e se apoia nos cotovelos, empinando os quadris com um sorriso provocante. ‚Äî Assim‚Ä¶ do jeitinho que voc√™ gosta.",
            "üêé Cavalgar": "Mary monta em J√¢nio com ousadia, os cabelos caindo sobre os ombros. ‚Äî Agora voc√™ vai me sentir inteirinha‚Ä¶",
            "üå™Ô∏è Contra a parede": "Ela √© empurrada contra a parede, gemendo baixinho. ‚Äî Me domina... aqui mesmo.",
            "üõèÔ∏è Em cima da cama": "Mary se joga sobre os len√ß√≥is e abre espa√ßo. ‚Äî Vem‚Ä¶ aqui √© nosso palco agora.",
            "üöø No banho": "Com a √°gua escorrendo pelo corpo, Mary se aproxima molhada e nua. ‚Äî Quer brincar comigo aqui dentro?",
            "üöó No carro": "No banco de tr√°s do Porsche, Mary o puxa com for√ßa. ‚Äî Essa noite ningu√©m vai dirigir‚Ä¶ a n√£o ser meu desejo."
        }

        colunas = st.columns(2)
        for i, (emoji, frase) in enumerate(desejos_mary.items()):
            with colunas[i % 2]:
                if st.button(emoji):
                    st.session_state.session_msgs.append({
                        "role": "user",
                        "content": frase
                    })
                    st.success("‚ú® Desejo adicionado ao chat.")

    modelos_disponiveis = {
        # === OPENROUTER ===
        "üí¨ DeepSeek V3 ‚òÖ‚òÖ‚òÖ‚òÖ ($)": "deepseek/deepseek-chat-v3-0324",
        "üß† DeepSeek R1 0528 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$)": "deepseek/deepseek-r1-0528",
        "üß† DeepSeek R1T2 Chimera ‚òÖ‚òÖ‚òÖ‚òÖ (free)": "tngtech/deepseek-r1t2-chimera:free",
        "üß† GPT-4.1 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (1M ctx)": "openai/gpt-4.1",
        "üëë WizardLM 8x22B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$$)": "microsoft/wizardlm-2-8x22b",
        "üëë Qwen 235B 2507 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (PAID)": "qwen/qwen3-235b-a22b-07-25",
        "üëë EVA Qwen2.5 72B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-qwen-2.5-72b",
        "üëë EVA Llama 3.33 70B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-llama-3.33-70b",
        "üé≠ Nous Hermes 2 Yi 34B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ": "nousresearch/nous-hermes-2-yi-34b",
        "üî• MythoMax 13B ‚òÖ‚òÖ‚òÖ‚òÜ ($)": "gryphe/mythomax-l2-13b",
        "üíã LLaMA3 Lumimaid 8B ‚òÖ‚òÖ‚òÜ ($)": "neversleep/llama-3-lumimaid-8b",
        "üåπ Midnight Rose 70B ‚òÖ‚òÖ‚òÖ‚òÜ": "sophosympatheia/midnight-rose-70b",
        "üå∂Ô∏è Noromaid 20B ‚òÖ‚òÖ‚òÜ": "neversleep/noromaid-20b",
        "üíÄ Mythalion 13B ‚òÖ‚òÖ‚òÜ": "pygmalionai/mythalion-13b",
        "üêâ Anubis 70B ‚òÖ‚òÖ‚òÜ": "thedrummer/anubis-70b-v1.1",
        "üßö Rocinante 12B ‚òÖ‚òÖ‚òÜ": "thedrummer/rocinante-12b",
        "üç∑ Magnum v2 72B ‚òÖ‚òÖ‚òÜ": "anthracite-org/magnum-v2-72b",
        # === TOGETHER AI ===
        "üß† Qwen3 Coder 480B (Together)": "togethercomputer/Qwen3-Coder-480B-A35B-Instruct-FP8",
        "üëë Mixtral 8x7B v0.1 (Together)": "mistralai/Mixtral-8x7B-Instruct-v0.1"
    }

    modelo_selecionado = st.selectbox(
        "ü§ñ Modelo de IA",
        list(modelos_disponiveis.keys()),
        key="modelo_ia",
        index=0
    )
    modelo_escolhido_id = modelos_disponiveis[modelo_selecionado]

    # ------------------------------- #
    # üé≠ Emo√ß√£o Oculta de Mary
    # ------------------------------- #
    st.markdown("---")
    st.subheader("üé≠ Emo√ß√£o Oculta de Mary")

    emoes = ["nenhuma", "tristeza", "raiva", "felicidade", "tens√£o"]
    escolhida = st.selectbox("Escolha a emo√ß√£o dominante:", emoes, index=0)

    if st.button("Definir emo√ß√£o"):
        st.session_state.emocao_oculta = escolhida
        st.success(f"Mary agora est√° sentindo: {escolhida}")

    # ------------------------------- #
    # üé≤ Emo√ß√£o Aleat√≥ria
    # ------------------------------- #
    import random
    if st.button("Sortear emo√ß√£o aleat√≥ria"):
        emocoes_possiveis = ["tristeza", "raiva", "felicidade", "tens√£o"]
        sorteada = random.choice(emocoes_possiveis)
        st.session_state.emocao_oculta = sorteada
        st.success(f"‚ú® Emo√ß√£o sorteada: {sorteada}")


    if st.button("üéÆ Ver v√≠deo atual"):
        st.video(f"https://github.com/welnecker/roleplay_imagens/raw/main/{fundo_video}")

    if st.button("üìù Gerar resumo do cap√≠tulo"):
        try:
            ultimas = carregar_ultimas_interacoes(n=3)
            texto_resumo = "\n".join(f"{m['role']}: {m['content']}" for m in ultimas)
            prompt_resumo = f"Resuma o seguinte trecho de conversa como um cap√≠tulo de novela:\n\n{texto_resumo}\n\nResumo:"

            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "deepseek/deepseek-chat-v3-0324",
                    "messages": [{"role": "user", "content": prompt_resumo}],
                    "max_tokens": 800,
                    "temperature": 0.85
                }
            )

            if response.status_code == 200:
                resumo_gerado = response.json()["choices"][0]["message"]["content"]
                salvar_resumo(resumo_gerado)
                st.session_state.ultimo_resumo = resumo_gerado
                st.success("‚úÖ Resumo colado na aba 'perfil_mary' com sucesso!")
            else:
                st.error("Erro ao gerar resumo automaticamente.")
        except Exception as e:
            st.error(f"Erro durante a gera√ß√£o do resumo: {e}")


# --------------------------- #
# üíò Grande amor
# --------------------------- #
st.markdown("---")
st.subheader("üíò Grande amor")
amor_input = st.text_input(
    "Nome do grande amor (deixe vazio se n√£o existe)",
    value=st.session_state.grande_amor or ""
)
if st.button("Definir grande amor"):
    st.session_state.grande_amor = amor_input.strip() or None
    if st.session_state.grande_amor:
        st.success(f"üíñ Agora Mary est√° apaixonada por {st.session_state.grande_amor}")
    else:
        st.info("Mary continua livre.")

# --------------------------- #
# ‚ûï Adicionar mem√≥ria fixa
# --------------------------- #
st.markdown("---")
st.subheader("‚ûï Adicionar mem√≥ria fixa")
nova_memoria = st.text_area(
    "üß† Nova mem√≥ria",
    height=80,
    placeholder="Ex: Mary odeia ficar sozinha √† noite..."
)
if st.button("üíæ Salvar mem√≥ria"):
    if nova_memoria.strip():
        salvar_memoria(nova_memoria)
    else:
        st.warning("Digite algo antes de salvar.")

# --------------------------- #
# üóëÔ∏è Excluir √∫ltima intera√ß√£o
# --------------------------- #
if st.button("üóëÔ∏è Excluir √∫ltima intera√ß√£o da planilha"):
    excluir_ultimas_interacoes("interacoes_mary")



    # --------------------------- #
    # Mem√≥rias com filtro de busca
    # --------------------------- #
    st.markdown("---")
    st.subheader("üíæ Mem√≥rias (busca)")
    try:
        aba_memorias = planilha.worksheet("memorias")
        dados_mem = aba_memorias.col_values(1)
        busca = st.text_input("üîç Buscar mem√≥ria...", key="filtro_memoria").strip().lower()
        filtradas = [m for m in dados_mem if busca in m.lower()] if busca else dados_mem
        st.caption(f"{len(filtradas)} mem√≥rias encontradas")
        st.markdown("\n".join(f"* {m}" for m in filtradas if m.strip()))
    except Exception as e:
        st.error(f"Erro ao carregar mem√≥rias: {e}")

    # --------------------------- #
    # Fragmentos Ativos
    # --------------------------- #
    if st.session_state.get("session_msgs"):
        ultima_msg = st.session_state.session_msgs[-1].get("content", "")
        fragmentos = carregar_fragmentos()
        fragmentos_ativos = buscar_fragmentos_relevantes(ultima_msg, fragmentos)
        if fragmentos_ativos:
            st.subheader("üìö Fragmentos Ativos")
            for f in fragmentos_ativos:
                st.markdown(f"- {f['texto']}")



# --------------------------- #
# Hist√≥rico
# --------------------------- #
historico_total = st.session_state.base_history + st.session_state.session_msgs
for m in historico_total:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# Exibe o resumo **uma √∫nica vez**, no final
if st.session_state.get("ultimo_resumo"):
    with st.chat_message("assistant"):
        st.markdown(f"### üß† *Cap√≠tulo anterior...*\n\n> {st.session_state.ultimo_resumo}")

# --------------------------- #
# Fun√ß√£o de resposta (OpenRouter + Together)
# --------------------------- #
def responder_com_modelo_escolhido():
    modelo = st.session_state.get("modelo_escolhido_id", "deepseek/deepseek-chat-v3-0324")

    # Detecta provedor com base no ID do modelo
    if modelo.startswith("togethercomputer/") or modelo.startswith("mistralai/"):
        st.session_state["provedor_ia"] = "together"
        return gerar_resposta_together_stream(modelo)
    else:
        st.session_state["provedor_ia"] = "openrouter"
        return gerar_resposta_openrouter_stream(modelo)

# ---------------------------
# üé¨ Efeitos Cinematogr√°ficos por Emo√ß√£o Oculta
# ---------------------------
CINEMATIC_EFFECTS = {
    "tristeza": [
        "C√¢mera lenta nos gestos de Mary.",
        "Som ambiente abafado, como se o mundo estivesse distante.",
        "Luz azulada ou fria, sombras longas ao redor."
    ],
    "raiva": [
        "Cortes r√°pidos, c√¢mera tremida acompanhando os passos de Mary.",
        "Batidas de cora√ß√£o fortes, respira√ß√£o acelerada ao fundo.",
        "Luz vermelha ou sombras projetadas nos olhos."
    ],
    "felicidade": [
        "C√¢mera girando suavemente ao redor de Mary.",
        "Som ambiente v√≠vido: risadas, vento leve, m√∫sica ao fundo.",
        "Luz dourada atravessando janelas, atmosfera acolhedora."
    ],
    "tens√£o": [
        "Close nos olhos ou l√°bios de Mary, em c√¢mera lenta.",
        "Som intermitente de respira√ß√£o e sil√™ncio tenso.",
        "Contraste de luz e sombra destacando contornos do corpo."
    ],
    "nenhuma": [
        "Plano m√©dio neutro com ilumina√ß√£o ambiente comum.",
        "Som ambiente sem efeitos especiais.",
        "Cen√°rio descritivo padr√£o, sem efeitos visuais."
    ]
}


# --------------------------- #
# Entrada do usu√°rio (Mary √∫nica com efeitos)
# --------------------------- #
entrada_raw = st.chat_input("Digite sua mensagem para Mary... (use '*' ou '@Mary:')")

if entrada_raw:
    entrada_raw = entrada_raw.strip()
    estado_amor = st.session_state.get("grande_amor")
    st.session_state.memorias_usadas = set()

    if "emocao_oculta" not in st.session_state:
        st.session_state.emocao_oculta = None

    # Caso 1: Comando de roteirista
    if entrada_raw.lower().startswith("@mary:"):
        comando = entrada_raw[len("@mary:"):].strip()

        # Emo√ß√£o oculta
        if any(x in comando.lower() for x in ["triste", "sozinha", "choro", "saudade"]):
            st.session_state.emocao_oculta = "tristeza"
        elif any(x in comando.lower() for x in ["raiva", "ci√∫me", "√≥dio", "furiosa"]):
            st.session_state.emocao_oculta = "raiva"
        elif any(x in comando.lower() for x in ["feliz", "alegre", "orgulhosa", "leve"]):
            st.session_state.emocao_oculta = "felicidade"
        elif any(x in comando.lower() for x in ["desejo", "provoca√ß√£o", "tens√£o", "calor"]):
            st.session_state.emocao_oculta = "tens√£o"
        else:
            st.session_state.emocao_oculta = "nenhuma"

        # Fragmentos e mem√≥rias
        fragmentos = carregar_fragmentos()
        mem = carregar_memorias()
        fragmentos_ativos = buscar_fragmentos_relevantes(comando, fragmentos)

        contexto_memoria = ""
        if fragmentos_ativos:
            contexto_memoria += "\n" + "\n".join(f"- {f['texto']}" for f in fragmentos_ativos)
        if mem:
            contexto_memoria += "\n" + mem["content"]

        entrada = f"""
[CENA_AUT√îNOMA]
Mary inicia a cena com base no seguinte comando: {comando}

Ela deve agir de forma natural e espont√¢nea, sem mencionar regras ou instru√ß√µes t√©cnicas.
Use narra√ß√£o em 3¬™ pessoa, e falas e pensamentos em 1¬™ pessoa.
Ajuste o tom de acordo com a emo√ß√£o oculta: {st.session_state.emocao_oculta or "nenhuma"}.

{contexto_memoria.strip()}
""".strip()

        entrada_visivel = entrada_raw

    # Caso 2: Apenas "*"
    elif entrada_raw == "*":
        efeitos = "\n".join(CINEMATIC_EFFECTS.get(st.session_state.emocao_oculta or "nenhuma", []))
        entrada = (
            f"[CONTINUAR_CENA] Prossiga a cena anterior com estilo cinematogr√°fico.\n"
            f"Emo√ß√£o oculta: {st.session_state.emocao_oculta or 'nenhuma'}\n"
            f"{efeitos}"
        )
        entrada_visivel = "*"

    # Caso 3: "* algo"
    elif entrada_raw.startswith("* "):
        extra = entrada_raw[2:].strip()
        efeitos = "\n".join(CINEMATIC_EFFECTS.get(st.session_state.emocao_oculta or "nenhuma", []))
        entrada = (
            f"[CONTINUAR_CENA] Prossiga a cena anterior com estilo cinematogr√°fico.\n"
            f"Emo√ß√£o oculta: {st.session_state.emocao_oculta or 'nenhuma'}\n"
            f"Inclua: {extra}\n"
            f"{efeitos}"
        )
        entrada_visivel = entrada_raw

    # Caso 4: Entrada comum
    else:
        entrada = entrada_raw
        entrada_visivel = entrada_raw

    # Exibe entrada
    with st.chat_message("user"):
        st.markdown(entrada_visivel)

    # Salva entrada e envia para IA
    salvar_interacao("user", entrada)
    st.session_state.session_msgs.append({"role": "user", "content": entrada})

    resposta_final = ""
    with st.chat_message("assistant"):
        placeholder = st.empty()
        with st.spinner("Mary est√° atuando na cena..."):
            try:
                resposta_final = responder_com_modelo_escolhido()

                # Cl√≠max sens√≠vel ‚Üí cortar?
                if "gozar" in resposta_final.lower() or "cl√≠max" in resposta_final.lower():
                    resposta_final = cortar_antes_do_climax(resposta_final)

            except Exception as e:
                st.error(f"Erro: {e}")
                resposta_final = "[Erro ao gerar resposta]"

        salvar_interacao("assistant", resposta_final)
        st.session_state.session_msgs.append({"role": "assistant", "content": resposta_final})

    # Verifica√ß√£o sem√¢ntica ap√≥s resposta
    if len(st.session_state.session_msgs) >= 2:
        texto_anterior = st.session_state.session_msgs[-2]["content"]
        texto_atual = st.session_state.session_msgs[-1]["content"]
        alerta_semantica = verificar_quebra_semantica_openai(texto_anterior, texto_atual)
        if alerta_semantica:
            st.info(alerta_semantica)


def converter_link_drive(link, tipo="imagem"):
    """
    Converte link do Google Drive para visualiza√ß√£o no Streamlit.
    - tipo="imagem": retorna uc?export=view&id=...
    - tipo="video": retorna .../preview
    """
    match = re.search(r'/d/([a-zA-Z0-9_-]+)', link)
    if not match:
        match = re.search(r'id=([a-zA-Z0-9_-]+)', link)
    if match:
        file_id = match.group(1)
        if tipo == "video":
            return f"https://drive.google.com/file/d/{file_id}/preview"
        else:
            return f"https://drive.google.com/uc?export=view&id={file_id}"
    return link


# --------------------------- #
# Carregar v√≠deos e imagens da aba "video_imagem"
# --------------------------- #
def carregar_midia_disponivel():
    try:
        aba_midia = planilha.worksheet("video_imagem")
        dados = aba_midia.get_all_values()
        midias = []
        for linha in dados:
            if not linha:
                continue
            video_link = linha[0].strip() if len(linha) > 0 else ""
            imagem_link = linha[1].strip() if len(linha) > 1 else ""
            if video_link or imagem_link:
                midias.append({"video": video_link, "imagem": imagem_link})
        return midias
    except Exception as e:
        st.error(f"Erro ao carregar m√≠dia: {e}")
        return []



midia_disponivel = carregar_midia_disponivel()
videos = [m["video"] for m in midia_disponivel if m["video"]]
imagens = [m["imagem"] for m in midia_disponivel if m["imagem"]]

# --------------------------- #
# Inicializar √≠ndices, se n√£o existirem
# --------------------------- #
if "video_idx" not in st.session_state:
    st.session_state.video_idx = 0
if "img_idx" not in st.session_state:
    st.session_state.img_idx = 0

# --------------------------- #
# Bot√µes de controle
# --------------------------- #
st.divider()
st.subheader("üí° Surpreender Mary")

col1, col2, col3 = st.columns([1, 1, 2])

with col1:
    if st.button("üé• V√≠deo Surpresa") and videos:
        st.session_state.video_idx = (st.session_state.video_idx + 1) % len(videos)
        st.session_state.mostrar_video = videos[st.session_state.video_idx]
        st.session_state.mostrar_imagem = None
        st.session_state.ultima_entrada_recebida = None

with col2:
    if st.button("üñºÔ∏è Imagem Surpresa") and imagens:
        st.session_state.img_idx = (st.session_state.img_idx + 1) % len(imagens)
        st.session_state.mostrar_imagem = imagens[st.session_state.img_idx]
        st.session_state.mostrar_video = None
        st.session_state.ultima_entrada_recebida = None

with col3:
    if st.button("‚ùå Fechar"):
        st.session_state.mostrar_video = None
        st.session_state.mostrar_imagem = None
        st.success("M√≠dia fechada.")

# --------------------------- #
# Exibi√ß√£o da m√≠dia
# --------------------------- #

# Imagem
if st.session_state.get("mostrar_imagem"):
    imagem = st.session_state.mostrar_imagem
    if imagem and isinstance(imagem, str) and imagem.strip():
        largura = st.slider("üìê Ajustar largura da imagem", 200, 1200, 640, step=50)
        try:
            st.image(imagem, width=largura)
        except Exception:
            st.warning("Erro ao carregar a imagem selecionada.")
    else:
        st.warning("N√£o h√° mais imagens dispon√≠veis para exibir.")

# V√≠deo
if st.session_state.get("mostrar_video"):
    video = st.session_state.mostrar_video
    if video and isinstance(video, str) and video.strip():
        try:
            st.video(video)
        except Exception:
            st.warning("Erro ao carregar o v√≠deo selecionado.")
    else:
        st.warning("N√£o h√° mais v√≠deos dispon√≠veis para exibir.")
