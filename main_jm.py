# ============================================================
# Narrador JM ‚Äî Variante ‚ÄúSomente FASE do romance‚Äù
# ============================================================

import os
import re
import json
import time
import random
from datetime import datetime
from typing import List, Dict, Any
import streamlit as st
import requests
import gspread
from gspread.exceptions import APIError
from oauth2client.service_account import ServiceAccountCredentials
from huggingface_hub import InferenceClient

# =========================
# CONFIG B√ÅSICA DO APP
# =========================

ONLY_FASE_MODE = True

PLANILHA_ID_PADRAO = st.secrets.get("SPREADSHEET_ID", "").strip() or "1f7LBJFlhJvg3NGIWwpLTmJXxH9TH-MNn3F4SQkyfZNM"
TAB_INTERACOES = "interacoes_jm"

# Modelos (pode expandir depois)
MODELOS_OPENROUTER = {
    "üí¨ DeepSeek V3 ‚òÖ‚òÖ‚òÖ‚òÖ ($)": "deepseek/deepseek-chat-v3-0324",
    "üß† DeepSeek R1 0528 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$)": "deepseek/deepseek-r1-0528",
    "üß† DeepSeek R1T2 Chimera ‚òÖ‚òÖ‚òÖ‚òÖ (free)": "tngtech/deepseek-r1t2-chimera:free",
    "üß† GPT-4.1 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (1M ctx)": "openai/gpt-4.1",
    "‚ö° Google Gemini 2.5 Pro": "google/gemini-2.5-pro",
    "üëë WizardLM 8x22B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$$)": "microsoft/wizardlm-2-8x22b",
    "üëë Qwen 235B 2507 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (PAID)": "qwen/qwen3-235b-a22b-07-25",
    "üëë EVA Qwen2.5 72B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-qwen-2.5-72b",
    "üëë EVA Llama 3.33 70B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-llama-3.33-70b",
    "üé≠ Nous Hermes 2 Yi 34B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ": "nousresearch/nous-hermes-2-yi-34b",
    "üî• MythoMax 13B ‚òÖ‚òÖ‚òÖ‚òÜ ($)": "gryphe/mythomax-l2-13b",
    "üíã LLaMA3 Lumimaid 8B ‚òÖ‚òÖ‚òÜ ($)": "neversleep/llama-3-lumimaid-8b",
    "üåπ Midnight Rose 70B ‚òÖ‚òÖ‚òÖ‚òÜ": "sophosympatheia/midnight-rose-70b",
    "üå∂Ô∏è Noromaid 20B ‚òÖ‚òÖ‚òÜ": "neversleep/noromaid-20b",
    "üíÄ Mythalion 13B ‚òÖ‚òÖ‚òÜ": "pygmalionai/mythalion-13b",
    "üêâ Anubis 70B ‚òÖ‚òÖ‚òÜ": "thedrummer/anubis-70b-v1.1",
    "üßö Rocinante 12B ‚òÖ‚òÖ‚òÜ": "thedrummer/rocinante-12b",
    "üç∑ Magnum v2 72B ‚òÖ‚òÖ‚òÜ": "anthracite-org/magnum-v2-72b",
}
MODELOS_TOGETHER_UI = {
    "üß† Qwen3 Coder 480B (Together)": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "üß† Qwen2.5-VL (72B) Instruct (Together)": "Qwen/Qwen2.5-VL-72B-Instruct",
    "üëë Mixtral 8x7B v0.1 (Together)": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "üëë Perplexity R1-1776 (Together)": "perplexity-ai/r1-1776",
    "üëë DeepSeek R1-0528 (Together)": "deepseek-ai/DeepSeek-R1",
}
MODELOS_HF = {
    "Llama 3.1 8B Instruct (HF)": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "Qwen2.5 7B Instruct (HF)":   "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "zai-org: LM-4.5-Air (HF)":   "zai-org/GLM-4.5-Air",
    "Mixtral 8x7B Instruct (HF)": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "DeepSeek R1 (HF)":           "deepseek-ai/DeepSeek-R1",
}

def api_config_for_provider(provider: str):
    if provider == "OpenRouter":
        return (
            "https://openrouter.ai/api/v1/chat/completions",
            st.secrets.get("OPENROUTER_API_KEY", ""),
            MODELOS_OPENROUTER,
        )
    elif provider == "Hugging Face":
        return (
            "HF_CLIENT",
            st.secrets.get("HUGGINGFACE_API_KEY", ""),
            MODELOS_HF,
        )
    else:
        return (
            "https://api.together.xyz/v1/chat/completions",
            st.secrets.get("TOGETHER_API_KEY", ""),
            MODELOS_TOGETHER_UI,
        )

def model_id_for_together(api_ui_model_id: str) -> str:
    key = (api_ui_model_id or "").strip()
    if "Qwen3-Coder-480B-A35B-Instruct-FP8" in key:
        return "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"
    low = key.lower()
    if low.startswith("mistralai/mixtral-8x7b-instruct-v0.1"):
        return "mistralai/Mixtral-8x7B-Instruct-V0.1"
    return key or "mistralai/Mixtral-8x7B-Instruct-v0.1"

# =========================
# GOOGLE SHEETS
# =========================

def conectar_planilha():
    try:
        creds_dict = json.loads(st.secrets["GOOGLE_CREDS_JSON"])
        if "private_key" in creds_dict:
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive",
        ]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        spreadsheet_id = st.secrets.get("SPREADSHEET_ID", "").strip() or PLANILHA_ID_PADRAO
        return client.open_by_key(spreadsheet_id)
    except Exception as e:
        st.error(f"Erro ao conectar √† planilha: {e}")
        return None

planilha = conectar_planilha()

def _ws(name: str, create_if_missing: bool = True):
    if not planilha:
        return None
    try:
        return planilha.worksheet(name)
    except Exception:
        if not create_if_missing:
            return None
        try:
            ws = planilha.add_worksheet(title=name, rows=5000, cols=10)
            if name == TAB_INTERACOES:
                _retry_429(ws.append_row, ["timestamp", "role", "content"])
            return ws
        except Exception:
            return None

def _retry_429(callable_fn, *args, _retries=5, _base=0.6, **kwargs):
    for i in range(_retries):
        try:
            return callable_fn(*args, **kwargs)
        except APIError as e:
            msg = str(e)
            if "429" in msg or "quota" in msg.lower():
                time.sleep((_base * (2 ** i)) + random.uniform(0, 0.25))
                continue
            raise
    return callable_fn(*args, **kwargs)

@st.cache_data(ttl=45, show_spinner=False)
def _sheet_all_records_cached(sheet_name: str):
    ws = _ws(sheet_name, create_if_missing=False)
    if not ws:
        return []
    return _retry_429(ws.get_all_records)

# =========================
# HIST√ìRICO DE TURNOS
# =========================

def carregar_interacoes(n: int = 20):
    """Carrega as intera√ß√µes recentes de TAB_INTERACOES."""
    cache = st.session_state.get("_cache_interacoes", None)
    if cache is None:
        regs = _sheet_all_records_cached(TAB_INTERACOES)
        norm = []
        for r in regs:
            norm.append({
                "timestamp": (r.get("timestamp") or "").strip(),
                "role": (r.get("role") or "user").strip(),
                "content": (r.get("content") or "").strip(),
            })
        st.session_state["_cache_interacoes"] = norm
        cache = norm
    return cache[-n:] if len(cache) > n else cache

def salvar_interacao(role: str, content: str):
    """Salva uma intera√ß√£o (turno)."""
    if not planilha:
        return
    try:
        aba = _ws(TAB_INTERACOES)
        if not aba:
            return
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        row = [timestamp, f"{role or ''}".strip(), f"{content or ''}".strip()]
        _retry_429(aba.append_row, row, value_input_option="RAW")
        lst = st.session_state.get("_cache_interacoes")
        if isinstance(lst, list):
            lst.append({"timestamp": timestamp, "role": row[1], "content": row[2]})
        else:
            st.session_state["_cache_interacoes"] = [{"timestamp": timestamp, "role": row[1], "content": row[2]}]
        _invalidate_sheet_caches()
    except Exception as e:
        st.error(f"Erro ao salvar intera√ß√£o: {e}")

# ---------------------------------------------
# VIRGINDADE ‚Äî leitura memoria_jm + fallback (interacoes_jm) e infer√™ncia temporal
# ---------------------------------------------
from typing import Optional, Tuple, List, Dict
import re
from datetime import datetime

# Padr√µes (priorize "n√£o virgem" sobre "virgem")
PADROES_NAO_VIRGEM = [
    r"\b(n[a√£]o\s+sou\s+mais\s+virgem)\b",
    r"\b(deix(ei|ou)\s+de\s+ser\s+virgem)\b",
    r"\b(perd[ei]u?\s+a\s+virgindade)\b",
    r"\b(minha|sua|nossa)\s+primeira\s+vez\s+(foi|aconteceu|rolou)\b",
    r"\b(tivemos|tive)\s+(a\s+)?primeira\s+vez\b",
]
PADROES_VIRGEM = [
    r"\b(sou|era|continuo?|permane[c√ß]o)\s+virgem\b",
    r"\b(nunca\s+(tran(s|√ß)ei|fiz\s+sexo|tive\s+rela[c√ß][o√µ]es))\b",
    r"\b(virgindade)\b(?!\s*(perd[i√≠]|\bn[a√£]o\b))",
]

def _to_dt(ts: str) -> Optional[datetime]:
    """Converte timestamp em datetime."""
    ts = (ts or "").strip()
    for fmt in ("%Y-%m-%d %H:%M:%S", "%Y-%m-%d", "%d/%m/%Y %H:%M:%S", "%d/%m/%Y %H:%M", "%d/%m/%Y"):
        try:
            return datetime.strptime(ts, fmt)
        except Exception:
            pass
    return None

def _ultimo_evento_virgindade_memoria(ate: Optional[datetime] = None) -> Optional[Tuple[bool, datetime, str]]:
    """
    Busca evid√™ncia em memoria_jm (tags [mary] e [all]), priorizando perda de virgindade.
    Retorna (estado_bool, timestamp, 'memoria_jm')
    """
    try:
        buckets = carregar_memorias_brutas()  # {'[tag]': [{'conteudo','timestamp'}, ...]}
    except Exception:
        buckets = {}
    candidatos: List[Tuple[bool, datetime]] = []
    ate = ate or datetime.now()
    for tag in ("[mary]", "[all]"):
        for item in buckets.get(tag, []) or []:
            txt = (item.get("conteudo") or "").strip()
            ts = _to_dt(item.get("timestamp"))
            if ts and ts > ate:
                continue
            low = txt.lower()
            if any(re.search(p, low, re.IGNORECASE) for p in PADROES_NAO_VIRGEM):
                candidatos.append((False, ts or datetime.min))
            elif any(re.search(p, low, re.IGNORECASE) for p in PADROES_VIRGEM):
                candidatos.append((True, ts or datetime.min))
    if not candidatos:
        return None
    # Mais recente, False (n√£o virgem) vence empate
    candidatos.sort(key=lambda x: (x[1], 0 if x[0] is False else 1))
    estado, ts = candidatos[-1]
    return (estado, ts, "memoria_jm")

def _ultimo_evento_virgindade_interacoes(ate: Optional[datetime] = None) -> Optional[Tuple[bool, datetime, str]]:
    """
    Fallback: busca padr√£o nas √∫ltimas intera√ß√µes (interacoes_jm).
    Retorna (estado_bool, timestamp, 'interacoes_jm')
    """
    ate = ate or datetime.now()
    inter = carregar_interacoes(n=20)
    if not inter:
        return None
    candidatos: List[Tuple[bool, datetime]] = []
    for r in inter:
        ts = _to_dt(r.get("timestamp"))
        if ts and ts > ate:
            continue
        low = (r.get("content") or "").strip().lower()
        if any(re.search(p, low, re.IGNORECASE) for p in PADROES_NAO_VIRGEM):
            candidatos.append((False, ts or datetime.min))
        elif any(re.search(p, low, re.IGNORECASE) for p in PADROES_VIRGEM):
            candidatos.append((True, ts or datetime.min))
    if not candidatos:
        return None
    candidatos.sort(key=lambda x: (x[1], 0 if x[0] is False else 1))
    estado, ts = candidatos[-1]
    return (estado, ts, "interacoes_jm")

def estado_virgindade_ate(ate: Optional[datetime] = None) -> Optional[bool]:
    """
    Determina status can√¥nico de virgindade para uso no prompt.
    True  -> virgem
    False -> n√£o virgem
    None  -> desconhecido (sem evid√™ncias)
    """
    ate = ate or datetime.now()
    res = _ultimo_evento_virgindade_memoria(ate)
    if res is None:
        res = _ultimo_evento_virgindade_interacoes(ate)
    return None if res is None else res[0]

# =========================
# MEM√ìRIA LONGA (opcional simples)
# =========================

def memoria_longa_listar_registros():
    try:
        return _sheet_all_records_cached(TAB_ML)
    except Exception:
        return []

def memoria_longa_salvar(texto: str, tags: str = "") -> bool:
    aba = _ws(TAB_ML, create_if_missing=False)
    if not aba:
        return False
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    linha = [texto.strip(), "", (tags or "").strip(), ts, 1.0]
    try:
        _retry_429(aba.append_row, linha, value_input_option="RAW")
        _invalidate_sheet_caches()
        return True
    except Exception:
        return False

def memoria_longa_buscar_topk(query_text: str, k: int = 3, limiar: float = 0.78, ate_ts=None):
    try:
        dados = _sheet_all_records_cached(TAB_ML)
    except Exception:
        return []
    def _tok(s): return set(re.findall(r"[a-z√†-√∫0-9]+", (s or "").lower()))
    s2 = _tok(query_text)
    cands = []
    for row in dados:
        texto = (row.get("texto") or "").strip()
        if not texto:
            continue
        row_ts = (row.get("timestamp") or "").strip()
        if ate_ts and row_ts and row_ts > ate_ts:
            continue
        s1 = _tok(texto)
        sim = len(s1 & s2) / max(1, len(s1 | s2))
        try:
            score = float(row.get("score", 1.0) or 1.0)
        except Exception:
            score = 1.0
        if sim >= limiar:
            rr = 0.7*sim + 0.3*score
            cands.append((texto, score, sim, rr))
    cands.sort(key=lambda x: x[3], reverse=True)
    return cands[:k]

def memoria_longa_reforcar(textos_usados: list):
    aba = _ws(TAB_ML, create_if_missing=False)
    if not aba or not textos_usados:
        return
    try:
        dados = _sheet_all_values_cached(TAB_ML)
        if not dados or len(dados) < 2:
            return
        headers = dados[0]
        idx_texto = headers.index("texto")
        idx_score = headers.index("score")
        for i, linha in enumerate(dados[1:], start=2):
            if len(linha) <= max(idx_texto, idx_score):
                continue
            t = (linha[idx_texto] or "").strip()
            if t in textos_usados:
                try:
                    sc = float(linha[idx_score] or 1.0)
                except Exception:
                    sc = 1.0
                sc = min(sc + 0.2, 2.0)
                _retry_429(aba.update_cell, i, idx_score + 1, sc)
        _invalidate_sheet_caches()
    except Exception:
        pass


# =========================
# REGRAS DE FASE (APENAS FASE)
# =========================

FASES_ROMANCE: Dict[int, Dict[str, str]] = {
    0: {"nome": "Estranhos",
        "permitidos": "olhares; near-miss (mesmo caf√©/rua/√¥nibus); detalhe do ambiente",
        "proibidos": "troca de nomes; toques; conversa pessoal; beijo"},
    1: {"nome": "Percep√ß√£o",
        "permitidos": "cumprimento neutro; pergunta impessoal curta; beijo no rosto",
        "proibidos": "beijo na boca; confid√™ncias"},
    2: {"nome": "Conhecidos",
        "permitidos": "troca de nomes; pequena ajuda; 1 pergunta pessoal leve; beijo suave na boca",
        "proibidos": "toque prolongado; encontro a s√≥s planejado"},
    3: {"nome": "Romance",
        "permitidos": "conversa 10‚Äì20 min; caminhar juntos; trocar contatos; beijos intensos (sem car√≠cias √≠ntimas)",
        "proibidos": "car√≠cias √≠ntimas; tirar roupas"},
    4: {"nome": "Namoro",
        "permitidos": "beijos intensos; car√≠cias √≠ntimas; **sem cl√≠max** at√© usu√°rio liberar",
        "proibidos": "sexo expl√≠cito sem consentimento claro"},
    5: {"nome": "Compromisso / Encontro definitivo",
        "permitidos": "beijos intensos; car√≠cias √≠ntimas; sexo com consentimento; **cl√≠max somente se usu√°rio liberar**",
        "proibidos": ""},
}
FLAG_FASE_TXT_PREFIX = "FLAG: mj_fase="

def _fase_label(n: int) -> str:
    d = FASES_ROMANCE.get(int(n), FASES_ROMANCE)
    return f"{int(n)} ‚Äî {d['nome']}"

def mj_set_fase(n: int, persist: bool=False):
    n = max(0, min(max(FASES_ROMANCE.keys()), int(n)))
    st.session_state.mj_fase = n
    if persist:
        try:
            memoria_longa_salvar(f"{FLAG_FASE_TXT_PREFIX}{n}", tags="[flag]")
        except Exception:
            pass

def mj_carregar_fase_inicial() -> int:
    if "mj_fase" in st.session_state:
        return int(st.session_state.mj_fase)
    try:
        recs = memoria_longa_listar_registros()
        for r in reversed(recs):
            t = (r.get("texto") or "").strip()
            if t.startswith(FLAG_FASE_TXT_PREFIX):
                n = int(t.split("=")[1])
                st.session_state.mj_fase = n
                return n
    except Exception:
        pass
    st.session_state.mj_fase = 0
    return 0


# =========================
# FALAS DA MARY (BRANDAS) + PLANILHA
# =========================

FALAS_EXPLICITAS_MARY = [
    "Vem mais perto, sem pressa.",
    "Assim est√° bom‚Ä¶ continua desse jeito.",
    "Eu quero sentir voc√™ devagar.",
    "Fica comigo, s√≥ mais um pouco.",
]

def carregar_falas_mary() -> List[str]:
    try:
        ws = _ws(TAB_FALAS_MARY, create_if_missing=False)
        if not ws:
            return []
        rows = _sheet_all_records_cached(TAB_FALAS_MARY)
        falas = []
        for r in rows:
            fala = (r.get("fala") or "").strip()
            if fala:
                falas.append(fala)
        return falas or []
    except Exception:
        return []


# =========================
# AJUSTES DE TOM / SINTONIA
# =========================
import re, random

import re, random

def gerar_mary_sensorial(level: int = 2, n: int = 2, hair_on: bool = True, sintonia: bool = True) -> str:
    if level <= 0 or n <= 0:
        return ""

    # Frases SEM cen√°rio/clima/met√°foras
    base_leve = [
        "Os cabelos de Mary ‚Äî negros, volumosos, levemente ondulados ‚Äî acompanham o passo.",
        "O olhar de Mary √© firme e sereno; a respira√ß√£o, tranquila.",
        "H√° calor discreto no perfume que ela deixa no ar.",
        "O sorriso surge pequeno, sincero e atento.",
    ]
    base_marcado = [
        "O tecido ro√ßa levemente nas pernas; o passo √© seguro, cadenciado.",
        "Os ombros relaxam quando ela encontra o olhar de J√¢nio.",
        "A pele arrepia sutil ao menor toque.",
        "O olhar de Mary segura o dele por um instante a mais.",
    ]
    base_ousado = [
        "O ritmo do corpo de Mary √© deliberado; chama sem exigir.",
        "O perfume na clav√≠cula convida a aproxima√ß√£o.",
        "Os l√°bios entreabertos, esperando o momento certo.",
        "O olhar pousa e permanece, pedindo gentileza.",
    ]

    if level == 1:
        pool = list(base_leve)
    elif level == 2:
        pool = list(base_leve) + list(base_marcado)
    else:
        pool = list(base_leve) + list(base_marcado) + list(base_ousado)

    # Filtro extra contra clima/paisagem
    termos_banidos = re.compile(
        r"\b(c[√©e]u|mar|onda?s?|vento|brisa|chuva|nublado|luar|horizonte|pier|paisage?m|cen[√°a]rio|amanhecer|entardecer|p[√¥o]r do sol)\b",
        re.IGNORECASE,
    )
    pool = [f for f in pool if not termos_banidos.search(f)]

    if sintonia:
        filtros = [r"\bexigir\b"]
        def _ok(fr): return not any(re.search(p, fr, re.I) for p in filtros)
        pool = [f for f in pool if _ok(f)]
        pool.extend([
            "A respira√ß√£o de Mary busca o mesmo compasso de J√¢nio.",
            "Ela desacelera e deixa o momento guiar.",
            "O toque come√ßa suave, sem precipita√ß√£o.",
        ])

    n_eff = max(1, min(n, len(pool)))
    frases = random.sample(pool, k=n_eff) if pool else []

    if hair_on:
        hair_line = "Os cabelos negros, volumosos e levemente ondulados moldam o rosto quando ela vira de leve."
        if hair_line not in frases:
            frases.insert(0, hair_line)
            if len(frases) > n_eff:
                frases = frases[:n_eff]
    return " ".join(frases)


def _last_user_text(hist):
    if not hist:
        return ""
    for r in reversed(hist):
        if str(r.get("role","")).lower() == "user":
            return r.get("content","")
    return ""

def _deduzir_ancora(texto: str) -> dict:
    t = (texto or "").lower()
    if "motel" in t or "su√≠te" in t or "suite" in t:
        return {"local": "Motel ‚Äî Su√≠te", "hora": "noite"}
    if "quarto" in t:
        return {"local": "Quarto", "hora": "noite"}
    if "praia" in t:
        return {"local": "Praia", "hora": "fim de tarde"}
    if "bar" in t or "pub" in t:
        return {"local": "Bar", "hora": "noite"}
    if "biblioteca" in t:
        return {"local": "Biblioteca", "hora": "tarde"}
    return {}


def inserir_regras_mary_e_janio(prompt_base: str) -> str:
    calor = int(st.session_state.get("nsfw_max_level", 0))
    regras = f"""
‚öñÔ∏è Regras de coer√™ncia:
- Narre em terceira pessoa; n√£o se dirija ao leitor como "voc√™".
- Consentimento claro antes de qualquer gesto significativo.
- Mary prefere ritmo calmo, sintonizado com o parceiro (modo harm√¥nico ativo).
- Linguagem sensual proporcional ao n√≠vel de calor ({calor}).
- Proibido natureza/ambiente/clima/met√°foras (c√©u, mar, vento, ondas, luar, paisagem etc.).
- Sem ‚Äúfade to black‚Äù: a progress√£o √© mostrada, mas sem pornografia expl√≠cita.
""".strip()
    return prompt_base + "\n" + regras


# =========================
# VIRGINDADE (opcional)
# =========================

def detectar_virgindade_mary(memos: dict, ate_ts: str) -> bool:
    for d in memos.get("[mary]", []):
        c = (d.get("conteudo") or "").lower()
        ts = (d.get("timestamp") or "")
        if ts and ate_ts and ts > ate_ts:
            continue
        if "sou virgem" in c or "virgindade" in c or "nunca fiz" in c:
            return True
    return False

def montar_bloco_virgindade(ativar: bool) -> str:
    if not ativar:
        return ""
    return (
        "### Nota de virgindade (prioridade)\n"
        "- Mary valoriza sua primeira vez. O ritmo √© cuidadoso, com comunica√ß√£o clara.\n"
        "- Evite pressa; foco em respeito, confian√ßa e conforto.\n"
    )

def prompt_da_cena(ctx: dict | None = None, modo_finalizacao: str = "ponte") -> str:
    ctx = ctx or {}
    tempo    = (ctx.get("tempo") or "").strip().rstrip(".")
    lugar    = (ctx.get("lugar") or "").strip().rstrip(".")
    figurino = (ctx.get("figurino") or "").strip().rstrip(".")

    # Monta a 1¬™ linha (permitida pela exce√ß√£o)
    pedacos = []
    if tempo: pedacos.append(tempo.capitalize())
    pedacos.append(f"Mary{(', ' + figurino) if figurino else ''}".strip())
    if lugar: pedacos.append(lugar)
    primeira_linha = ". ".join([p for p in pedacos if p]) + "."

    # Regras de fechamento
    modo = (modo_finalizacao or "ponte").lower()
    if modo == "eu":
        regra_fim = "- Feche com 1 frase curta em 1¬™ pessoa (Mary), conectando o pr√≥ximo gesto."
    elif modo == "seco":
        regra_fim = "- Termine sem gancho, frase final objetiva."
    else:  # ponte
        regra_fim = "- Feche com micro-a√ß√£o que deixe gancho natural para continua√ß√£o, sem concluir a cena."

    return (
        "### Diretrizes de abertura e fechamento\n"
        "- Comece com UMA linha: Tempo. Mary[, figurino]. [Lugar]. (somente se houver dados; caso contr√°rio, pule)\n"
        "- Em seguida, entre direto em a√ß√£o e di√°logo, focada na DIRETIVA do usu√°rio.\n"
        f"{regra_fim}\n"
        f"ABERTURA_SUGERIDA: {primeira_linha if primeira_linha != '.' else ''}\n"
    )

# =========================
# PROMPT BUILDER (APENAS FASE) ‚Äî compat√≠vel com Modo Mary
# =========================

def construir_prompt_com_narrador() -> str:
    BLOCO_ROLEPLAY = """
OBRIGAT√ìRIO ‚Äî FORMATO ESTRUTURADO DE ROLEPLAY

- Cada fala ("‚Äî") deve come√ßar linha nova isolada, SEMPRE seguida ou precedida de bloco de a√ß√£o/descri√ß√£o corporal.
- Nunca una mais de 2 frases no mesmo par√°grafo narrativo; em narra√ß√£o, troque de linha a cada a√ß√£o/rea√ß√£o f√≠sica importante.
- O texto final sempre ter√° par√°grafos curtos: bloco de a√ß√£o (m√°x. 2 frases), bloco de fala, bloco de rea√ß√£o, bloco de fala. Nunca prosa longa.
- N√ÉO formate como prosa de romance/livro; sempre como roteiro estruturado de roleplay moderno e comercial.
""".strip()

    BLOCO_RESTRICAO_SENSORY = """
Conduza como romance contempor√¢neo: descreva a√ß√µes, sensa√ß√µes, di√°logos de forma rica, emotiva e natural, incluindo cen√°rios, introspec√ß√µes leves e clima emocional.
Di√°logos podem aparecer intercalados com narra√ß√£o, integrados em par√°grafos maiores quando pertinente.
Jamais use in√≠cio seco tipo 'Parque da cidade.' nem fechos como 'um sil√™ncio el√©trico preenche o quarto'.
"""


...
""".strip()

    ctx = st.session_state.get("ctx_cena", {})
    try:
        voz_bloco = instrucao_llm(st.session_state.get("finalizacao_modo", "ponto de gancho"), ctx)
    except Exception:
        voz_bloco = prompt_da_cena(ctx, st.session_state.get("finalizacao_modo", "ponte"))
    cena_bloco = prompt_da_cena(ctx, st.session_state.get("finalizacao_modo", "ponte"))

    # Sanitizador leve de hist√≥rico (sem praia/clima)
    import re
    _split = re.compile(r'(?<=[\.\!\?])\s+')
    _amb = re.compile(
        r'\b(c[√©e]u|nuvens?|horizonte|luar|mar|onda?s?|pier|praia|vento|brisa|chuva|garoa|sereno|amanhecer|entardecer|p[√¥o]r do sol|paisage?m|cen[√°a]rio|temperatura|ver√£o|quiosques?)\b',
        re.I
    )

    def _hist_sanitizado(hist):
        L = []
        for r in hist or []:
            role = r.get("role", "user")
            txt = (r.get("content") or "").strip()
            if not txt:
                continue
            s = [t for t in _split.split(txt) if t.strip() and not _amb.search(t)]
            if s:
                L.append(f"{role}: {' '.join(s)[:900]}")
        return "\n".join(L) if L else "(sem hist√≥rico)"

    memos = carregar_memorias_brutas()
    perfil = carregar_resumo_salvo()
    fase = int(st.session_state.get("mj_fase", mj_carregar_fase_inicial()))
    fdata = FASES_ROMANCE.get(fase, FASES_ROMANCE[0])
    modo_mary = bool(st.session_state.get("interpretar_apenas_mary", False))

    _sens_on = bool(st.session_state.get("mary_sensorial_on", True))
    _sens_level = int(st.session_state.get("mary_sensorial_level", 2))
    _sens_n = int(st.session_state.get("mary_sensorial_n", 2))
    mary_sens_txt = (
        gerar_mary_sensorial(_sens_level, n=_sens_n, sintonia=bool(st.session_state.get("modo_sintonia", True)))
        if _sens_on
        else ""
    )

    ritmo_cena = int(st.session_state.get("ritmo_cena", 0))
    ritmo_label = ["muito lento", "lento", "m√©dio", "r√°pido"][max(0, min(3, ritmo_cena))]
    modo_sintonia = bool(st.session_state.get("modo_sintonia", True))

    n_hist = int(st.session_state.get("n_sheet_prompt", 15))
    hist = carregar_interacoes(n=n_hist)
    hist_txt = _hist_sanitizado(hist)
    ultima_fala_user = _last_user_text(hist)

    ancora_bloco = ""
    ate_ts = _parse_ts(hist[-1].get("timestamp", "")) if hist else datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    ml_topk_txt = "(nenhuma)"
    st.session_state["_ml_topk_texts"] = []
    if st.session_state.get("use_memoria_longa", True) and hist:
        try:
            topk = memoria_longa_buscar_topk(
                query_text=hist[-1]["content"],
                k=int(st.session_state.get("k_memoria_longa", 3)),
                limiar=float(st.session_state.get("limiar_memoria_longa", 0.78)),
                ate_ts=ate_ts,
            )
            if topk:
                ml_topk_txt = "\n".join([f"- {t}" for (t, *_rest) in topk])
                st.session_state["_ml_topk_texts"] = [t for (t, *_r) in topk]
        except Exception:
            st.session_state["_ml_topk_texts"] = []

    memos_all = [
        (d.get("conteudo") or "").strip()
        for d in memos.get("[all]", [])
        if isinstance(d, dict) and d.get("conteudo") and (not d.get("timestamp") or d.get("timestamp") <= ate_ts)
    ]
    st.session_state["_ml_recorrentes"] = memos_all

    dossie = []
    m = persona_block_temporal("mary", memos, ate_ts, 8)
    j = persona_block_temporal("janio", memos, ate_ts, 8)
    if m:
        dossie.append(m)
    if j:
        dossie.append(j)
    dossie_txt = "\n\n".join(dossie) if dossie else "(sem personas definidas)"

    falas_mary_bloco = ""
    st.session_state["_falas_mary_list"] = []
    if st.session_state.get("usar_falas_mary", False):
        falas = carregar_falas_mary() or FALAS_EXPLICITAS_MARY
        if falas:
            st.session_state["_falas_mary_list"] = falas[:]
            falas_mary_bloco = (
                "### Falas de Mary ‚Äî use literalmente 1‚Äì2 destas (no m√°ximo 1 por par√°grafo)\n"
                "N√ÉO reescreva as frases abaixo; quando usar, mantenha exatamente como est√°.\n"
                + "\n".join(f"- {s}" for s in falas)
            )

    sintonia_bloco = ""
    if modo_sintonia:
        sintonia_bloco = (
            "### Sintonia & Ritmo (priorit√°rio)\n"
            f"- Ritmo da cena: **{ritmo_label}**.\n"
            "- Condu√ß√£o harm√¥nica: Mary sintoniza com o parceiro; evite ordens r√≠spidas/imperativas. Prefira convites e pedidos gentis.\n"
            "- Pausas e respira√ß√£o contam; mostre desejo pela troca, n√£o por imposi√ß√£o.\n"
        )

    try:
        _ref_dt = _to_dt(ate_ts) if ("_to_dt" in globals() or "_to_dt" in dir()) else None
        est = estado_virgindade_ate(_ref_dt)
        if est is True:
            virg_bloco = (
                "### Estado can√¥nico ‚Äî Virgindade\n"
                "- Mary √© **virgem** neste momento da hist√≥ria.\n"
                "- Mantenha coer√™ncia: sem hist√≥rico de penetra√ß√£o; se houver explora√ß√£o √≠ntima, trate como **primeira descoberta**, cuidadosa e sem contradi√ß√µes.\n"
            )
        elif est is False:
            virg_bloco = (
                "### Estado can√¥nico ‚Äî Virgindade\n"
                "- Mary **n√£o √© mais virgem** (evento passado registrado).\n"
                "- N√£o reescreva o passado; mantenha consist√™ncia com a cena que marcou a primeira vez.\n"
            )
        else:
            virg_bloco = (
                "### Estado can√¥nico ‚Äî Virgindade\n"
                "- **Sem evid√™ncia temporal** suficiente: **n√£o** afirme que √© a primeira vez e **n√£o** invente perda de virgindade.\n"
            )
    except Exception:
        virg_bloco = (
            "### Estado can√¥nico ‚Äî Virgindade\n"
            "- Falha ao ler o estado; **evite** afirmar status e **n√£o** contradiga cenas anteriores.\n"
        )

    climax_bloco = ""
    if bool(st.session_state.get("app_bloqueio_intimo", True)) and fase < 5:
        climax_bloco = (
            "### Prote√ß√£o de avan√ßo √≠ntimo (ATIVA)\n"
            "- **Sem cl√≠max por padr√£o**: n√£o descreva orgasmo/finaliza√ß√£o **a menos que o usu√°rio tenha liberado explicitamente na mensagem anterior**.\n"
            "- Encerre em **pausa sensorial** (respira√ß√£o, sil√™ncio, carinho), **sem** 'fade-to-black'.\n"
        )

    if modo_mary:
        papel_header = "Voc√™ √© **Mary**, responda **em primeira pessoa**, sem narrador externo. Use apenas o que Mary v√™/sente/ouve. N√£o descreva pensamentos de J√¢nio. N√£o use t√≠tulos nem repita instru√ß√µes."
        regra_saida = "- Narre **em primeira pessoa (eu)** como Mary; nunca use narrador onisciente.\n- Produza uma cena fechada e natural, sem coment√°rios externos."
        formato_cena = (
            "- DI√ÅLOGOS diretos com travess√£o (‚Äî), intercalados com a√ß√£o/rea√ß√£o **em 1¬™ pessoa (Mary)**."
        )
    else:
        papel_header = "Voc√™ √© o **Narrador** de um roleplay dram√°tico brasileiro; foque em Mary e J√¢nio. N√£o repita instru√ß√µes nem t√≠tulos."
        regra_saida = "- Narre **em terceira pessoa**; nunca fale com 'voc√™'.\n- Produza uma cena fechada e natural, sem coment√°rios externos."
        formato_cena = "- DI√ÅLOGOS diretos com travess√£o (‚Äî), intercalados com a√ß√£o/rea√ß√£o f√≠sica/visual."
        climax_bloco += (
            "### Regra permanente de cl√≠max\n"
            "- **N√£o** descreva orgasmo/ejacula√ß√£o/cl√≠max **sem libera√ß√£o expl√≠cita na √öLTIMA fala do usu√°rio**.\n"
            "- Se n√£o houver libera√ß√£o, pare no **limiar**: respira√ß√£o, tremor, pausa; **sem finalizar**.\n"
            "- **Sem fade-to-black** em qualquer circunst√¢ncia.\n"
        )


   prompt = f"""
{BLOCO_RESTRICAO_SENSORY}
{voz_bloco}
{cena_bloco}
{papel_header}
{ancora_bloco}{sintonia_bloco}{virg_bloco}{climax_bloco}{falas_mary_bloco}
### Dossi√™ (personas)
{dossie_txt}
### Diretrizes gerais (ALL)
{chr(10).join(f"- {c}" for c in memos_all) if memos_all else "(vazio)"}
### Perfil (resumo mais recente)
{perfil or "(vazio)"}
### Hist√≥rico recente (sanitizado)
{hist_txt}
### BLOCO DE ESTILO E TOM ‚Äî ROLEPLAY SENSORIAL

- N√£o descreva cen√°rio, natureza, ambiente, temperatura, clima, praia, quiosques, ver√£o, paisagem ou localiza√ß√£o em nenhum momento. PROIBIDO iniciar cena com tempo, lugar ou natureza.

- Cada turno da resposta deve obrigatoriamente incluir sensa√ß√£o corporal e visual de Mary: curvas naturais, seios, quadris, boca, coxas, gestos sedutores, calor f√≠sico, tens√£o, suor, desejo, pele, rea√ß√µes f√≠sicas e troca de olhares. Escreva sempre o efeito do olhar e dos gestos do par sobre o corpo de Mary.

- Descreva as rea√ß√µes f√≠sicas intensas de Mary: peito arfando, seios balan√ßando, quadris se movendo, m√∫sculos tensionando, pele arrepiando, corpo se inclinando, respira√ß√£o acelerada, boca entreaberta, l√°bios √∫midos, m√£os deslizando pela roupa ou corpo, gemidos, suspiros, movimentos provocantes. Jamais apenas "pensamento" ou "emo√ß√£o", sempre efeito f√≠sico vis√≠vel.

- Use di√°logos alternados e a√ß√µes entre os personagens. Comece e termine com ganchos f√≠sicos/visuais: gesto, aproxima√ß√£o, olhar, toque, convite, microa√ß√£o. Jamais feche uma cena com frases clich√™ como "A tens√£o fica no ar‚Ä¶", "Um sil√™ncio el√©trico‚Ä¶", "Eles param no limiar‚Ä¶" ou qualquer varia√ß√£o parecida.

- Par√°grafos devem ser curtos (at√© 3 frases cada), com linhas em branco entre cada bloco de frase/fala. Nunca agrupe textos longos nem explique o contexto; sempre priorize o momento presente, corpo-a-corpo, sem retrospectiva, sem ambienta√ß√£o.

- Nunca descreva tempo ("Domingo de manh√£"), nunca local ("Praia de Jacara√≠pe"), nunca ambiente ("areias quentes", "vento", "c√©u azul", "quiosques"). Proibido met√°fora, poesia ambiental, ou qualquer men√ß√£o impl√≠cita de natureza/cen√°rio.

- Quando Mary se move, sempre explicitamente cite curvas, seios, quadris, boca, cabelo, toque, calor e rea√ß√£o f√≠sica. Se o usu√°rio der uma ordem ou dire√ß√£o, Mary sempre reage com gesto f√≠sico e fala conectando o desejo expl√≠cito do momento.

- Nunca fa√ßa pausas narrativas, n√£o explique ou analise. Apenas descreva a√ß√£o f√≠sica, rea√ß√£o corporal e di√°logo r√°pido.

- Se usar falas fixas da Mary, sempre intercale com a√ß√£o corporal, nunca use s√≥ fala.

- Se n√£o puder avan√ßar por limita√ß√£o de fase, encerre com microa√ß√£o f√≠sica de tens√£o, mas nunca diga "a tens√£o fica no ar".

- Proibido mon√≥logo introspectivo ou pensamento maior que uma frase. Priorize sempre calor, desejo, corpo, gra√ßa e sensualidade natural do encontro.

- Escreva apenas o momento imediato; nunca use frases de abertura como "Naquela manh√£‚Ä¶", "No fim de tarde‚Ä¶", "No bar‚Ä¶", "Ao entardecer‚Ä¶", "Na praia‚Ä¶", "Enquanto o vento soprava‚Ä¶", "Ela caminhava pelas areias‚Ä¶".

- Este √© um roleplay comercial e engajante, n√£o uma novela nem conto liter√°rio. O texto deve ser sempre vivo, sensual, direto, curto e visual.

### FIM DO BLOCO DE ESTILO SENSORIAL
### Camada sensorial ‚Äî Mary (OBRIGAT√ìRIA no 1¬∫ par√°grafo)
{mary_sens_txt or "- Apenas sensa√ß√µes f√≠sicas, nunca ambiente."}
### Mem√≥ria longa ‚Äî Top-K relevantes
{ml_topk_txt}
### ‚è±Ô∏è Estado do romance (manual)
- Fase atual: {_fase_label(fase)}
- Siga **somente** as regras da fase (permitidos/proibidos) abaixo:
- Permitidos: {fdata['permitidos']}
- Proibidos: {fdata['proibidos']}
### Geografia & Montagem
- N√£o force coincid√™ncias. Sem teletransporte.
### Formato OBRIGAT√ìRIO da cena
{formato_cena}
### Regra de sa√≠da
{regra_saida}
""".strip()

prompt = inserir_regras_mary_e_janio(prompt)
return prompt


import re

# --- Remo√ß√£o de termos de paisagem/clima ---
SCENERY_TERMS = [
    r"c[√©e]u", r"nuvens?", r"horizonte", r"luar",
    r"mar", r"onda?s?", r"pier",
    r"vento", r"brisa", r"neblina|brumas?",
    r"chuva|garoa|sereno",
    r"amanhecer|entardecer|crep[u√∫]sculo|p[√¥o]r do sol",
    r"paisage?m|cen[√°a]rio",
    r"luz\s+do\s+luar", r"som\s+das?\s+ondas?"
]
SCENERY_WORD = re.compile(r"\b(" + "|".join(SCENERY_TERMS) + r")\b", re.IGNORECASE)

def sanitize_scenery(text: str) -> str:
    """Remove termos de natureza/clima definidos em SCENERY_WORD do texto."""
    if not text:
        return ""
    return SCENERY_WORD.sub("", text)

def sanitize_scenery_preserve_opening(t: str) -> str:
    """Remove natureza/clima, mas preserva a primeira linha intacta."""
    if not t:
        return ""
    linhas = t.strip().split('\n')
    if not linhas:
        return ""
    primeira_linha = linhas[0].strip()
    resto = '\n'.join(linhas[1:]).strip()
    if resto:
        resto_filtrado = sanitize_scenery(resto)
        return primeira_linha + ('\n' + resto_filtrado if resto_filtrado else '')
    return primeira_linha

def _render_visible(t: str) -> str:
    t = sanitize_scenery_preserve_opening(t)  # Preserva linha de abertura limpa
    t = roleplay_paragraphizer(t)             # Organiza par√°grafos e falas
    if st.session_state.get("app_bloqueio_intimo", True):
        t = sanitize_explicit(t, int(st.session_state.get("nsfw_max_level", 0)), action="soften")
    return t

def force_linebreak_on_falas(txt):
    """For√ßa quebra em toda fala iniciada por travess√£o em texto corrido."""
    return re.sub(r"([^\n])\s*(‚Äî)", r"\1\n\n\2", txt)

# --- Filtro de termos expl√≠citos de sexo ---
EXPL_PAT = re.compile(
    r"\b(mamilos?|genit[a√°]lia|ere[c√ß][a√£]o|penetra[c√ß][a√£]o|boquete|gozada|gozo|sexo oral|chupar|enfiar)\b",
    flags=re.IGNORECASE
)

def classify_nsfw_level(t: str) -> int:
    if EXPL_PAT.search(t or ""):
        return 3
    if re.search(r"\b(cintura|pesco[c√ß]o|costas|beijo prolongado|respira[c√ß][a√£]o curta)\b", (t or ""), re.I):
        return 2
    if re.search(r"\b(olhar|aproximar|toque|m[a√£]os dadas|beijo)\b", (t or ""), re.I):
        return 1
    return 0

def sanitize_explicit(t: str, max_level: int, action: str) -> str:
    """Corta ou suaviza respostas que excedem o n√≠vel permitido de NSFW."""
    lvl = classify_nsfw_level(t)
    if lvl <= max_level:
        return t
    # Adapte este bloco se quiser cortar ou substituir al√©m do recomendado
    return t  # N√£o aplica corte autom√°tico por padr√£o

def redact_for_logs(t: str) -> str:
    if not t:
        return ""
    t = re.sub(EXPL_PAT, "[‚Ä¶]", t, flags=re.I)
    return re.sub(r'\n{3,}', '\n\n', t).strip()

def resposta_valida(t: str) -> bool:
    """Verifica se h√° conte√∫do suficiente para ser considerado uma resposta v√°lida."""
    if not t or t.strip() == "[Sem conte√∫do]":
        return False
    if len(t.strip()) < 5:
        return False
    return True

# Exemplo de uso ap√≥s gerar resposta:
# visible_txt = force_linebreak_on_falas(_render_visible(resposta_txt).strip())

# =========================
# UI ‚Äî CABE√áALHO
# =========================

st.title("üé¨ Narrador JM ‚Äî Somente Fase")
st.subheader("Voc√™ √© o roteirista. Digite uma dire√ß√£o de cena. A IA narrar√° Mary e J√¢nio.")
st.markdown("---")

# =========================
# ESTADOS INICIAIS
# =========================

for k, v in {
    "resumo_capitulo": carregar_resumo_salvo(),
    "session_msgs": [],
    "use_memoria_longa": True,
    "k_memoria_longa": 3,
    "limiar_memoria_longa": 0.78,
    "app_bloqueio_intimo": True,
    "app_emocao_oculta": "nenhuma",
    "mj_fase": mj_carregar_fase_inicial(),
    "max_avancos_por_cena": 1,
    "estilo_escrita": "A√á√ÉO",
    "templates_jm": {},
    "template_ativo": None,
    "etapa_template": 0,
    "ctx_cena": dict(CTX_INICIAL),
    "finalizacao_modo": "ponto de gancho",
}.items():
    if k not in st.session_state:
        st.session_state[k] = v
# =========================
# SIDEBAR ‚Äî Reorganizado (apenas FASE)
# =========================

with st.sidebar:
    st.title("üß≠ Painel do Roteirista")
    
    # Provedor / modelos
    provedor = st.radio(
        "üåê Provedor",
        ["OpenRouter", "Together", "Hugging Face"],
        index=["OpenRouter", "Together", "Hugging Face"].index(st.session_state.get("provedor_ia", "OpenRouter")),
        key="provedor_ia"
    )
    api_url, api_key, modelos_map = api_config_for_provider(provedor)
    if not api_key:
        st.warning("‚ö†Ô∏è API key ausente para o provedor selecionado. Defina em st.secrets.")

    modelo_nome = st.selectbox(
        "ü§ñ Modelo de IA",
        list(modelos_map.keys()),
        index=list(modelos_map.keys()).index(next((k for k, v in modelos_map.items() if v == st.session_state.get("modelo_escolhido_id")), list(modelos_map.keys())[0])),
        key="modelo_nome_ui"
    )
    st.session_state.modelo_escolhido_id = modelos_map[modelo_nome]

    st.markdown("---")
    st.markdown("### ‚úçÔ∏è Estilo & Progresso Dram√°tico")

    # Modo de resposta (NARRADOR ou MARY 1¬™ pessoa)
    modo_op = st.selectbox(
        "Modo de resposta",
        ["Narrador padr√£o", "Mary (1¬™ pessoa)"],
        index=["Narrador padr√£o", "Mary (1¬™ pessoa)"].index(st.session_state.get("modo_resposta", "Narrador padr√£o")),
        key="modo_resposta"
    )
    st.session_state.interpretar_apenas_mary = (modo_op == "Mary (1¬™ pessoa)")

    st.selectbox(
        "Estilo de escrita",
        ["A√á√ÉO", "ROMANCE LENTO", "NOIR"],
        index=["A√á√ÉO", "ROMANCE LENTO", "NOIR"].index(st.session_state.get("estilo_escrita", "A√á√ÉO")),
        key="estilo_escrita"
    )

    st.slider("N√≠vel de calor (0=leve, 3=expl√≠cito)", 0, 3, value=int(st.session_state.get("nsfw_max_level", 0)), key="nsfw_max_level")

    st.checkbox(
        "Sintonia com o parceiro (modo harm√¥nico)",
        key="modo_sintonia",
        value=st.session_state.get("modo_sintonia", True)
    )

    st.select_slider(
        "Ritmo da cena",
        options=[0, 1, 2, 3],
        value=int(st.session_state.get("ritmo_cena", 0)),
        format_func=lambda n: ["muito lento", "lento", "m√©dio", "r√°pido"][n],
        key="ritmo_cena"
    )

    st.selectbox(
        "Finaliza√ß√£o",
        ["ponto de gancho", "fecho suave", "deixar no suspense"],
        index=["ponto de gancho", "fecho suave", "deixar no suspense"].index(st.session_state.get("finalizacao_modo", "ponto de gancho")),
        key="finalizacao_modo"
    )

    st.checkbox(
        "Usar falas da Mary da planilha (usar literalmente)",
        value=st.session_state.get("usar_falas_mary", False),
        key="usar_falas_mary"
    )

    st.markdown("---")
    st.markdown("### üíû Romance Mary & J√¢nio (apenas Fase)")
    fase_default = mj_carregar_fase_inicial()
    options_fase = sorted(FASES_ROMANCE.keys())
    fase_ui_val = int(st.session_state.get("mj_fase", fase_default))
    fase_ui_val = max(min(fase_ui_val, max(options_fase)), min(options_fase))
    fase_escolhida = st.select_slider(
        "Fase do romance",
        options=options_fase,
        value=fase_ui_val,
        format_func=_fase_label,
        key="ui_mj_fase"
    )
    if fase_escolhida != st.session_state.get("mj_fase", fase_default):
        mj_set_fase(fase_escolhida, persist=True)

    col_a, col_b = st.columns(2)
    with col_a:
        if st.button("‚ûï Avan√ßar 1 fase"):
            mj_set_fase(min(st.session_state.get("mj_fase", 0) + 1, max(options_fase)), persist=True)
    with col_b:
        if st.button("‚Ü∫ Reiniciar (0)"):
            mj_set_fase(0, persist=True)

    st.markdown("---")
    st.checkbox(
        "Evitar coincid√™ncias for√ßadas (montagem paralela A/B)",
        value=st.session_state.get("no_coincidencias", True),
        key="no_coincidencias"
    )
    st.checkbox(
        "Bloquear avan√ßos √≠ntimos sem ordem",
        value=st.session_state.get("app_bloqueio_intimo", True),
        key="app_bloqueio_intimo"
    )
    st.selectbox(
        "üé≠ Emo√ß√£o oculta",
        ["nenhuma", "tristeza", "felicidade", "tens√£o", "raiva"],
        index=["nenhuma", "tristeza", "felicidade", "tens√£o", "raiva"].index(st.session_state.get("app_emocao_oculta", "nenhuma")),
        key="ui_app_emocao_oculta"
    )
    st.session_state.app_emocao_oculta = st.session_state.get("ui_app_emocao_oculta", "nenhuma")

    st.markdown("---")
    st.markdown("### ‚è±Ô∏è Comprimento/timeout")
    st.slider("Max tokens da resposta", 256, 2500, value=int(st.session_state.get("max_tokens_rsp",1200)), step=32, key="max_tokens_rsp")
    st.slider("Timeout (segundos)", 60, 600, value=int(st.session_state.get("timeout_s", 300)), step=10, key="timeout_s")

    st.markdown("---")
    st.markdown("### üóÉÔ∏è Mem√≥ria Longa")
    st.checkbox("Usar mem√≥ria longa no prompt", value=st.session_state.get("use_memoria_longa", True), key="use_memoria_longa")
    st.slider("Top-K mem√≥rias", 1, 5, int(st.session_state.get("k_memoria_longa", 3)), 1, key="k_memoria_longa")
    st.slider("Limiar de similaridade", 0.50, 0.95, float(st.session_state.get("limiar_memoria_longa", 0.78)), 0.01, key="limiar_memoria_longa")

    st.markdown("### üß© Hist√≥rico no prompt")
    st.slider("Intera√ß√µes do Sheets (N)", 10, 30, value=int(st.session_state.get("n_sheet_prompt", 15)), step=1, key="n_sheet_prompt")

    st.markdown("---")
    st.markdown("### üìù Utilit√°rios")

    # Gerar resumo do cap√≠tulo (pega as √∫ltimas intera√ß√µes do Sheets)
    if st.button("üìù Gerar resumo do cap√≠tulo"):
        try:
            inter = carregar_interacoes(n=6)
            texto = "\n".join(f"{r['role']}: {r['content']}" for r in inter) if inter else ""
            prompt_resumo = (
                "Resuma o seguinte trecho como um cap√≠tulo de novela brasileira, mantendo tom e emo√ß√µes.\n\n"
                + texto + "\n\nResumo:"
            )
            provedor_local = st.session_state.get("provedor_ia", provedor)
            api_url_local = api_url
            api_key_local = api_key
            model_id_call = (
                model_id_for_together(st.session_state.modelo_escolhido_id)
                if provedor_local == "Together"
                else st.session_state.modelo_escolhido_id
            )
            if not api_key_local:
                st.error("‚ö†Ô∏è API key ausente para o provedor selecionado (defina em st.secrets).")
            else:
                if provedor_local == "Hugging Face":
                    # --- HF sem requests: usa InferenceClient ---
                    try:
                        hf_client = InferenceClient(
                            token=api_key_local,
                            timeout=int(st.session_state.get("timeout_s", 300))
                        )
                        out = hf_client.chat.completions.create(
                            model=model_id_call,
                            messages=[{"role": "user", "content": prompt_resumo}],
                            max_tokens=800,
                            temperature=0.85,
                            stream=False,
                        )
                        resumo = out.choices[0].message.content.strip()
                        st.session_state.resumo_capitulo = resumo
                        salvar_resumo(resumo)
                        st.success("Resumo gerado e salvo com sucesso!")
                    except Exception as e:
                        st.error(f"Erro ao resumir (HF): {e}")
                else:
                    # OpenRouter / Together (requests)
                    r = requests.post(
                        api_url_local,
                        headers={"Authorization": f"Bearer {api_key_local}", "Content-Type": "application/json"},
                        json={
                            "model": model_id_call,
                            "messages": [{"role": "user", "content": prompt_resumo}],
                            "max_tokens": 800,
                            "temperature": 0.85
                        },
                        timeout=int(st.session_state.get("timeout_s", 300)),
                    )
                    if r.status_code == 200:
                        resumo = r.json()["choices"][0]["message"]["content"].strip()
                        st.session_state.resumo_capitulo = resumo
                        salvar_resumo(resumo)
                        st.success("Resumo gerado e salvo com sucesso!")
                    else:
                        st.error(f"Erro ao resumir: {r.status_code} - {r.text}")
        except Exception as e:
            st.error(f"Erro ao gerar resumo: {e}")

# =========================
# ENVIO DO USU√ÅRIO + STREAMING
# =========================

entrada = st.chat_input("Digite sua dire√ß√£o de cena...")

if entrada:
    salvar_interacao("user", str(entrada))
    st.session_state.session_msgs.append({"role": "user", "content": str(entrada)})
    st.session_state["ctx_cena"] = extrair_diretriz_contexto(entrada, st.session_state.get("ctx_cena", CTX_INICIAL))
    ctx = st.session_state["ctx_cena"]

    linha_abertura = gerar_linha_abertura(ctx)

    mary_mode_active = bool(
        st.session_state.get("interpretar_apenas_mary")
        or st.session_state.get("modo_resposta") == "Mary (1¬™ pessoa)"
    )

    historico = []
    for ix, m in enumerate(st.session_state.session_msgs):
        role = m.get("role", "user")
        content = m.get("content", "")
        # S√≥ a √öLTIMA mensagem do usu√°rio recebe o contexto de abertura (mas prefixa s√≥ depois do J√ÇNIO:)
        if ix == len(st.session_state.session_msgs) - 1 and role.lower() == "user":
            content = linha_abertura
        if mary_mode_active and role.lower() == "user":
            content = f"J√ÇNIO: {content}"
        historico.append({"role": role, "content": content})

    prompt = construir_prompt_com_narrador()

    prov = st.session_state.get("provedor_ia", "OpenRouter")
    if prov == "Together":
        endpoint = "https://api.together.xyz/v1/chat/completions"
        auth = st.secrets.get("TOGETHER_API_KEY", "")
        model_to_call = model_id_for_together(st.session_state.modelo_escolhido_id)
    elif prov == "Hugging Face":
        endpoint = "HF_CLIENT"
        auth = st.secrets.get("HUGGINGFACE_API_KEY", "")
        model_to_call = st.session_state.modelo_escolhido_id
    else:
        endpoint = "https://openrouter.ai/api/v1/chat/completions"
        auth = st.secrets.get("OPENROUTER_API_KEY", "")
        model_to_call = st.session_state.modelo_escolhido_id

    if not auth:
        st.error("A chave de API do provedor selecionado n√£o foi definida em st.secrets.")
        st.stop()

    system_pt = {"role": "system", "content": "Responda em portugu√™s do Brasil. Mostre apenas a narrativa final."}
    system_mary = {
        "role": "system",
        "content": (
            "MODO MARY (ATIVO):\n"
            "- Trate a fala do usu√°rio como a√ß√µes/falas de J√¢nio.\n"
            "- Responda SOMENTE como Mary, em primeira pessoa.\n"
            "- N√£o invente falas de J√¢nio; descreva apenas o que Mary diz/sente/faz.\n"
            "- Se usar di√°logo, use travess√£o (‚Äî) apenas para a fala de Mary."
        )
    }

    messages = [system_pt]
    if mary_mode_active:
        messages.append(system_mary)
    messages.append({"role": "system", "content": prompt})
    messages += historico

    payload = {
        "model": model_to_call,
        "messages": messages,
        "max_tokens": int(st.session_state.get("max_tokens_rsp", 1200)),
        "temperature": 0.9,
        "stream": True,
    }
    headers = {"Authorization": f"Bearer {auth}", "Content-Type": "application/json"}

    # ============ BLOQUEIO DE CL√çMAX ============
    CLIMAX_USER_TRIGGER = re.compile(
        r"(?:\b("
        r"finaliza(?:r)?|"
        r"pode\s+(?:gozar|finalizar)|"
        r"liber(?:a|o)\s+(?:o\s+)?(?:cl[i√≠]max|orgasmo)|"
        r"cheg(?:a|ou)\s+ao?\s+(?:cl[i√≠]max|orgasmo)|"
        r"goza(?:r)?\s+(?:agora|j√°)|"
        r"agora\s+goza|"
        r"permite\s+orgasmo|"
        r"explod(?:e|iu)\s+em\s+orgasmo"
        r")\b)",
        flags=re.IGNORECASE
    )

    ORGASM_TERMS = r"(?:cl[i√≠]max|orgasmo|org√°sm(?:ic)o|gozou|gozando|gozaram|ejacul(?:a|ou|ar)|cheg(?:a|ou)\s+l√°|explod(?:e|iu))"
    ORGASM_SENT = re.compile(rf"([^.!\n]*\b{ORGASM_TERMS}\b[^.!?\n]*[.!?])", flags=re.IGNORECASE)
    def _user_allows_climax(msgs: list) -> bool:
        last_user = ""
        for r in reversed(msgs or []):
            if str(r.get("role", "")).lower() == "user":
                last_user = r.get("content", "") or ""
                break
        return bool(CLIMAX_USER_TRIGGER.search(last_user))
    def _strip_or_soften_climax(texto: str) -> str:
        if not texto:
            return texto
        texto = ORGASM_SENT.sub("", texto)
        texto = re.sub(r"\n{3,}", "\n\n", texto).strip()
        if not texto.endswith((".", "‚Ä¶", "!", "?")):
            texto += "‚Ä¶"
        finais = [
            " A tens√£o fica no ar, sem conclus√£o, apenas a respira√ß√£o quente entre eles.",
            " Eles param no limiar, ainda ofegantes, guardando o resto para o pr√≥ximo passo.",
            " Um sil√™ncio el√©trico preenche o quarto; nenhum desfecho, s√≥ a pele e o pulso acelerado.",
        ]
        if all(f not in texto for f in finais):
            texto += random.choice(finais)
        return texto

    with st.chat_message("assistant"):
        placeholder = st.empty()
        resposta_txt = ""
        last_update = time.time()

        # STREAMING: HF ou requests
        if prov == "Hugging Face":
            from huggingface_hub import InferenceClient
            hf_client = InferenceClient(token=auth, timeout=int(st.session_state.get("timeout_s", 300)))
            for chunk in hf_client.chat.completions.create(
                model=model_to_call,
                messages=messages,
                temperature=0.9,
                max_tokens=int(st.session_state.get("max_tokens_rsp", 1200)),
                stream=True,
            ):
                delta = getattr(chunk.choices.delta, "content", None)
                if not delta:
                    continue
                resposta_txt += delta
                if time.time() - last_update > 0.10:
                    parcial = _render_visible(resposta_txt) + "‚ñå"
                    if st.session_state.get("app_bloqueio_intimo", True):
                        if not _user_allows_climax(st.session_state.session_msgs):
                            parcial = _strip_or_soften_climax(parcial)
                    placeholder.markdown(parcial)
                    last_update = time.time()
        else:
            with requests.post(endpoint, headers=headers, json=payload, stream=True, timeout=int(st.session_state.get("timeout_s", 300))) as r:
                if r.status_code == 200:
                    for raw in r.iter_lines(decode_unicode=False):
                        if not raw:
                            continue
                        line = raw.decode("utf-8", errors="ignore").strip()
                        if not line.startswith("data:"):
                            continue
                        data = line[5:].strip()
                        if data == "[DONE]":
                            break
                        try:
                            j = json.loads(data)
                            delta = j["choices"]["delta"].get("content", "")
                            if not delta:
                                continue
                            resposta_txt += delta
                            if time.time() - last_update > 0.10:
                                parcial = _render_visible(resposta_txt) + "‚ñå"
                                if st.session_state.get("app_bloqueio_intimo", True):
                                    if not _user_allows_climax(st.session_state.session_msgs):
                                        parcial = _strip_or_soften_climax(parcial)
                                placeholder.markdown(parcial)
                                last_update = time.time()
                        except Exception:
                            continue
                else:
                    st.error(f"Erro {('Together' if prov=='Together' else 'OpenRouter')}: {r.status_code} - {r.text}")

        # FINALIZA TEXTO VIS√çVEL completo
        visible_txt = _render_visible(resposta_txt).strip()
        if st.session_state.get("app_bloqueio_intimo", True):
            if not _user_allows_climax(st.session_state.session_msgs):
                visible_txt = _strip_or_soften_climax(visible_txt)

        # Renderiza√ß√£o final
        placeholder.markdown(visible_txt if visible_txt else "[Sem conte√∫do]")

        # Persist√™ncia sempre no hist√≥rico
        if visible_txt and visible_txt != "[Sem conte√∫do]":
            salvar_interacao("assistant", visible_txt)
            st.session_state.session_msgs.append({"role": "assistant", "content": visible_txt})
        else:
            salvar_interacao("assistant", "[Sem conte√∫do]")
            st.session_state.session_msgs.append({"role": "assistant", "content": "[Sem conte√∫do]"})

        # Refor√ßo de mem√≥ria longa
        try:
            usados = []
            topk_usadas = memoria_longa_buscar_topk(
                query_text=visible_txt,
                k=int(st.session_state.get("k_memoria_longa", 3)),
                limiar=float(st.session_state.get("limiar_memoria_longa", 0.78)),
            )
            for t, *_ in topk_usadas:
                usados.append(t)
            memoria_longa_reforcar(usados)
        except Exception:
            pass

       # ======================
    # STREAM (PATCH C) ‚Äî com suporte a HF
    # ======================
    try:
        if prov == "Hugging Face":
            # --- STREAM via InferenceClient (sem SSE) ---
            hf_client = InferenceClient(
                token=auth,
                timeout=int(st.session_state.get("timeout_s", 300))
            )
            for chunk in hf_client.chat.completions.create(
                model=model_to_call,
                messages=messages,
                temperature=0.9,
                max_tokens=int(st.session_state.get("max_tokens_rsp", 1200)),
                stream=True,
            ):
                delta = getattr(chunk.choices[0].delta, "content", None)
                if not delta:
                    continue
                resposta_txt += delta
    
                # Atualiza√ß√£o parcial
                if time.time() - last_update > 0.10:
                    parcial = _render_visible(resposta_txt) + "‚ñå"
    
                    # BLOQUEIO ON-THE-FLY (sempre ativo se a op√ß√£o estiver ligada)
                    if st.session_state.get("app_bloqueio_intimo", True):
                        if not _user_allows_climax(st.session_state.session_msgs):
                            parcial = _strip_or_soften_climax(parcial)
    
                    placeholder.markdown(parcial)
                    last_update = time.time()
    
        else:
            # --- STREAM via SSE (OpenRouter/Together) ‚Äî mant√©m seu fluxo atual via requests ---
            headers = {"Authorization": f"Bearer {auth}", "Content-Type": "application/json"}
            payload = {
                "model": model_to_call,
                "messages": messages,
                "max_tokens": int(st.session_state.get("max_tokens_rsp", 1200)),
                "temperature": 0.9,
                "stream": True,
            }
            with requests.post(
                endpoint, headers=headers, json=payload, stream=True,
                timeout=int(st.session_state.get("timeout_s", 300))
            ) as r:
                if r.status_code == 200:
                    for raw in r.iter_lines(decode_unicode=False):
                        if not raw:
                            continue
                        line = raw.decode("utf-8", errors="ignore").strip()
                        if not line.startswith("data:"):
                            continue
                        data = line[5:].strip()
                        if data == "[DONE]":
                            break
                        try:
                            j = json.loads(data)
                            delta = j["choices"][0]["delta"].get("content", "")
                            if not delta:
                                continue
                            resposta_txt += delta
    
                            # Atualiza√ß√£o parcial
                            if time.time() - last_update > 0.10:
                                parcial = _render_visible(resposta_txt) + "‚ñå"
    
                                # BLOQUEIO ON-THE-FLY (sempre ativo se a op√ß√£o estiver ligada)
                                if st.session_state.get("app_bloqueio_intimo", True):
                                    if not _user_allows_climax(st.session_state.session_msgs):
                                        parcial = _strip_or_soften_climax(parcial)
    
                                placeholder.markdown(parcial)
                                last_update = time.time()
                        except Exception:
                            continue
                else:
                    st.error(f"Erro {('Together' if prov=='Together' else 'OpenRouter')}: {r.status_code} - {r.text}")
    except Exception as e:
        st.error(f"Erro no streaming: {e}")

    # FINALIZA TEXTO VIS√çVEL
    visible_txt = _render_visible(resposta_txt).strip()

    # Fallback sem stream
    if not visible_txt:
        try:
            if prov == "Hugging Face":
                out = InferenceClient(token=auth).chat.completions.create(
                    model=model_to_call,
                    messages=messages,
                    temperature=0.9,
                    max_tokens=int(st.session_state.get("max_tokens_rsp", 1200)),
                    stream=False,
                )
                resposta_txt = (out.choices[0].message.content or "").strip()
                visible_txt = _render_visible(resposta_txt).strip()
            else:
                r2 = requests.post(
                    endpoint, headers={"Authorization": f"Bearer {auth}", "Content-Type": "application/json"},
                    json={**payload, "stream": False},
                    timeout=int(st.session_state.get("timeout_s", 300))
                )
                if r2.status_code == 200:
                    try:
                        resposta_txt = r2.json()["choices"][0]["message"]["content"].strip()
                    except Exception:
                        resposta_txt = ""
                    visible_txt = _render_visible(resposta_txt).strip()
                else:
                    st.error(f"Fallback (sem stream) falhou: {r2.status_code} - {r2.text}")
        except Exception as e:
            st.error(f"Fallback (sem stream) erro: {e}")

        # Fallback com prompts limpos
    if not visible_txt:
        try:
            if prov == "Hugging Face":
                out2 = InferenceClient(token=auth).chat.completions.create(
                    model=model_to_call,
                    messages=[{"role": "system", "content": prompt}] + historico,
                    temperature=0.9,
                    max_tokens=int(st.session_state.get("max_tokens_rsp", 1200)),
                    stream=False,
                )
                resposta_txt = (out2.choices[0].message.content or "").strip()
                visible_txt = _render_visible(resposta_txt).strip()
            else:
                r3 = requests.post(
                    endpoint, headers={"Authorization": f"Bearer {auth}", "Content-Type": "application/json"},
                    json={
                        "model": model_to_call,
                        "messages": [{"role": "system", "content": prompt}] + historico,
                        "max_tokens": int(st.session_state.get("max_tokens_rsp", 1200)),
                        "temperature": 0.9,
                        "stream": False,
                    },
                    timeout=int(st.session_state.get("timeout_s", 300))
                )
                if r3.status_code == 200:
                    try:
                        resposta_txt = r3.json()["choices"][0]["message"]["content"].strip()
                    except Exception:
                        resposta_txt = ""
                    visible_txt = _render_visible(resposta_txt).strip()
                else:
                    st.error(f"Fallback (prompts limpos) falhou: {r3.status_code} - {r3.text}")
        except Exception as e:
            st.error(f"Fallback (prompts limpos) erro: {e}")

    # BLOQUEIO DE CL√çMAX FINAL (sempre que a op√ß√£o estiver ativa, s√≥ libera com comando do usu√°rio)
    if st.session_state.get("app_bloqueio_intimo", True):
        if not _user_allows_climax(st.session_state.session_msgs):
            visible_txt = _strip_or_soften_climax(visible_txt)

        # --- ENFORCER: garantir ao menos 1 fala de Mary, se a op√ß√£o estiver ativa ---
    if st.session_state.get("usar_falas_mary", False):
        falas = st.session_state.get("_falas_mary_list", []) or []
        if falas and visible_txt:
            tem_fala = any(re.search(re.escape(f), visible_txt, flags=re.IGNORECASE) for f in falas)
            if not tem_fala:
                escolha = random.choice(falas)
                if st.session_state.get("interpretar_apenas_mary", False):
                    inj = f"‚Äî {escolha}\n\n"
                else:
                    inj = f"‚Äî {escolha} ‚Äî diz Mary.\n\n"
                visible_txt = inj + visible_txt
    
    # ===== Render final (sempre) =====
    placeholder.markdown(visible_txt if visible_txt else "[Sem conte√∫do]")
    
    # ===== Persist√™ncia (sempre) =====
    if visible_txt and visible_txt != "[Sem conte√∫do]":
        salvar_interacao("assistant", visible_txt)
        st.session_state.session_msgs.append({"role": "assistant", "content": visible_txt})
    else:
        salvar_interacao("assistant", "[Sem conte√∫do]")
        st.session_state.session_msgs.append({"role": "assistant", "content": "[Sem conte√∫do]"})
    
    # ===== Refor√ßo p√≥s-resposta (sempre) =====
    try:
        usados = []
        topk_usadas = memoria_longa_buscar_topk(
            query_text=visible_txt,
            k=int(st.session_state.get("k_memoria_longa", 3)),
            limiar=float(st.session_state.get("limiar_memoria_longa", 0.78)),
        )
        for t, _sc, _sim, _rr in topk_usadas:
            usados.append(t)
        memoria_longa_reforcar(usados)
    except Exception:
        pass









