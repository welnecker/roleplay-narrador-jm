# ============================================================
# Narrador JM ‚Äî Roleplay adulto (sem pornografia expl√≠cita)
# Compat√≠vel com o m√©todo antigo: GOOGLE_CREDS_JSON + oauth2client
# ============================================================

import os
import re
import json
import time
import random

from datetime import datetime
from typing import List, Tuple, Dict, Any

import streamlit as st
import requests
import gspread

from oauth2client.service_account import ServiceAccountCredentials
import numpy as np
from gspread.exceptions import APIError

# ---- Backoff p/ 429 do Sheets ----
def _retry_429(callable_fn, *args, _retries=5, _base=0.6, **kwargs):
    for i in range(_retries):
        try:
            return callable_fn(*args, **kwargs)
        except APIError as e:
            msg = str(e)
            if "429" in msg or "quota" in msg.lower():
                time.sleep((_base * (2 ** i)) + random.uniform(0, 0.25))
                continue
            raise
    return callable_fn(*args, **kwargs)

@st.cache_data(ttl=45, show_spinner=False)
def _sheet_all_records_cached(sheet_name: str):
    ws = _ws(sheet_name, create_if_missing=False)
    if not ws:
        return []
    return _retry_429(ws.get_all_records)

@st.cache_data(ttl=45, show_spinner=False)
def _sheet_all_values_cached(sheet_name: str):
    ws = _ws(sheet_name, create_if_missing=False)
    if not ws:
        return []
    return _retry_429(ws.get_all_values)

def _invalidate_sheet_caches():
    try:
        _sheet_all_records_cached.clear()
        _sheet_all_values_cached.clear()
    except Exception:
        pass

# (Opcional) Embeddings OpenAI para verifica√ß√£o sem√¢ntica/mem√≥ria longa
try:
    from openai import OpenAI
    OPENAI_CLIENT = OpenAI(api_key=st.secrets.get("OPENAI_API_KEY", ""))
    OPENAI_OK = bool(st.secrets.get("OPENAI_API_KEY"))
except Exception:
    OPENAI_CLIENT = None
    OPENAI_OK = False

# === FALAS SOBRE VIRGINDADE DA MARY (brandas; voc√™ pode trocar depois) ===
FALAS_VIRGINDADE_MARY = [
    "Eu preciso te dizer‚Ä¶ eu ainda sou virgem.",
    "Quero ir devagar, no meu tempo ‚Äî fica comigo.",
    "Hoje eu quero carinho e beijo, sem passar do meu limite.",
    "Se for com voc√™, quero que seja especial; me escuta, t√°?",
]


# =========================
# CONFIG B√ÅSICA DO APP
# =========================

PLANILHA_ID_PADRAO = st.secrets.get("SPREADSHEET_ID", "").strip() or "1f7LBJFlhJvg3NGIWwpLTmJXxH9TH-MNn3F4SQkyfZNM"
TAB_INTERACOES = "interacoes_jm"
TAB_PERFIL     = "perfil_jm"
TAB_MEMORIAS   = "memoria_jm"
TAB_ML         = "memoria_longa_jm"
TAB_TEMPLATES  = "templates_jm"
TAB_FALAS_MARY = "falas_mary_jm"   # <<< NOVA ABA: fala | timestamp

def conectar_planilha():
    try:
        creds_dict = json.loads(st.secrets["GOOGLE_CREDS_JSON"])
        if "private_key" in creds_dict:
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive",
        ]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        spreadsheet_id = st.secrets.get("SPREADSHEET_ID", "").strip() or PLANILHA_ID_PADRAO
        return client.open_by_key(spreadsheet_id)
    except Exception as e:
        st.error(f"Erro ao conectar √† planilha: {e}")
        return None

planilha = conectar_planilha()

def _ws(name: str, create_if_missing: bool = True):
    if not planilha:
        return None
    try:
        return planilha.worksheet(name)
    except Exception:
        if not create_if_missing:
            return None
        try:
            ws = planilha.add_worksheet(title=name, rows=5000, cols=10)
            if name == TAB_INTERACOES:
                _retry_429(ws.append_row, ["timestamp", "role", "content"])
            elif name == TAB_PERFIL:
                _retry_429(ws.append_row, ["timestamp", "resumo"])
            elif name == TAB_MEMORIAS:
                _retry_429(ws.append_row, ["tipo", "conteudo", "timestamp"])
            elif name == TAB_ML:
                _retry_429(ws.append_row, ["texto", "embedding", "tags", "timestamp", "score"])
            elif name == TAB_TEMPLATES:
                _retry_429(ws.append_row, ["template", "etapa", "texto"])
            elif name == TAB_FALAS_MARY:  # <<< cria cabe√ßalho
                _retry_429(ws.append_row, ["fala", "timestamp"])
            return ws
        except Exception:
            return None

# -------- templates (N√çVEL DE M√ìDULO; N√ÉO DENTRO DE _ws !) --------
def carregar_templates_planilha():
    """Carrega todos os templates sequenciais da aba templates_jm em {template:[etapa1, etapa2,...]}"""
    try:
        ws = _ws(TAB_TEMPLATES, create_if_missing=False)
        if not ws:
            return {}
        rows = _sheet_all_records_cached(TAB_TEMPLATES)
        templates = {}
        for row in rows:
            r = {(k or "").strip().lower(): (v or "") for k, v in row.items()}
            nome = r.get("template", "").strip()
            etapa_str = r.get("etapa", "1")
            try:
                etapa = int(etapa_str)
            except Exception:
                etapa = 1
            texto = r.get("texto", "").strip()
            if nome and texto:
                templates.setdefault(nome, []).append((etapa, texto))
        for nome in templates:
            templates[nome].sort(key=lambda x: x[0])
            templates[nome] = [t[1] for t in templates[nome]]
        return templates
    except Exception as e:
        st.warning(f"Erro ao carregar templates do Sheets: {e}")
        return {}

def _init_templates_once():
    if "templates_jm" not in st.session_state:
        st.session_state.templates_jm = carregar_templates_planilha()
    if "template_ativo" not in st.session_state:
        st.session_state.template_ativo = None
    if "etapa_template" not in st.session_state:
        st.session_state.etapa_template = 0

_init_templates_once()

# =====
# UTILIDADES: MEM√ìRIAS / HIST√ìRICO
# =====

def _normalize_tag(raw: str) -> str:
    t = (raw or "").strip().lower()
    if not t:
        return ""
    return t if t.startswith("[") else f"[{t}]"

def _parse_ts(s: str) -> str:
    s = (s or "").strip()
    try:
        datetime.strptime(s, "%Y-%m-%d %H:%M:%S")
        return s
    except Exception:
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def carregar_memorias_brutas() -> Dict[str, List[dict]]:
    try:
        regs = _sheet_all_records_cached(TAB_MEMORIAS)
        buckets: Dict[str, List[dict]] = {}
        for r in regs:
            tag = _normalize_tag(r.get("tipo"))
            txt = (r.get("conteudo") or "").strip()
            ts  = (r.get("timestamp") or "").strip()
            if tag and txt:
                buckets.setdefault(tag, []).append({"conteudo": txt, "timestamp": ts})
        return buckets
    except Exception as e:
        st.warning(f"Erro ao carregar mem√≥rias: {e}")
        return {}

def persona_block(nome: str, buckets: dict, max_linhas: int = 8) -> str:
    tag = f"[{nome}]"
    linhas = buckets.get(tag, [])
    ordem = ["OBJ:", "TAT:", "LV:", "VOZ:", "BIO:", "ROTINA:", "LACOS:", "APS:", "CONFLITOS:"]
    def peso(linha_dict):
        up = (linha_dict.get("conteudo","")).upper()
        for i, p in enumerate(ordem):
            if up.startswith(p):
                return i
        return len(ordem)
    linhas_ordenadas = sorted(linhas, key=peso)[:max_linhas]
    titulo = "J√¢nio" if nome in ("janio", "j√¢nio") else "Mary" if nome == "mary" else nome.capitalize()
    return f"{titulo}:\n- " + "\n- ".join(l['conteudo'] for l in linhas_ordenadas) if linhas_ordenadas else ""

def persona_block_temporal(nome: str, buckets: dict, ate_ts: str, max_linhas: int = 8) -> str:
    tag = f"[{nome}]"
    linhas = []
    for d in buckets.get(tag, []) or []:
        if not isinstance(d, dict):
            continue
        c = (d.get("conteudo") or "").strip()
        ts = (d.get("timestamp") or "").strip()
        if not c:
            continue
        if ts and ate_ts and ts > ate_ts:
            continue
        linhas.append((ts, c))
    linhas.sort(key=lambda x: x[0])
    ult = [c for _, c in linhas][-max_linhas:]
    if not ult:
        return ""
    titulo = "J√¢nio" if nome in ("janio", "j√¢nio") else "Mary" if nome == "mary" else nome.capitalize()
    return f"{titulo}:\n- " + "\n- ".join(ult)

def detectar_virgindade_mary(memos: dict, ate_ts: str = "") -> bool:
    """
    True se h√°, em [mary], alguma mem√≥ria com 'virgem' ou 'virgindade'
    (respeitando corte temporal, se ate_ts vier).
    """
    for d in memos.get("[mary]", []) or []:
        c = (d.get("conteudo") or "").lower()
        ts = (d.get("timestamp") or "")
        if ate_ts and ts and ts > ate_ts:
            continue
        if ("virgem" in c) or ("virgindade" in c):
            return True
    return False


def montar_bloco_virgindade(ativar: bool) -> str:
    """
    Se ativar=True, devolve bloco de regras + 2‚Äì3 falas brandas (voc√™ pode editar depois).
    """
    if not ativar:
        return ""
    exemplos = "\n".join(f"- {s}" for s in FALAS_VIRGINDADE_MARY[:3])
    return (
        "### Virgindade & Limites (priorit√°rio)\n"
        "- Mary √© virgem e valoriza isso. Se a cena se aproximar de sexo expl√≠cito, "
        "**ela verbaliza seus limites antes** de qualquer avan√ßo.\n"
        "- Mostre desejo com respeito ao ritmo: consentimento claro, trocas gentis, pausas.\n"
        "- Inclua **uma fala curta** de Mary sobre isso quando apropriado (exemplos abaixo):\n"
        f"{exemplos}\n"
    )


def carregar_resumo_salvo() -> str:
    try:
        registros = _sheet_all_records_cached(TAB_PERFIL)
        for r in reversed(registros):
            txt = (r.get("resumo") or "").strip()
            if txt:
                return txt
        return ""
    except Exception as e:
        st.warning(f"Erro ao carregar resumo salvo: {e}")
        return ""

def salvar_resumo(resumo: str):
    try:
        aba = _ws(TAB_PERFIL)
        if not aba:
            return
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        _retry_429(aba.append_row, [timestamp, resumo], value_input_option="RAW")
        _invalidate_sheet_caches()
    except Exception as e:
        st.error(f"Erro ao salvar resumo: {e}")

def carregar_interacoes(n: int = 20):
    cache = st.session_state.get("_cache_interacoes", None)
    if cache is None:
        regs = _sheet_all_records_cached(TAB_INTERACOES)
        st.session_state["_cache_interacoes"] = regs
        cache = regs
    return cache[-n:] if len(cache) > n else cache

def salvar_interacao(role: str, content: str):
    if not planilha:
        return
    try:
        aba = _ws(TAB_INTERACOES)
        if not aba:
            return
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        row_role = f"{role or ''}".strip()
        row_content = f"{content or ''}".strip()
        _retry_429(aba.append_row, [timestamp, row_role, row_content], value_input_option="RAW")
        lst = st.session_state.get("_cache_interacoes")
        if isinstance(lst, list):
            lst.append({"timestamp": timestamp, "role": row_role, "content": row_content})
        else:
            st.session_state["_cache_interacoes"] = [{
                "timestamp": timestamp, "role": row_role, "content": row_content
            }]
        _invalidate_sheet_caches()
    except Exception as e:
        st.error(f"Erro ao salvar intera√ß√£o: {e}")

# ----- Falas da Mary (planilha) -----
def carregar_falas_mary() -> List[str]:
    try:
        rows = _sheet_all_records_cached(TAB_FALAS_MARY)
        falas = []
        for r in rows:
            f = (r.get("fala") or "").strip()
            if f:
                falas.append(f)
        return falas
    except Exception as e:
        st.warning(f"Erro ao carregar {TAB_FALAS_MARY}: {e}")
        return []

# =========================
# EMBEDDINGS / SIMILARIDADE
# =========================

def gerar_embedding_openai(texto: str):
    if not OPENAI_OK:
        return None
    try:
        resp = OPENAI_CLIENT.embeddings.create(
            input=texto,
            model="text-embedding-3-small"
        )
        return np.array(resp.data[0].embedding, dtype=float)
    except Exception as e:
        st.error(f"Erro ao gerar embedding: {e}")
        return None

def cosine_similarity(v1: np.ndarray, v2: np.ndarray) -> float:
    return float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))

def verificar_quebra_semantica_openai(texto1: str, texto2: str, limite=0.6) -> str:
    if not OPENAI_OK:
        return ""
    e1 = gerar_embedding_openai(texto1)
    e2 = gerar_embedding_openai(texto2)
    if e1 is None or e2 is None:
        return ""
    sim = cosine_similarity(e1, e2)
    if sim < limite:
        return f"‚ö†Ô∏è Baixa continuidade narrativa (similaridade: {sim:.2f})."
    return ""

# =========================
# MEM√ìRIA LONGA (opcional)
# =========================

def _sheet_ensure_memoria_longa():
    return _ws(TAB_ML, create_if_missing=False)

def _serialize_vec(vec: np.ndarray) -> str:
    return json.dumps(vec.tolist(), separators=(",", ":"))

def _deserialize_vec(s: str) -> np.ndarray:
    try:
        return np.array(json.loads(s), dtype=float)
    except Exception:
        return np.zeros(1, dtype=float)

def memoria_longa_salvar(texto: str, tags: str = "") -> bool:
    aba = _sheet_ensure_memoria_longa()
    if not aba:
        st.warning("Aba 'memoria_longa_jm' n√£o encontrada ‚Äî crie com cabe√ßalhos: texto | embedding | tags | timestamp | score")
        return False
    emb = gerar_embedding_openai(texto)
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    linha = [texto.strip(), _serialize_vec(emb) if emb is not None else "", (tags or "").strip(), ts, 1.0]
    try:
        _retry_429(aba.append_row, linha, value_input_option="RAW")
        _invalidate_sheet_caches()
        return True
    except Exception as e:
        st.error(f"Erro ao salvar mem√≥ria longa: {e}")
        return False

def memoria_longa_listar_registros():
    try:
        return _sheet_all_records_cached(TAB_ML)
    except Exception:
        return []

def _tokenize(s: str) -> set:
    return set(re.findall(r"[a-z√†-√∫0-9]+", (s or "").lower()))

def memoria_longa_buscar_topk(query_text: str, k: int = 3, limiar: float = 0.78, ate_ts=None):
    try:
        dados = _sheet_all_records_cached(TAB_ML)
    except Exception as e:
        st.warning(f"Erro ao carregar memoria_longa_jm: {e}")
        return []
    q = gerar_embedding_openai(query_text) if OPENAI_OK else None
    candidatos = []
    for row in dados:
        texto = (row.get("texto") or "").strip()
        emb_s = (row.get("embedding") or "").strip()
        row_ts = (row.get("timestamp") or "").strip()
        try:
            score = float(row.get("score", 1.0) or 1.0)
        except Exception:
            score = 1.0
        if not texto:
            continue
        if ate_ts and row_ts and row_ts > ate_ts:
            continue
        if q is not None and emb_s:
            vec = _deserialize_vec(emb_s)
            if vec.ndim == 1 and vec.size >= 10 and np.linalg.norm(vec) > 0 and np.linalg.norm(q) > 0:
                sim = float(np.dot(q, vec) / (np.linalg.norm(q) * np.linalg.norm(vec)))
            else:
                sim = 0.0
        else:
            s1 = _tokenize(texto); s2 = _tokenize(query_text)
            sim = len(s1 & s2) / max(1, len(s1 | s2))
        if sim >= limiar:
            rr = 0.7 * sim + 0.3 * score
            candidatos.append((texto, score, sim, rr))
    candidatos.sort(key=lambda x: x[3], reverse=True)
    return candidatos[:k]

def memoria_longa_reforcar(textos_usados: list):
    aba = _sheet_ensure_memoria_longa()
    if not aba or not textos_usados:
        return
    try:
        dados = _sheet_all_values_cached(TAB_ML)
        if not dados or len(dados) < 2:
            return
        headers = dados[0]
        idx_texto = headers.index("texto")
        idx_score = headers.index("score")
        for i, linha in enumerate(dados[1:], start=2):
            if len(linha) <= max(idx_texto, idx_score): continue
            t = (linha[idx_texto] or "").strip()
            if t in textos_usados:
                try: sc = float(linha[idx_score] or 1.0)
                except Exception: sc = 1.0
                sc = min(sc + 0.2, 2.0)
                _retry_429(aba.update_cell, i, idx_score + 1, sc)
        _invalidate_sheet_caches()
    except Exception:
        pass

# =========================
# ROMANCE (FASES) + MOMENTO
# =========================

FASES_ROMANCE: Dict[int, Dict[str, str]] = {
    0: {"nome": "Estranhos",
        "permitidos": "olhares; near-miss (mesmo caf√©/rua/√¥nibus); detalhe do ambiente",
        "proibidos": "troca de nomes; toques; conversa pessoal"},
    1: {"nome": "Percep√ß√£o",
        "permitidos": "cumprimento neutro; pergunta impessoal curta",
        "proibidos": "contato f√≠sico; confid√™ncias"},
    2: {"nome": "Conhecidos",
        "permitidos": "troca de nomes; pequena ajuda; 1 pergunta pessoal leve",
        "proibidos": "toque prolongado; encontro a s√≥s planejado"},
    3: {"nome": "Amizade",
        "permitidos": "conversa 10‚Äì20 min; caminhar juntos; troca de contatos; 1 gesto de afeto leve (com consentimento)",
        "proibidos": "beijos; car√≠cias intimistas"},
    4: {"nome": "Confian√ßa / Quase",
        "permitidos": "confid√™ncias; abra√ßo com consentimento expresso; marcar encontro futuro claro",
        "proibidos": "pressa ou ‚Äúprovas de amor‚Äù f√≠sicas"},
    5: {"nome": "Compromisso / Encontro definitivo",
        "permitidos": "beijo prolongado; dormir juntos; consuma√ß√£o impl√≠cita (fade-to-black); manh√£ seguinte sugerida",
        "proibidos": ""},
}

FLAG_FASE_TXT_PREFIX = "FLAG: mj_fase="

def _fase_label(n: int) -> str:
    d = FASES_ROMANCE.get(int(n), FASES_ROMANCE[0])
    return f"{int(n)} ‚Äî {d['nome']}"

def mj_set_fase(n: int, persist: bool=False):
    n = max(0, min(max(FASES_ROMANCE.keys()), int(n)))
    st.session_state.mj_fase = n
    if persist:
        try:
            memoria_longa_salvar(f"{FLAG_FASE_TXT_PREFIX}{n}", tags="[flag]")
        except Exception:
            pass

def mj_carregar_fase_inicial() -> int:
    if "mj_fase" in st.session_state:
        return int(st.session_state.mj_fase)
    try:
        recs = memoria_longa_listar_registros()
        for r in reversed(recs):
            t = (r.get("texto") or "").strip()
            if t.startswith(FLAG_FASE_TXT_PREFIX):
                n = int(t.split("=")[1])
                st.session_state.mj_fase = n
                return n
    except Exception:
        pass
    st.session_state.mj_fase = 0
    return 0

MOMENTOS = {
    0: {"nome": "Aproxima√ß√£o log√≠stica",
        "objetivo": "um acompanha o outro",
        "permitidos": "gentilezas; proximidade leve; di√°logo casual",
        "proibidos": "declara√ß√£o; revela√ß√µes √≠ntimas; toques prolongados",
        "gatilhos": [r"\b(p[i√≠]er|acompanhar|vamos embora|te levo)\b"],
        "proximo": 1},
    1: {"nome": "Declara√ß√£o",
        "objetivo": "um deles declara import√¢ncia",
        "permitidos": "confiss√£o afetiva; sil√™ncio tenso; abra√ßo curto",
        "proibidos": "negocia√ß√£o sexual; tirar roupas",
        "gatilhos": [r"\b(amo voc[e√™]|te amo|n[a√£]o paro de pensar)\b"],
        "proximo": 2},
    2: {"nome": "Revela√ß√£o sens√≠vel",
        "objetivo": "Mary revela vulnerabilidade / limites",
        "permitidos": "nomear limites; conforto m√∫tuo",
        "proibidos": "car√≠cias √≠ntimas; tirar roupas",
        "gatilhos": [r"\b(meu limite|prefiro ir devagar)\b"],
        "proximo": 3},
    3: {"nome": "Consentimento expl√≠cito",
        "objetivo": "alinhamento de limites e um 'sim' claro",
        "permitidos": "pedir/receber consentimento; decidir 'agora sim'",
        "proibidos": "",
        "gatilhos": [r"\b(consento|quero|vamos juntos|tudo bem pra voc[e√™])\b", r"\b(at[e√©] onde)\b"],
        "proximo": 4},
    4: {"nome": "Intimidade (el√≠ptica)",
        "objetivo": "intimidade sugerida (fade-to-black) / p√≥s-ato impl√≠cito",
        "permitidos": "beijos longos; proximidade forte; fade-to-black",
        "proibidos": "",
        "gatilhos": [r"\b(quarto|cama|luz baixa|porta fechada|manh[a√£] seguinte)\b"],
        "proximo": 4},
}

def _momento_label(n: int) -> str:
    m = MOMENTOS.get(int(n), MOMENTOS[0])
    return f"{int(n)} ‚Äî {m['nome']}"

def detectar_momento_sugerido(texto: str, fallback: int = 0) -> int:
    t = (texto or "").lower()
    for i in range(4, -1, -1):
        for gx in MOMENTOS[i]["gatilhos"]:
            if re.search(gx, t, flags=re.IGNORECASE):
                return i
    return fallback

def clamp_momento(atual: int, proposto: int, max_steps: int) -> int:
    if proposto > atual + max_steps:
        return atual + max_steps
    if proposto < atual:
        return max(proposto, atual - 1)
    return proposto

def momento_set(n: int, persist: bool = True):
    n = max(0, min(max(MOMENTOS.keys()), int(n)))
    st.session_state.momento = n
    if persist:
        try:
            memoria_longa_salvar(f"FLAG: mj_momento={n}", tags="[flag]")
        except Exception:
            pass

def momento_carregar() -> int:
    if "momento" in st.session_state:
        return int(st.session_state.momento)
    try:
        recs = memoria_longa_listar_registros()
        for r in reversed(recs):
            t = (r.get("texto") or "").strip()
            if t.startswith("FLAG: mj_momento="):
                n = int(t.split("=")[1])
                st.session_state.momento = n
                return n
    except Exception:
        pass
    st.session_state.momento = 0
    return 0

def viola_momento(texto: str, momento: int) -> str:
    return ""

# =========================
# PROVEDORES E MODELOS (enxuto)
# =========================

MODELOS_OPENROUTER = {
    "üí¨ DeepSeek V3 ‚òÖ‚òÖ‚òÖ‚òÖ ($)": "deepseek/deepseek-chat-v3-0324",
    "üß† DeepSeek R1 0528 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$)": "deepseek/deepseek-r1-0528",
    "üß† DeepSeek R1T2 Chimera ‚òÖ‚òÖ‚òÖ‚òÖ (free)": "tngtech/deepseek-r1t2-chimera:free",
    "üß† GPT-4.1 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (1M ctx)": "openai/gpt-4.1",
    "üëë WizardLM 8x22B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$$)": "microsoft/wizardlm-2-8x22b",
    "üëë Qwen 235B 2507 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (PAID)": "qwen/qwen3-235b-a22b-07-25",
    "üëë EVA Qwen2.5 72B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-qwen-2.5-72b",
    "üëë EVA Llama 3.33 70B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-llama-3.33-70b",
    "üé≠ Nous Hermes 2 Yi 34B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ": "nousresearch/nous-hermes-2-yi-34b",
    "üî• MythoMax 13B ‚òÖ‚òÖ‚òÖ‚òÜ ($)": "gryphe/mythomax-l2-13b",
    "üíã LLaMA3 Lumimaid 8B ‚òÖ‚òÖ‚òÜ ($)": "neversleep/llama-3-lumimaid-8b",
    "üåπ Midnight Rose 70B ‚òÖ‚òÖ‚òÖ‚òÜ": "sophosympatheia/midnight-rose-70b",
    "üå∂Ô∏è Noromaid 20B ‚òÖ‚òÖ‚òÜ": "neversleep/noromaid-20b",
    "üíÄ Mythalion 13B ‚òÖ‚òÖ‚òÜ": "pygmalionai/mythalion-13b",
    "üêâ Anubis 70B ‚òÖ‚òÖ‚òÜ": "thedrummer/anubis-70b-v1.1",
    "üßö Rocinante 12B ‚òÖ‚òÖ‚òÜ": "thedrummer/rocinante-12b",
    "üç∑ Magnum v2 72B ‚òÖ‚òÖ‚òÜ": "anthracite-org/magnum-v2-72b",
}

MODELOS_TOGETHER_UI = {
    "üß† Qwen3 Coder 480B (Together)": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "üëë Mixtral 8x7B v0.1 (Together)": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "üëë Perplexity R1-1776 (Together)": "perplexity-ai/r1-1776",
}

def model_id_for_together(api_ui_model_id: str) -> str:
    return api_ui_model_id or "mistralai/Mixtral-8x7B-Instruct-v0.1"

def api_config_for_provider(provider: str):
    if provider == "OpenRouter":
        return ("https://openrouter.ai/api/v1/chat/completions",
                st.secrets.get("OPENROUTER_API_KEY", ""),
                MODELOS_OPENROUTER)
    else:
        return ("https://api.together.xyz/v1/chat/completions",
                st.secrets.get("TOGETHER_API_KEY", ""),
                MODELOS_TOGETHER_UI)

# =========================
# PROMPT BUILDER
# =========================

def inserir_regras_mary_e_janio(prompt_base: str) -> str:
    calor = int(st.session_state.get("nsfw_max_level", 3))
    regras = f"""
‚öñÔ∏è Regras de coer√™ncia:
- Narre em terceira pessoa; n√£o se dirija ao leitor como "voc√™".
- Consentimento claro antes de qualquer gesto significativo.
- J√¢nio respeita o ritmo de Mary.
- Linguagem sensual proporcional ao n√≠vel de calor ({calor}).
""".strip()
    fase = int(st.session_state.get("mj_fase", mj_carregar_fase_inicial()))
    if fase >= 5:
        regras += "\n- A intimidade pode ser sugerida sem elipses for√ßadas."
    else:
        regras += "\n- Evite consuma√ß√£o expl√≠cita; foque em progress√£o coerente."
    return prompt_base + "\n" + regras

def gerar_mary_sensorial(level: int = 2, n: int = 2, hair_on: bool = True, sintonia: bool = False) -> str:
    if level <= 0 or n <= 0:
        return ""
    base_leve = [
        "Mary caminha com ritmo seguro; h√° algo hipn√≥tico no balan√ßo dos quadris.",
        "O olhar de Mary prende f√°cil: direto, firme, cativante.",
        "O perfume de Mary chega antes dela, discreto e morno.",
        "O sorriso aparece quando quer; breve, afiado, certeiro.",
    ]
    base_marcado = [
        "Os quadris de Mary balan√ßam num compasso que chama aten√ß√£o sem pedir licen√ßa.",
        "Enquanto caminha, os seios balan√ßam de leve sob o tecido.",
        "O tecido ro√ßa nas pernas e denuncia o passo: firme, √≠ntimo, decidido.",
        "O olhar de Mary √© um convite silencioso ‚Äî confiante e dif√≠cil de sustentar por muito tempo.",
    ]
    base_ousado = [
        "O balan√ßo dos quadris de Mary fica na cabe√ßa de quem v√™.",
        "Os seios acompanham a passada num movimento suave.",
        "O olhar de Mary encosta na pele de quem cruza com ela: quente e demorado.",
        "O perfume fica na mem√≥ria como um toque atr√°s da nuca.",
    ]
    hair_leve = [
        "Os cabelos de Mary ‚Äî negros, volumosos, levemente ondulados ‚Äî descansam nos ombros e acompanham o passo.",
        "Os cabelos negros, volumosos e levemente ondulados moldam o rosto quando ela vira de leve.",
    ]
    hair_marcado = [
        "Cabelos negros, volumosos, levemente ondulados, fazem um arco quando ela vira o rosto.",
        "Os cabelos, negros e volumosos, ondulam de leve a cada passada e enquadram o olhar.",
    ]
    hair_ousado = [
        "Os cabelos negros, volumosos e levemente ondulados deslizam pela clav√≠cula.",
        "O balan√ßo dos cabelos negros ‚Äî volumosos, levemente ondulados ‚Äî marca o compasso do corpo.",
    ]
    if level == 1:
        pool = list(base_leve); hair_pool = list(hair_leve)
    elif level == 2:
        pool = list(base_leve) + list(base_marcado); hair_pool = list(hair_leve) + list(hair_marcado)
    else:
        pool = base_leve + base_marcado + base_ousado; hair_pool = hair_leve + hair_marcado + hair_ousado

    if sintonia:
        filtros = [r"\binsinuante\b", r"\bacende o ambiente\b"]
        def _ok(fr): return not any(re.search(p, fr, re.IGNORECASE) for p in filtros)
        pool = [f for f in pool if _ok(f)]
        pool += [
            "A respira√ß√£o de Mary encontra o compasso do parceiro, sem pressa.",
            "Ela desacelera um passo, deixando o momento guiar o ritmo.",
            "H√° pausas gentis entre olhares; tudo acontece no tempo certo.",
            "O gesto nasce do encontro, n√£o da urg√™ncia; Mary prefere sentir antes de conduzir.",
        ]
    n_eff = max(1, min(n, len(pool)))
    frases = random.sample(pool, k=n_eff)
    if hair_on and hair_pool:
        hair_line = random.choice(hair_pool)
        if hair_line not in frases:
            frases.insert(0, hair_line)
            if len(frases) > n_eff:
                frases = frases[:n_eff]
    return " ".join(frases)

def encontrar_memorias_relevantes(pergunta, buckets):
    keywords = ["nome","integrante","banda","integrantes","profiss√£o","rotina","cargo","ocupa√ß√£o",
                "onde","quem","quando","idade","universidade","curso","hist√≥ria","grupo"]
    relevantes = []
    pergunta_lc = (pergunta or "").lower()
    for tag, items in buckets.items():
        tag_limp = tag.strip("[]")
        if any(k in pergunta_lc for k in keywords) or tag_limp in pergunta_lc:
            relevantes.extend(items)
    return relevantes

def _last_user_text(hist):
    if not hist: return ""
    for r in reversed(hist):
        if str(r.get("role","")).lower() == "user":
            return r.get("content","")
    return ""

def _deduzir_ancora(texto: str) -> dict:
    t = (texto or "").lower()
    if "motel" in t or "su√≠te" in t or "suite" in t:
        return {"local": "Motel ‚Äî Su√≠te Master", "hora": "noite"}
    if "quarto" in t:
        return {"local": "Quarto", "hora": "noite"}
    if "praia" in t:
        return {"local": "Praia", "hora": "fim de tarde"}
    if "bar" in t or "pub" in t:
        return {"local": "Bar", "hora": "noite"}
    if "biblioteca" in t:
        return {"local": "Biblioteca", "hora": "tarde"}
    if "ufes" in t:
        return {"local": "UFES ‚Äî campus", "hora": "manh√£"}
    gatilhos_motel = ["cama redonda", "espelho no teto", "piscina aquecida"]
    if any(g in t for g in gatilhos_motel):
        return {"local": "Motel ‚Äî Su√≠te Master", "hora": "noite"}
    return {}

def construir_prompt_com_narrador() -> str:
    memos = carregar_memorias_brutas()
    perfil = carregar_resumo_salvo()
    fase = int(st.session_state.get("mj_fase", mj_carregar_fase_inicial()))
    fdata = FASES_ROMANCE.get(fase, FASES_ROMANCE[0])
    momento_atual = int(st.session_state.get("momento", momento_carregar()))
    mdata = MOMENTOS.get(momento_atual, MOMENTOS[0])
    proximo_nome = MOMENTOS.get(mdata.get("proximo", 0), MOMENTOS[0])["nome"]
    estilo = st.session_state.get("estilo_escrita", "A√á√ÉO")

    # Camada sensorial (Mary)
    _sens_on = bool(st.session_state.get("mary_sensorial_on", True))
    _sens_level = int(st.session_state.get("mary_sensorial_level", 2))
    _sens_n = int(st.session_state.get("mary_sensorial_n", 2))
    mary_sens_txt = gerar_mary_sensorial(
        _sens_level, n=_sens_n, sintonia=bool(st.session_state.get("modo_sintonia", True))
    ) if _sens_on else ""

    # Sintonia & Ritmo
    modo_sintonia = bool(st.session_state.get("modo_sintonia", True))
    ritmo_cena = int(st.session_state.get("ritmo_cena", 1))
    ritmo_label = ["muito lento", "lento", "m√©dio", "r√°pido"][max(0, min(3, ritmo_cena))]

    # Hist√≥rico
    n_hist = int(st.session_state.get("n_sheet_prompt", 15))
    hist = carregar_interacoes(n=n_hist)
    hist_txt = "\n".join(f"{r.get('role','user')}: {r.get('content','')}" for r in hist) if hist else "(sem hist√≥rico)"
    ultima_fala_user = _last_user_text(hist)
    ancora = _deduzir_ancora(ultima_fala_user)
    ancora_bloco = ""
    if ancora:
        ancora_bloco = (
            "### √Çncora de cen√°rio (OBRIGAT√ìRIA)\n"
            f"- Local: **{ancora['local']}**\n"
            f"- Hora: **{ancora['hora']}**\n"
            "- Regra: mantenha a cena **neste local**; **n√£o** troque para UFES, bar, biblioteca etc.\n"
            "- Primeira frase deve ancorar **lugar e hora** neste formato: `Local ‚Äî Hora ‚Äî ...`.\n"
        )
    # Corte temporal
    if hist:
        ate_ts = _parse_ts(hist[-1].get("timestamp", ""))
    else:
        ate_ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
   
    # >>> Virgindade (auto, a partir de memoria_jm e corte temporal)
    virg_bloco = montar_bloco_virgindade(
        ativar=detectar_virgindade_mary(memos, ate_ts)
    )

    
    # Mem√≥ria longa Top-K (opcional)
    ml_topk_txt = "(nenhuma)"
    st.session_state["_ml_topk_texts"] = []
    if st.session_state.get("use_memoria_longa", True) and hist:
        try:
            topk = memoria_longa_buscar_topk(
                query_text=hist[-1]["content"],
                k=int(st.session_state.get("k_memoria_longa", 3)),
                limiar=float(st.session_state.get("limiar_memoria_longa", 0.78)),
                ate_ts=ate_ts,
            )
            if topk:
                ml_topk_txt = "\n".join([f"- {t}" for (t, _sc, _sim, _rr) in topk])
                st.session_state["_ml_topk_texts"] = [t for (t, *_rest) in topk]
        except Exception:
            st.session_state["_ml_topk_texts"] = []
    else:
        st.session_state["_ml_topk_texts"] = []

    # Diretrizes [all] respeitando o tempo
    recorrentes = [
        (d.get("conteudo") or "").strip()
        for d in memos.get("[all]", [])
        if isinstance(d, dict) and d.get("conteudo") and (not d.get("timestamp") or d.get("timestamp") <= ate_ts)
    ]
    st.session_state["_ml_recorrentes"] = recorrentes

    # Dossi√™ temporal
    dossie = []
    mary = persona_block_temporal("mary", memos, ate_ts, 8)
    janio = persona_block_temporal("janio", memos, ate_ts, 8)
    if mary: dossie.append(mary)
    if janio: dossie.append(janio)
    dossie_txt = "\n\n".join(dossie) if dossie else "(sem personas definidas)"

    flag_parallel = bool(st.session_state.get("no_coincidencias", True))

    # Falas da Mary (planilha)
    falas_mary_bloco = ""
    if st.session_state.get("usar_falas_mary", False):
        falas_mary = carregar_falas_mary()
        if falas_mary:
            falas_mary_bloco = "### Falas de Mary (usar literalmente)\n" + "\n".join(f"- {s}" for s in falas_mary)

    # Sintonia & Ritmo
    sintonia_bloco = ""
    if modo_sintonia:
        sintonia_bloco = (
            "### Sintonia & Ritmo (priorit√°rio)\n"
            f"- Ritmo da cena: **{ritmo_label}**.\n"
            "- Condu√ß√£o harm√¥nica: Mary sintoniza com o parceiro; evite ordens r√≠spidas. Prefira convites, sussurros, pedidos gentis.\n"
            "- Respeite pausas, respira√ß√£o, olhar; o desejo √© mostrado pela troca, n√£o por imposi√ß√£o.\n"
        )

   prompt = f"""
Voc√™ √© o Narrador de um roleplay dram√°tico brasileiro, foque em Mary e J√¢nio. N√£o repita instru√ß√µes nem t√≠tulos.

{ancora_bloco}{sintonia_bloco}{virg_bloco}### Dossi√™ (personas)
{dossie_txt}

### Diretrizes gerais (ALL)
{chr(10).join(f"- {c}" for c in recorrentes) if recorrentes else "(vazio)"}

### Perfil (resumo mais recente)
{perfil or "(vazio)"}

### Hist√≥rico recente (planilha)
{hist_txt}

### Estilo
- Use o estilo **{estilo}**:
{("- Frases curtas, cortes r√°pidos, foco em gesto/ritmo.") if estilo=="A√á√ÉO" else
("- Atmosfera sombria, subtexto, sil√™ncio que pesa.") if estilo=="NOIR" else
("- Ritmo lento, tens√£o emocional, detalhes sensoriais (sem grafismo).")}
- As falas de Mary devem soar naturais, diretas e sensoriais; evite grosserias. Ajuste o tom ao **modo de sintonia** e ao **ritmo**.

### Camada sensorial ‚Äî Mary (OBRIGAT√ìRIA no 1¬∫ par√°grafo)
{mary_sens_txt or "- Comece com 1‚Äì2 frases sobre caminhar/olhar/perfume/cabelos (negros, volumosos, levemente ondulados)."}
- Aplique essa camada ANTES do primeiro di√°logo.
- Frases curtas, f√≠sicas; evite met√°foras rebuscadas.

{falas_mary_bloco}

### Mem√≥ria longa ‚Äî Top-K relevantes
{ml_topk_txt}

### ‚è±Ô∏è Estado do romance (manual)
- Fase atual: {_fase_label(fase)}
- Permitidos: {fdata['permitidos']}
- Proibidos: {fdata['proibidos']}

### üéØ Momento dram√°tico (agora)
- Momento: {_momento_label(momento_atual)}
- Objetivo da cena: {mdata['objetivo']}
- Nesta cena, **permita**: {mdata['permitidos']}
- Evite/adiar: {mdata['proibidos']}
- **Micropassos:** avance no m√°ximo **{int(st.session_state.get("max_avancos_por_cena",1))}** subpasso(s) rumo a: {proximo_nome}.
- Se o roteirista pedir salto maior, **negocie** consentimento e **prepare** a transi√ß√£o.

### Geografia & Montagem
- **N√£o force coincid√™ncias**: sem ponte expl√≠cita, mantenha locais distintos e use **montagem paralela** (A/B) = {flag_parallel}.
- **Comece cada bloco** com uma frase que **ancore lugar e hora** (ex.: ‚ÄúLocal ‚Äî Hora ‚Äî ‚Ä¶‚Äù). Escreva isso na primeira frase do par√°grafo.
- Havendo ponte dieg√©tica plaus√≠vel, convergir ao final √© permitido (sem teletransporte).

### Formato OBRIGAT√ìRIO da cena
- **Inclua DI√ÅLOGOS diretos** com travess√£o (‚Äî), intercalados com a√ß√£o/rea√ß√£o f√≠sica/visual (m√≠nimo 4 falas).
- Garanta **pelo menos 2 falas de Mary e 2 de J√¢nio** (quando ambos estiverem na cena).
- **N√£o inclua** pensamentos em it√°lico, reflex√µes internas ou mon√≥logos subjetivos.
- Sem blocos finais de cr√©ditos, microconquistas, resumos ou ganchos.

### Regra de sa√≠da
- Narre em **terceira pessoa**; nunca fale com "voc√™".
- Produza uma cena fechada e natural.
""".strip()

    prompt = inserir_regras_mary_e_janio(prompt)
    return prompt

# =========================
# FILTROS DE SA√çDA
# =========================

def render_tail(t: str) -> str:
    if not t:
        return ""
    t = re.sub(r'^\s*\**\s*(microconquista|gancho)\s*:\s*.*$', '', t, flags=re.IGNORECASE | re.MULTILINE)
    t = re.sub(r'&lt;\s*think\s*&gt;.*?&lt;\s*/\s*think\s*&gt;', '', t, flags=re.IGNORECASE | re.DOTALL)
    t = re.sub(r'\n{3,}', '\n\n', t).strip()
    return t

EXPL_PAT = re.compile(
    r"\b(seio[s]?|mamilos?|bunda|fio[- ]?dental|genit[a√°]lia|ere[c√ß][a√£]o|penetra[c√ß][a√£]o|"
    r"boquete|gozada|gozo|sexo oral|chupar|enfiar)\b",
    flags=re.IGNORECASE
)

def classify_nsfw_level(t: str) -> int:
    if EXPL_PAT.search(t or ""):
        return 3
    if re.search(r"\b(cintura|pesco[c√ß]o|costas|beijo prolongado|respira[c√ß][a√£]o curta)\b", (t or ""), re.IGNORECASE):
        return 2
    if re.search(r"\b(olhar|aproximar|toque|m[a√£]os dadas|beijo)\b", (t or ""), re.IGNORECASE):
        return 1
    return 0

def sanitize_explicit(t: str, max_level: int, action: str) -> str:
    lvl = classify_nsfw_level(t)
    if lvl <= max_level:
        return t
    return t

def redact_for_logs(t: str) -> str:
    if not t:
        return ""
    t = re.sub(EXPL_PAT, "[‚Ä¶]", t, flags=re.IGNORECASE)
    return re.sub(r'\n{3,}', '\n\n', t).strip()

def resposta_valida(t: str) -> bool:
    if not t or t.strip() == "[Sem conte√∫do]":
        return False
    if len(t.strip()) < 5:
        return False
    return True

def precisa_reforcar_dialogo(texto: str) -> bool:
    if not texto:
        return True
    n_dialog = len(re.findall(r'(^|\n)\s*(‚Äî|")', texto))
    n_thoughts = len(re.findall(r'\*[^*\n]{4,}\*', texto))
    return (n_dialog < 4) or (n_thoughts < 2)

# =========================
# UI ‚Äî CABE√áALHO E CONTROLES
# =========================

st.title("üé¨ Narrador JM")
st.subheader("Voc√™ √© o roteirista. Digite uma dire√ß√£o de cena. A IA narrar√° Mary e J√¢nio.")
st.markdown("---")

# Estados b√°sicos
if "resumo_capitulo" not in st.session_state:
    st.session_state.resumo_capitulo = carregar_resumo_salvo()
if "session_msgs" not in st.session_state:
    st.session_state.session_msgs = []
if "use_memoria_longa" not in st.session_state:
    st.session_state.use_memoria_longa = True
if "k_memoria_longa" not in st.session_state:
    st.session_state.k_memoria_longa = 3
if "limiar_memoria_longa" not in st.session_state:
    st.session_state.limiar_memoria_longa = 0.78
if "app_bloqueio_intimo" not in st.session_state:
    st.session_state.app_bloqueio_intimo = False
if "app_emocao_oculta" not in st.session_state:
    st.session_state.app_emocao_oculta = "nenhuma"
if "mj_fase" not in st.session_state:
    st.session_state.mj_fase = mj_carregar_fase_inicial()
if "momento" not in st.session_state:
    st.session_state.momento = momento_carregar()
if "max_avancos_por_cena" not in st.session_state:
    st.session_state.max_avancos_por_cena = 1
if "estilo_escrita" not in st.session_state:
    st.session_state.estilo_escrita = "A√á√ÉO"
if "templates_jm" not in st.session_state:
    st.session_state.templates_jm = carregar_templates_planilha()
if "template_ativo" not in st.session_state:
    st.session_state.template_ativo = None
if "etapa_template" not in st.session_state:
    st.session_state.etapa_template = 0

col1, col2 = st.columns([3, 2])
with col1:
    st.markdown("#### üìñ √öltimo resumo salvo:")
    st.info(st.session_state.resumo_capitulo or "Nenhum resumo dispon√≠vel.")
with col2:
    st.markdown("#### ‚öôÔ∏è Op√ß√µes")
    st.write(
        f'- Bloqueio √≠ntimo: {"Sim" if st.session_state.get("app_bloqueio_intimo", False) else "N√£o"}\n'
        f'- Emo√ß√£o oculta: {st.session_state.get("app_emocao_oculta", "").capitalize()}'
    )

# =========================
# SIDEBAR ‚Äî Reorganizado
# =========================

with st.sidebar:
    st.title("üß≠ Painel do Roteirista")

    # Provedor/modelos
    provedor = st.radio("üåê Provedor", ["OpenRouter", "Together"], index=0, key="provedor_ia")
    api_url, api_key, modelos_map = api_config_for_provider(provedor)
    if not api_key:
        st.warning("‚ö†Ô∏è API key ausente para o provedor selecionado. Defina em st.secrets.")
    modelo_nome = st.selectbox("ü§ñ Modelo de IA", list(modelos_map.keys()), index=0, key="modelo_nome_ui")
    modelo_escolhido_id_ui = modelos_map[modelo_nome]
    st.session_state.modelo_escolhido_id = modelo_escolhido_id_ui

    st.markdown("---")
    st.markdown("### ‚úçÔ∏è Estilo & Progresso Dram√°tico")
    st.selectbox(
        "Estilo de escrita",
        ["A√á√ÉO", "ROMANCE LENTO", "NOIR"],
        index=["A√á√ÉO", "ROMANCE LENTO", "NOIR"].index(st.session_state.get("estilo_escrita", "A√á√ÉO")),
        key="estilo_escrita",
    )
    st.slider("N√≠vel de calor (0=leve, 3=expl√≠cito)", 0, 3, value=int(st.session_state.get("nsfw_max_level", 3)), key="nsfw_max_level")

    # Sintonia & Ritmo (DENTRO do sidebar)
    st.checkbox(
        "Sintonia com o parceiro (modo harm√¥nico)",
        key="modo_sintonia",
        value=st.session_state.get("modo_sintonia", True),
    )
    st.select_slider(
        "Ritmo da cena",
        options=[0, 1, 2, 3],
        value=int(st.session_state.get("ritmo_cena", 1)),
        format_func=lambda n: ["muito lento", "lento", "m√©dio", "r√°pido"][n],
        key="ritmo_cena",
    )

    # Falas de Mary ‚Äî planilha
    st.checkbox(
        "Usar falas da Mary da planilha (usar literalmente)",
        value=st.session_state.get("usar_falas_mary", False),
        key="usar_falas_mary",
    )

    st.markdown("---")
    st.markdown("### üíû Romance Mary & J√¢nio")
    fase_default = mj_carregar_fase_inicial()
    options_fase = sorted(FASES_ROMANCE.keys())
    fase_ui_val = int(st.session_state.get("mj_fase", fase_default))
    fase_ui_val = max(min(fase_ui_val, max(options_fase)), min(options_fase))
    fase_escolhida = st.select_slider("Fase do romance", options=options_fase, value=fase_ui_val, format_func=_fase_label, key="ui_mj_fase")
    if fase_escolhida != st.session_state.get("mj_fase", fase_default):
        mj_set_fase(fase_escolhida, persist=True)
    options_momento = sorted(MOMENTOS.keys())
    mom_default = momento_carregar()
    mom_ui_val = int(st.session_state.get("momento", mom_default))
    mom_ui_val = max(min(mom_ui_val, max(options_momento)), min(options_momento))
    mom_ui = st.select_slider("Momento atual", options=options_momento, value=mom_ui_val, format_func=_momento_label, key="ui_momento")
    if mom_ui != st.session_state.get("momento", mom_default):
        momento_set(mom_ui, persist=False)
    st.slider("Micropassos por cena", 1, 3, value=int(st.session_state.get("max_avancos_por_cena", 1)), key="max_avancos_por_cena")
    col_a, col_b = st.columns(2)
    with col_a:
        if st.button("‚ûï Avan√ßar 1 passo"):
            mj_set_fase(min(st.session_state.get("mj_fase", 0) + 1, max(options_fase)), persist=True)
    with col_b:
        if st.button("‚Ü∫ Reiniciar (0)"):
            mj_set_fase(0, persist=True)

    st.markdown("---")
    st.markdown("### üé¨ Roteiros Sequenciais (Templates)")
    nomes_templates = list(st.session_state.templates_jm.keys())
    if st.button("üîÑ Recarregar templates"):
        st.session_state.templates_jm = carregar_templates_planilha()
        st.success("Templates atualizados da planilha!")
    if nomes_templates:
        roteiro_escolhido = st.selectbox("Escolha o roteiro:", nomes_templates, key="sb_rota_sel")
        etapas = st.session_state.templates_jm.get(roteiro_escolhido, [])

        if st.button("Iniciar roteiro", key="btn_iniciar_roteiro"):
            st.session_state.template_ativo = roteiro_escolhido
            st.session_state.etapa_template = 0
            if etapas:
                comando = etapas[0]
                salvar_interacao("user", comando)
                st.session_state.session_msgs.append({"role": "user", "content": comando})
                st.session_state["_trigger_input"] = comando
                st.session_state.etapa_template = 1

        if st.session_state.get("template_ativo"):
            etapas_ativas = st.session_state.templates_jm.get(st.session_state.template_ativo, [])
            etap = int(st.session_state.get("etapa_template", 0))
            if etap < len(etapas_ativas):
                st.markdown(f"Etapa atual: {etap + 1} de {len(etapas_ativas)}")
                if st.button("Pr√≥xima etapa (*)", key="btn_proxima_etapa"):
                    comando = etapas_ativas[etap]
                    salvar_interacao("user", comando)
                    st.session_state.session_msgs.append({"role": "user", "content": comando})
                    st.session_state.etapa_template = etap + 1
                    st.session_state["_trigger_input"] = comando
            else:
                st.success("Roteiro conclu√≠do!")
                st.session_state.template_ativo = None
                st.session_state.etapa_template = 0
    else:
        st.info("Nenhum template encontrado na aba templates_jm.")

    st.markdown("---")
    st.checkbox(
        "Evitar coincid√™ncias for√ßadas (montagem paralela A/B)",
        value=st.session_state.get("no_coincidencias", True),
        key="no_coincidencias",
    )
    st.checkbox(
        "Bloquear avan√ßos √≠ntimos sem ordem",
        value=st.session_state.app_bloqueio_intimo,
        key="ui_bloqueio_intimo",
    )
    st.selectbox(
        "üé≠ Emo√ß√£o oculta",
        ["nenhuma", "tristeza", "felicidade", "tens√£o", "raiva"],
        index=["nenhuma", "tristeza", "felicidade", "tens√£o", "raiva"].index(st.session_state.app_emocao_oculta),
        key="ui_app_emocao_oculta",
    )
    st.session_state.app_bloqueio_intimo = st.session_state.get("ui_bloqueio_intimo", False)
    st.session_state.app_emocao_oculta = st.session_state.get("ui_app_emocao_oculta", "nenhuma")

    st.markdown("---")
    st.markdown("### ‚è±Ô∏è Comprimento/timeout")
    st.slider("Max tokens da resposta", 256, 2500, value=int(st.session_state.get("max_tokens_rsp", 1200)), step=32, key="max_tokens_rsp")
    st.slider("Timeout (segundos)", 60, 600, value=int(st.session_state.get("timeout_s", 300)), step=10, key="timeout_s")

    st.markdown("---")
    st.markdown("### üóÉÔ∏è Mem√≥ria Longa")
    st.checkbox("Usar mem√≥ria longa no prompt", value=st.session_state.get("use_memoria_longa", True), key="use_memoria_longa")
    st.slider("Top-K mem√≥rias", 1, 5, int(st.session_state.get("k_memoria_longa", 3)), 1, key="k_memoria_longa")
    st.slider("Limiar de similaridade", 0.50, 0.95, float(st.session_state.get("limiar_memoria_longa", 0.78)), 0.01, key="limiar_memoria_longa")

    st.markdown("---")
    if st.button("üìù Gerar resumo do cap√≠tulo"):
        try:
            inter = carregar_interacoes(n=6)
            texto = "\n".join(f"{r.get('role','user')}: {r.get('content','')}" for r in inter) if inter else ""
            prompt_resumo = (
                "Resuma o seguinte trecho como um cap√≠tulo de novela brasileiro, mantendo tom e emo√ß√µes.\n\n"
                + texto + "\n\nResumo:"
            )
            model_id_call = model_id_for_together(modelo_escolhido_id_ui) if provedor == "Together" else modelo_escolhido_id_ui
            r = requests.post(
                api_url,
                headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
                json={"model": model_id_call, "messages": [{"role": "user", "content": prompt_resumo}], "max_tokens": 800, "temperature": 0.85},
                timeout=int(st.session_state.get("timeout_s", 300)),
            )
            if r.status_code == 200:
                resumo = r.json()["choices"][0]["message"]["content"].strip()
                st.session_state.resumo_capitulo = resumo
                salvar_resumo(resumo)
                st.success("Resumo gerado e salvo com sucesso!")
            else:
                st.error(f"Erro ao resumir: {r.status_code} - {r.text}")
        except Exception as e:
            st.error(f"Erro ao gerar resumo: {e}")

    if st.button("üíæ Salvar √∫ltima resposta como mem√≥ria"):
        ultimo_assist = ""
        for m in reversed(st.session_state.get("session_msgs", [])):
            if m.get("role") == "assistant":
                ultimo_assist = m.get("content", "").strip()
                break
        if ultimo_assist:
            ok = memoria_longa_salvar(ultimo_assist, tags="auto")
            st.success("Mem√≥ria de longo prazo salva!" if ok else "Falha ao salvar mem√≥ria.")
        else:
            st.info("Ainda n√£o h√° resposta do assistente nesta sess√£o.")

    if st.button("üîÅ Refor√ßar mem√≥rias biogr√°ficas"):
        memos = carregar_memorias_brutas()
        count = 0
        for k in ["[mary]", "[janio]", "[all]"]:
            for entrada in memos.get(k, []):
                texto = entrada.get("conteudo", "").strip()
                if texto:
                    ok = memoria_longa_salvar(texto, tags=k)
                    if ok: count += 1
        st.success(f"{count} mem√≥rias biogr√°ficas refor√ßadas na mem√≥ria longa!")

    st.markdown("### üß© Hist√≥rico no prompt")
    st.slider("Intera√ß√µes do Sheets (N)", 10, 30, value=int(st.session_state.get("n_sheet_prompt", 15)), step=1, key="n_sheet_prompt")

# =========================
# EXIBIR HIST√ìRICO
# =========================

with st.container():
    interacoes = carregar_interacoes(n=20)
    for r in interacoes:
        role = r.get("role", "user")
        content = r.get("content", "")
        if role == "user":
            with st.chat_message("user"):
                st.markdown(content)
        else:
            with st.chat_message("assistant"):
                st.markdown(content)
    if st.session_state.get("resumo_capitulo"):
        with st.expander("üß† Resumo do cap√≠tulo (mais recente)"):
            st.markdown(st.session_state.resumo_capitulo)

# =========================
# ENVIO DO USU√ÅRIO + STREAMING
# =========================

entrada = st.chat_input("Digite sua dire√ß√£o de cena...")

if entrada:
    try:
        mom_atual = int(st.session_state.get("momento", momento_carregar()))
        mom_sug   = detectar_momento_sugerido(entrada, fallback=mom_atual)
        mom_novo  = clamp_momento(mom_atual, mom_sug, int(st.session_state.get("max_avancos_por_cena", 1)))
        if st.session_state.get("app_bloqueio_intimo", False):
            mom_novo = clamp_momento(mom_atual, mom_sug, 1)
        momento_set(mom_novo, persist=False)
    except Exception:
        pass

    salvar_interacao("user", str(entrada))
    st.session_state.session_msgs.append({"role": "user", "content": str(entrada)})

    prompt = construir_prompt_com_narrador()

    historico = [{"role": m.get("role", "user"), "content": m.get("content", "")}
                 for m in st.session_state.session_msgs]

    prov = st.session_state.get("provedor_ia", "OpenRouter")
    if prov == "Together":
        endpoint = "https://api.together.xyz/v1/chat/completions"
        auth = st.secrets.get("TOGETHER_API_KEY", "")
        model_to_call = model_id_for_together(st.session_state.modelo_escolhido_id)
    else:
        endpoint = "https://openrouter.ai/api/v1/chat/completions"
        auth = st.secrets.get("OPENROUTER_API_KEY", "")
        model_to_call = st.session_state.modelo_escolhido_id

    if not auth:
        st.error("A chave de API do provedor selecionado n√£o foi definida em st.secrets.")
        st.stop()

    system_pt = {"role": "system", "content": "Responda em portugu√™s do Brasil. Mostre apenas a narrativa final."}
    messages = [system_pt, {"role": "system", "content": prompt}] + historico

    payload = {
        "model": model_to_call,
        "messages": messages,
        "max_tokens": int(st.session_state.get("max_tokens_rsp", 1200)),
        "temperature": 0.9,
        "stream": True,
    }
    headers = {"Authorization": f"Bearer {auth}", "Content-Type": "application/json"}

    def _render_visible(t: str) -> str:
        out = render_tail(t)
        out = sanitize_explicit(out, max_level=int(st.session_state.get("nsfw_max_level", 3)), action="livre")
        return out

    with st.chat_message("assistant"):
        placeholder = st.empty()
        resposta_txt = ""
        last_update = time.time()

        try:
            usados_prompt = []
            usados_prompt.extend(st.session_state.get("_ml_topk_texts", []))
            usados_prompt.extend(st.session_state.get("_ml_recorrentes", []))
            usados_prompt = [t for t in usados_prompt if t]
            if usados_prompt:
                memoria_longa_reforcar(usados_prompt)
        except Exception:
            pass

        try:
            with requests.post(endpoint, headers=headers, json=payload, stream=True,
                               timeout=int(st.session_state.get("timeout_s", 300))) as r:
                if r.status_code == 200:
                    for raw in r.iter_lines(decode_unicode=False):
                        if not raw: continue
                        line = raw.decode("utf-8", errors="ignore").strip()
                        if not line.startswith("data:"): continue
                        data = line[5:].strip()
                        if data == "[DONE]": break
                        try:
                            j = json.loads(data)
                            delta = j["choices"][0]["delta"].get("content", "")
                            if not delta: continue
                            resposta_txt += delta
                            if time.time() - last_update > 0.10:
                                placeholder.markdown(_render_visible(resposta_txt) + "‚ñå")
                                last_update = time.time()
                        except Exception:
                            continue
                else:
                    st.error(f"Erro {('Together' if prov=='Together' else 'OpenRouter')}: {r.status_code} - {r.text}")
        except Exception as e:
            st.error(f"Erro no streaming: {e}")

        visible_txt = _render_visible(resposta_txt).strip()
        if not visible_txt:
            try:
                r2 = requests.post(endpoint, headers=headers,
                                   json={**payload, "stream": False},
                                   timeout=int(st.session_state.get("timeout_s", 300)))
                if r2.status_code == 200:
                    try:
                        resposta_txt = r2.json()["choices"][0]["message"]["content"].strip()
                    except Exception:
                        resposta_txt = ""
                    visible_txt = _render_visible(resposta_txt).strip()
                else:
                    st.error(f"Fallback (sem stream) falhou: {r2.status_code} - {r2.text}")
            except Exception as e:
                st.error(f"Fallback (sem stream) erro: {e}")

        if not visible_txt:
            try:
                r3 = requests.post(
                    endpoint, headers=headers,
                    json={
                        "model": model_to_call,
                        "messages": [{"role": "system", "content": prompt}] + historico,
                        "max_tokens": int(st.session_state.get("max_tokens_rsp", 1200)),
                        "temperature": 0.9,
                        "stream": False,
                    },
                    timeout=int(st.session_state.get("timeout_s", 300))
                )
                if r3.status_code == 200:
                    try:
                        resposta_txt = r3.json()["choices"][0]["message"]["content"].strip()
                    except Exception:
                        resposta_txt = ""
                    visible_txt = _render_visible(resposta_txt).strip()
                else:
                    st.error(f"Fallback (prompts limpos) falhou: {r3.status_code} - {r3.text}")
            except Exception as e:
                st.error(f"Fallback (prompts limpos) erro: {e}")

        placeholder.markdown(visible_txt if visible_txt else "[Sem conte√∫do]")

        try:
            viol = viola_momento(visible_txt, int(st.session_state.get("momento", 0)))
            if viol and st.session_state.get("app_bloqueio_intimo", False):
                st.info(f"‚ö†Ô∏è {viol}")
        except Exception:
            pass

        if len(st.session_state.session_msgs) >= 1 and visible_txt and visible_txt != "[Sem conte√∫do]":
            texto_anterior = st.session_state.session_msgs[-1]["content"]
            alerta = verificar_quebra_semantica_openai(texto_anterior, visible_txt)
            if alerta:
                st.info(alerta)

        salvar_interacao("assistant", visible_txt if visible_txt else "[Sem conte√∫do]")
        st.session_state.session_msgs.append({"role": "assistant", "content": visible_txt if visible_txt else "[Sem conte√∫do]"})

        try:
            usados = []
            topk_usadas = memoria_longa_buscar_topk(
                query_text=visible_txt,
                k=int(st.session_state.k_memoria_longa),
                limiar=float(st.session_state.limiar_memoria_longa),
            )
            for t, _sc, _sim, _rr in topk_usadas:
                usados.append(t)
            memoria_longa_reforcar(usados)
        except Exception:
            pass


