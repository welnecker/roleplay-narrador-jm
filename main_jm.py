import streamlit as st
import gspread
import json
import requests
import time
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials

st.set_page_config(page_title="Narrador JM", page_icon="üé¨")

def conectar_planilha():
    try:
        creds_dict = json.loads(st.secrets["GOOGLE_CREDS_JSON"])
        creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive",
        ]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        return client.open_by_key("1f7LBJFlhJvg3NGIWwpLTmJXxH9TH-MNn3F4SQkyfZNM")
    except Exception as e:
        st.error(f"Erro ao conectar √† planilha: {e}")
        return None

planilha = conectar_planilha()

def carregar_memorias():
    try:
        aba = planilha.worksheet("memorias_jm")
        registros = aba.get_all_records()
        mem_mary = [r["conteudo"] for r in registros if r.get("tipo", "").strip().lower() == "[mary]"]
        mem_janio = [r["conteudo"] for r in registros if r.get("tipo", "").strip().lower() == "[j√¢nio]"]
        mem_all = [r["conteudo"] for r in registros if r.get("tipo", "").strip().lower() == "[all]"]
        return mem_mary, mem_janio, mem_all
    except Exception as e:
        st.warning(f"Erro ao carregar mem√≥rias: {e}")
        return [], [], []

def carregar_resumo_salvo():
    try:
        aba = planilha.worksheet("perfil_jm")
        valores = aba.col_values(7)
        for val in reversed(valores[1:]):
            if val and val.strip():
                return val.strip()
        return ""
    except Exception as e:
        st.warning(f"Erro ao carregar resumo salvo: {e}")
        return ""

def salvar_resumo(resumo: str):
    try:
        aba = planilha.worksheet("perfil_jm")
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        linha = ["", "", "", "", "", timestamp, resumo]
        aba.append_row(linha, value_input_option="RAW")
    except Exception as e:
        st.error(f"Erro ao salvar resumo: {e}")

def salvar_interacao(role: str, content: str):
    if not planilha:
        return
    try:
        aba = planilha.worksheet("interacoes_jm")
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        aba.append_row([timestamp, role.strip(), content.strip()], value_input_option="RAW")
    except Exception as e:
        st.error(f"Erro ao salvar intera√ß√£o: {e}")

def construir_prompt_com_narrador():
    mem_mary, mem_janio, mem_all = carregar_memorias()
    emocao = st.session_state.get("emocao_oculta", "nenhuma")
    resumo = st.session_state.get("resumo_capitulo", "")

    try:
        aba = planilha.worksheet("interacoes_jm")
        registros = aba.get_all_records()
        ultimas = registros[-15:] if len(registros) > 15 else registros
        texto_ultimas = "\n".join(f"{r['role']}: {r['content']}" for r in ultimas)
    except:
        texto_ultimas = ""

    prompt = (
        "Voc√™ √© o narrador de uma hist√≥ria em constru√ß√£o. Os protagonistas s√£o Mary e J√¢nio.\n\n"
        "Sua fun√ß√£o √© narrar cenas com naturalidade e profundidade. Use narra√ß√£o em 3¬™ pessoa e falas/pensamentos dos personagens em 1¬™ pessoa.\n\n"
        "‚õî Jamais antecipe encontros, conex√µes emocionais ou cenas √≠ntimas sem ordem expl√≠cita do roteirista.\n\n"
        f"üé≠ Emo√ß√£o oculta da cena: {emocao}\n\n"
        "üìñ Cap√≠tulo anterior:\n"
        f"{resumo if resumo else 'Nenhum resumo salvo.'}\n\n"
        "### üß† Mem√≥rias:\n"
        "Mary:\n- " + ("\n- ".join(mem_mary) if mem_mary else "Nenhuma.") + "\n\n"
        "J√¢nio:\n- " + ("\n- ".join(mem_janio) if mem_janio else "Nenhuma.") + "\n\n"
        "Compartilhadas:\n- " + ("\n- ".join(mem_all) if mem_all else "Nenhuma.") + "\n\n"
        "### üìñ √öltimas intera√ß√µes:\n"
        f"{texto_ultimas}"
    )
    return prompt.strip()

# =========================== #
# Provedores e Modelos (IDs exatos)
# =========================== #
MODELOS_OPENROUTER = {
    "üí¨ DeepSeek V3 ‚òÖ‚òÖ‚òÖ‚òÖ ($)": "deepseek/deepseek-chat-v3-0324",
    "üß† DeepSeek R1 0528 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$)": "deepseek/deepseek-r1-0528",
    "üß† DeepSeek R1T2 Chimera ‚òÖ‚òÖ‚òÖ‚òÖ (free)": "tngtech/deepseek-r1t2-chimera:free",
    "üß† GPT-4.1 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (1M ctx)": "openai/gpt-4.1",
    "üëë WizardLM 8x22B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$$)": "microsoft/wizardlm-2-8x22b",
    "üëë Qwen 235B 2507 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (PAID)": "qwen/qwen3-235b-a22b-07-25",
    "üëë EVA Qwen2.5 72B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-qwen-2.5-72b",
    "üëë EVA Llama 3.33 70B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-llama-3.33-70b",
    "üé≠ Nous Hermes 2 Yi 34B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ": "nousresearch/nous-hermes-2-yi-34b",
    "üî• MythoMax 13B ‚òÖ‚òÖ‚òÖ‚òÜ ($)": "gryphe/mythomax-l2-13b",
    "üíã LLaMA3 Lumimaid 8B ‚òÖ‚òÖ‚òÜ ($)": "neversleep/llama-3-lumimaid-8b",
    "üåπ Midnight Rose 70B ‚òÖ‚òÖ‚òÖ‚òÜ": "sophosympatheia/midnight-rose-70b",
    "üå∂Ô∏è Noromaid 20B ‚òÖ‚òÖ‚òÜ": "neversleep/noromaid-20b",
    "üíÄ Mythalion 13B ‚òÖ‚òÖ‚òÜ": "pygmalionai/mythalion-13b",
    "üêâ Anubis 70B ‚òÖ‚òÖ‚òÜ": "thedrummer/anubis-70b-v1.1",
    "üßö Rocinante 12B ‚òÖ‚òÖ‚òÜ": "thedrummer/rocinante-12b",
    "üç∑ Magnum v2 72B ‚òÖ‚òÖ‚òÜ": "anthracite-org/magnum-v2-72b",
}

MODELOS_TOGETHER = {
    "üß† Qwen3 Coder 480B (Together)": "togethercomputer/qwen3-coder-480b-a35b-instruct",
    "üëë Mixtral 8x7B v0.1 (Together)": "mistralai/mixtral-8x7b-instruct-v0.1",
}


# =========================== #
# Sidebar ‚Äì provedor, modelo e resumo
# =========================== #
with st.sidebar:
    st.title("üß≠ Painel do Roteirista")

    provedor = st.radio("Provedor de IA", ["OpenRouter", "Together"], index=0, key="provedor_ia")

    # Modelos por provedor
    if provedor == "OpenRouter":
        modelos_disponiveis = MODELOS_OPENROUTER
        api_url = "https://openrouter.ai/api/v1/chat/completions"
        api_key = st.secrets["OPENROUTER_API_KEY"]
    else:
        modelos_disponiveis = MODELOS_TOGETHER
        api_url = "https://api.together.xyz/v1/chat/completions"
        api_key = st.secrets["TOGETHER_API_KEY"]

    modelo_nome = st.selectbox("ü§ñ Modelo de IA", list(modelos_disponiveis.keys()), index=0, key="modelo_ia_nome")
    modelo_id = modelos_disponiveis[modelo_nome]

    # Persistir na sess√£o
    st.session_state.api_url = api_url
    st.session_state.api_key = api_key
    st.session_state.modelo_id = modelo_id

    st.markdown("---")
    st.caption("Gerar resumo usando o modelo selecionado acima")
    if st.button("üìù Gerar resumo do cap√≠tulo"):
        try:
            aba_i = planilha.worksheet("interacoes_jm")
            registros = aba_i.get_all_records()
            ultimas = registros[-6:] if len(registros) > 6 else registros
            texto = "
".join(f"{r['role']}: {r['content']}" for r in ultimas)
            prompt_resumo = (
                "Resuma o seguinte trecho como um cap√≠tulo de novela brasileiro, mantendo tom e emo√ß√µes.

"
                + texto
                + "

Resumo:"
            )

            r = requests.post(
                st.session_state.api_url,
                headers={
                    "Authorization": f"Bearer {st.session_state.api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": st.session_state.modelo_id,
                    "messages": [{"role": "user", "content": prompt_resumo}],
                    "max_tokens": 800,
                    "temperature": 0.85,
                },
                timeout=120,
            )
            if r.status_code == 200:
                novo_resumo = r.json()["choices"][0]["message"]["content"].strip()
                salvar_resumo(novo_resumo)
                st.session_state.resumo_capitulo = novo_resumo
                st.success("Resumo gerado e salvo com sucesso!")
            else:
                st.error(f"Erro ao resumir: {r.status_code} - {r.text}")
        except Exception as e:
            st.error(f"Erro ao gerar resumo: {e}")

    st.markdown("---")
    st.caption("Op√ß√µes de narrativa")
    st.session_state.bloqueio_intimo = st.checkbox("Bloquear avan√ßos √≠ntimos sem ordem", value=False)
    st.session_state.emocao_oculta = st.selectbox(
        "üé≠ Emo√ß√£o oculta", ["nenhuma", "tristeza", "felicidade", "tens√£o", "raiva"], index=0
    )

# =========================== #
# Tela principal ‚Äì t√≠tulo, resumo e hist√≥rico
# =========================== #
st.title("üé¨ Narrador JM")
st.subheader("Voc√™ √© o roteirista. Digite uma dire√ß√£o de cena. A IA narrar√° Mary e J√¢nio.")
st.markdown("---")

# Carregar resumo ao iniciar (apenas 1x)
if "resumo_capitulo" not in st.session_state:
    st.session_state.resumo_capitulo = carregar_resumo_salvo()

st.markdown("#### üìñ √öltimo resumo salvo:")
st.info(st.session_state.resumo_capitulo or "Nenhum resumo dispon√≠vel.")

# Mostrar hist√≥rico recente de intera√ß√µes (role para cima para ver mais antigas)
with st.container():
    try:
        aba = planilha.worksheet("interacoes_jm")
        registros = aba.get_all_records()
        ultimas = registros[-20:] if len(registros) > 20 else registros
        for r in ultimas:
            role = r.get("role", "user")
            content = r.get("content", "")
            if role == "user":
                with st.chat_message("user"):
                    st.markdown(content)
            else:
                with st.chat_message("assistant"):
                    st.markdown(content)
    except Exception as e:
        st.warning(f"Erro ao carregar intera√ß√µes: {e}")

# =========================== #
# Entrada de cena e gera√ß√£o (com digita√ß√£o)
# =========================== #

def exibir_resposta_digitando(texto: str, delay: float = 0.02):
    box = st.empty()
    acumulado = ""
    for ch in texto:
        acumulado += ch
        box.markdown(acumulado)
        time.sleep(delay)

entrada_usuario = st.chat_input("Digite sua dire√ß√£o de cena...")
if entrada_usuario:
    salvar_interacao("user", entrada_usuario)

    prompt = construir_prompt_com_narrador() + f"

üé¨ Dire√ß√£o do roteirista: {entrada_usuario}"

    try:
        resp = requests.post(
            st.session_state.api_url,
            headers={
                "Authorization": f"Bearer {st.session_state.api_key}",
                "Content-Type": "application/json",
            },
            json={
                "model": st.session_state.modelo_id,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 1000,
                "temperature": 0.85,
            },
            timeout=180,
        )
        if resp.status_code == 200:
            conteudo = resp.json()["choices"][0]["message"]["content"].strip()
            salvar_interacao("assistant", conteudo)
            exibir_resposta_digitando(conteudo)
        else:
            st.error(f"Erro {resp.status_code} - {resp.text}")
    except Exception as e:
        st.error(f"Erro ao gerar resposta: {e}")



