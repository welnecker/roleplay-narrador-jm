import streamlit as st
import gspread
import json
import re
import requests
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials

st.set_page_config(page_title="Narrador JM", page_icon="üé¨")

# --------------------------- #
# Conectar √† planilha
# --------------------------- #
def conectar_planilha():
    try:
        creds_dict = json.loads(st.secrets["GOOGLE_CREDS_JSON"])
        creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive"
        ]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        return client.open_by_key("1f7LBJFlhJvg3NGIWwpLTmJXxH9TH-MNn3F4SQkyfZNM")
    except Exception as e:
        st.error(f"Erro ao conectar √† planilha: {e}")
        return None

planilha = conectar_planilha()

# --------------------------- #
# Carregar perfis e mem√≥rias
# --------------------------- #
def carregar_perfis():
    try:
        aba = planilha.worksheet("perfil_jm")
        dados = aba.get_all_values()
        resumo_mary, resumo_janio = "", ""
        for linha in dados[1:]:
            if linha[0].strip().lower() == "mary" and len(linha) >= 7:
                resumo_mary = linha[6].strip()
            if linha[0].strip().lower() == "j√¢nio" and len(linha) >= 7:
                resumo_janio = linha[6].strip()
        return resumo_mary, resumo_janio
    except Exception as e:
        st.error(f"Erro ao carregar perfis: {e}")
        return "", ""

def carregar_memorias():
    try:
        aba = planilha.worksheet("memorias_jm")
        registros = aba.get_all_records()
        mem_mary = [r["conteudo"] for r in registros if r["tipo"].strip().lower() == "[mary]"]
        mem_janio = [r["conteudo"] for r in registros if r["tipo"].strip().lower() == "[j√¢nio]"]
        mem_all = [r["conteudo"] for r in registros if r["tipo"].strip().lower() == "[all]"]
        return mem_mary, mem_janio, mem_all
    except Exception as e:
        st.warning(f"Erro ao carregar mem√≥rias: {e}")
        return [], [], []

# --------------------------- #
# Construir prompt narrativo
# --------------------------- #
def construir_prompt_com_narrador():
    resumo_mary, resumo_janio = carregar_perfis()
    mem_mary, mem_janio, mem_all = carregar_memorias()
    emocao = st.session_state.get("emocao_oculta", "nenhuma")

    prompt = f"""
Voc√™ √© o narrador de uma hist√≥ria em constru√ß√£o. Os protagonistas s√£o:

üî¥ Mary ‚Äî {resumo_mary}
üîµ J√¢nio ‚Äî {resumo_janio}

Sua fun√ß√£o √© narrar cenas com naturalidade e profundidade. Use narra√ß√£o em 3¬™ pessoa e falas/pensamentos dos personagens em 1¬™ pessoa.

‚õî Jamais antecipe encontros, conex√µes emocionais ou cenas √≠ntimas sem ordem expl√≠cita do roteirista.

üé≠ Emo√ß√£o oculta da cena: {emocao}

### üß† Mem√≥rias:
Mary:
- {'\n- '.join(mem_mary) if mem_mary else 'Nenhuma.'}

J√¢nio:
- {'\n- '.join(mem_janio) if mem_janio else 'Nenhuma.'}

Compartilhadas:
- {'\n- '.join(mem_all) if mem_all else 'Nenhuma.'}
"""
    return prompt.strip()

# --------------------------- #
# Salvar intera√ß√£o
# --------------------------- #
def salvar_interacao(role, content):
    if not planilha:
        return
    try:
        aba = planilha.worksheet("interacoes_jm")
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        aba.append_row([timestamp, role.strip(), content.strip()], value_input_option="RAW")
    except Exception as e:
        st.error(f"Erro ao salvar intera√ß√£o: {e}")

# --------------------------- #
# Sidebar (modelos, emo√ß√£o)
# --------------------------- #
with st.sidebar:
    st.title("üéõÔ∏è Controle do Roteirista")

    modelos = {
        "üí¨ DeepSeek V3 (OpenRouter)": "deepseek/deepseek-chat-v3-0324",
        "üß† GPT-4.1 (OpenRouter)": "openai/gpt-4.1"
    }
    modelo_nome = st.selectbox("ü§ñ Modelo de IA", list(modelos.keys()), index=0)
    st.session_state.modelo_escolhido = modelos[modelo_nome]

    emocao = st.selectbox("üé≠ Emo√ß√£o oculta da cena", ["nenhuma", "tristeza", "felicidade", "tens√£o", "raiva"], index=0)
    st.session_state.emocao_oculta = emocao

    if st.button("üìù Gerar resumo do cap√≠tulo"):
        try:
            aba = planilha.worksheet("interacoes_jm")
            registros = aba.get_all_records()
            ultimas = registros[-6:] if len(registros) > 6 else registros
            texto = "\n".join(f"{r['role']}: {r['content']}" for r in ultimas)
            prompt_resumo = f"Resuma o seguinte trecho como um cap√≠tulo de novela:\n\n{texto}\n\nResumo:"

            resposta = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {st.secrets['OPENROUTER_API_KEY']}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "deepseek/deepseek-chat-v3-0324",
                    "messages": [{"role": "user", "content": prompt_resumo}],
                    "max_tokens": 800,
                    "temperature": 0.85
                }
            )
            if resposta.status_code == 200:
                resumo = resposta.json()["choices"][0]["message"]["content"]
                st.success("Resumo gerado com sucesso!")
                st.text_area("üìñ Cap√≠tulo anterior", resumo, height=200)
            else:
                st.error("Erro ao gerar resumo.")
        except Exception as e:
            st.error(f"Erro ao resumir: {e}")

# --------------------------- #
# Interface principal
# --------------------------- #
st.title("üé¨ Narrador JM")
st.markdown("Voc√™ √© o roteirista. Digite uma dire√ß√£o de cena. A IA narrar√° Mary e J√¢nio.")

entrada = st.chat_input("Ex: Mary acorda atrasada. J√¢nio est√° malhando na academia...")
if "historico" not in st.session_state:
    st.session_state.historico = []

if entrada:
    st.chat_message("user").markdown(entrada)
    salvar_interacao("user", entrada)
    st.session_state.historico.append({"role": "user", "content": entrada})

    prompt = construir_prompt_com_narrador()
    mensagens = [{"role": "system", "content": prompt}] + st.session_state.historico

    st.chat_message("assistant").markdown("*(Narrando...)*")
    try:
        resposta = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {st.secrets['OPENROUTER_API_KEY']}",
                "Content-Type": "application/json"
            },
            json={
                "model": st.session_state.modelo_escolhido,
                "messages": mensagens,
                "max_tokens": 800,
                "temperature": 0.85
            },
            timeout=120
        )
        if resposta.status_code == 200:
            conteudo = resposta.json()["choices"][0]["message"]["content"]
            salvar_interacao("assistant", conteudo)
            st.session_state.historico.append({"role": "assistant", "content": conteudo})
            st.chat_message("assistant").markdown(conteudo)
        else:
            st.error("Erro ao gerar resposta da IA.")
    except Exception as e:
        st.error(f"Erro de conex√£o: {e}")

# Exibir hist√≥rico
for msg in st.session_state.historico:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
