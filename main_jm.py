# roleplay_narrador_jm_clean_messages.py
# ---------------------------------------------------------------------------------
# Objetivo: manter toda a ESTRUTURA DE MODELOS do app original, mas
# ENVIAR APENAS MENSAGENS M√çNIMAS aos modelos (sem prompts auxiliares, fases, etc.).
# - System √∫nico (persona Mary)
# - Hist√≥rico user/assistant como est√°
# - Persist√™ncia s√≥ em "interacoes_jm"
# ---------------------------------------------------------------------------------

import json
import re
import random
from datetime import datetime
from typing import Dict, List, Any
import gspread
import requests
import streamlit as st
from gspread.exceptions import APIError, GSpreadException
from oauth2client.service_account import ServiceAccountCredentials
from huggingface_hub import InferenceClient

st.set_page_config(page_title="Narrador JM ‚Äî Clean Messages", page_icon="üé¨")

# ------------------------
# Presets de Modo de Fala
# ------------------------
FALA_PRESETS: Dict[str, Dict[str, str]] = {
    "Oral": {
        "rule": "‚Äî Sexy: carga er√≥tica verbal com descri√ß√£o gr√°fica; NSFW liberado.",
        "example": "tira minha calcinha; Chupa meu clit√≥ris; me faz gozar; vou gozar....chupa gostoso "
    },
    "Boquete": {
        "rule": "‚Äî Sexy: carga er√≥tica verbal com descri√ß√£o gr√°fica; NSFW liberado.",
        "example": "tira essa cal√ßa; deixa eu chupar seu pau; como √© grande e grosso...hummm; goza na minha boca... "
    },
    "cavalga": {
        "rule": "‚Äî Sexy: carga er√≥tica verbal com descri√ß√£o gr√°fica; NSFW liberado.",
        "example": "deita amor...vou montar em voc√™; fode gostoso; calma..n√£o goza ainda; t√° gostoso?.. pega na minha bunda; isso...goza..."
    },
    "quatro": {
        "rule": "‚Äî Sexy: carga er√≥tica verbal com descri√ß√£o gr√°fica; NSFW liberado.",
        "example": "Vem...mete por tr√°s; porra...que del√≠cia; empurra tudo...humm; calma..n√£o goza ainda; deixa eu rebolar...fica parado; isso...goza...."
    },
    "Ciumenta": {
        "rule": "‚Äî Ciumenta: marca territ√≥rio com eleg√¢ncia; perguntas diretas; limites claros; nada de insultos.",
        "example": "Quem √© essa piranha?."
    },
}

CARINHOSA_FRASES = [
    '‚Äî "Voc√™ √© uma gra√ßa, sabia?"',
    '‚Äî "√â t√£o bonitinho quando voc√™ fica inseguro."',
    '‚Äî "Vem c√°‚Ä¶ me d√° um abra√ßo."',
    '‚Äî "Eu gosto de ouvir voc√™ assim, sem pressa."',
    '‚Äî "Fica perto de mim um pouquinho?"',
    '‚Äî "T√° tudo bem. Eu t√¥ aqui."',
    '‚Äî "Adoro quando voc√™ confia em mim."',
    '‚Äî "Deixa eu cuidar de voc√™ agora?"',
]

_TRIG_CARINHO = re.compile(
    r"(?i)\b(n[√£a]o sei|talvez|acho que|t[o√¥] com medo|insegur|desculp|ser[a√°] que|pode ser)\b|[?]\s*$"
)

def inject_carinhosa(texto: str, user_text: str, ativo: bool) -> str:
    if not ativo or not texto.strip():
        return texto
    gatilho = bool(_TRIG_CARINHO.search(user_text or "")) or (random.random() < 0.25)
    if not gatilho:
        return texto
    frase = random.choice(CARINHOSA_FRASES)
    # mant√©m estilo: novo par√°grafo curto, 1‚Äì2 frases
    sep = "\n\n" if not texto.endswith("\n") else "\n"
    return (texto.rstrip() + f"{sep}{frase}").strip()


def build_fala_block(modos: List[str]) -> str:
    if not modos:
        return ""
    linhas = ["[MODO DE FALA ‚Äî Mary]", "‚Äî Modos ativos: " + ", ".join(modos) + "."]
    for m in modos:
        if m in FALA_PRESETS:
            linhas.append(FALA_PRESETS[m]["rule"])
    linhas.append("‚Äî Responda mantendo este(s) tom(ns) em falas e narra√ß√£o de Mary.")
    return "\n".join(linhas)




# ================================
# UI ‚Äî Roleplay comercial (cards)
# ================================
with st.sidebar:
    st.subheader("Roleplay comercial")
    st.session_state.setdefault("user_name", "")
    st.session_state["user_name"] = st.text_input(
        "Seu nome (como o personagem vai se referir a voc√™)",
        value=st.session_state["user_name"],
        max_chars=40,
    )
    st.session_state.setdefault("scenario_init", "")
    st.session_state.setdefault("plot_init", "")
    st.session_state["scenario_init"] = st.text_area(
        "Cen√°rio inicial",
        value=st.session_state["scenario_init"],
        height=80,
        placeholder="Ex.: Final de tarde na Praia de Camburi; quiosque perto do cal√ßad√£o‚Ä¶",
    )
    st.session_state["plot_init"] = st.text_area(
        "Enredo inicial",
        value=st.session_state["plot_init"],
        height=80,
        placeholder="Ex.: Mary encontra o usu√°rio ap√≥s um mal-entendido com Ricardo‚Ä¶",
    )

with st.sidebar:
    st.markdown("**Modo de fala da Mary**")
    st.session_state.setdefault("fala_mods", [])

    # 5 caixas de sele√ß√£o (podem combinar)
    mods_escolhidos: List[str] = []
    if st.checkbox("Boquete", value=True, key="fala_Boquete"):
        mods_escolhidos.append("Boquete")
    if st.checkbox("Oral", key="fala_Oral"):
        mods_escolhidos.append("Oral")
    if st.checkbox("cavalga", key="fala_cavalga"):
        mods_escolhidos.append("cavalga")
    if st.checkbox("quatro", key="fala_quatro"):
        mods_escolhidos.append("quatro")
    if st.checkbox("Ciumenta", key="fala_ciumenta"):
        mods_escolhidos.append("Ciumenta")

    if st.checkbox("Carinhosa", key="fala_carinhosa"):
        mods_escolhidos.append("Carinhosa")
    
    st.session_state["fala_mods"] = mods_escolhidos
    
    # (Opcional) dicas r√°pidas do tom atual
    if mods_escolhidos:
        exemplos = [
            FALA_PRESETS.get(m, {}).get("example")
            for m in mods_escolhidos if FALA_PRESETS.get(m)
        ]
        exemplos = [e for e in exemplos if e]
        if exemplos:
            st.caption("Exemplos de abertura (tom atual): " + " / ".join(exemplos[:3]))


# --------- Filtro: silenciar falas/mensagens de J√¢nio (robusto) ---------
def _is_quoted_or_bulleted(line: str) -> bool:
    s = line.lstrip()
    return (
        s.startswith('‚Äî') or
        s.startswith('"') or s.startswith('‚Äú') or
        s.startswith('*"') or s.startswith('*‚Äú') or
        s[:2] in ('- ', '* ') or
        (len(s) > 2 and s[0].isdigit() and s[1] in '.)')
    )

# --------- Silenciar falas/mensagens de J√¢nio (sem trocar o nome) ---------
JANIO_SPEECH = re.compile(r'(?i)^\s*(?:j√¢nio|janio)\s*:\s+.*$')
JANIO_ATTR_QUOTE = re.compile(r'(?i)^\s*‚Äî\s*[\"‚Äú].*[\"‚Äù].*(?:‚Äî\s*)?(?:disse|fala|respondeu)\s+j[√¢a]nio\b.*$')
MSG_HEADER = re.compile(r'(?i)^\s*\**\s*mensagens? de j[√¢a]nio\s*\**\s*$')

def silenciar_janio(txt: str) -> str:
    if not txt:
        return txt
    out: List[str] = []
    in_msg_block = False
    for line in txt.splitlines():
        raw = line.strip()

        # Bloco "Mensagem de J√¢nio"
        if MSG_HEADER.match(raw):
            out.append('_Uma notifica√ß√£o de J√¢nio chega ao celular de Mary._')
            in_msg_block = True
            continue
        if in_msg_block:
            if not raw:   # linha vazia encerra o bloco
                in_msg_block = False
                continue
            if raw.startswith('‚Äî') or _is_quoted_or_bulleted(line):
                out.append('_[Conte√∫do de J√¢nio omitido]_')
                continue
            # qualquer outra linha dentro do bloco √© omitida
            out.append('_[Conte√∫do de J√¢nio omitido]_')
            continue

        # Linha direta "J√¢nio: ..." ou cita√ß√£o atribu√≠da a J√¢nio
        if JANIO_SPEECH.match(line) or JANIO_ATTR_QUOTE.match(line):
            out.append('_[Conte√∫do de J√¢nio omitido]_')
            continue

        # Men√ß√µes a J√¢nio (presen√ßa/a√ß√£o) passam normalmente
        out.append(line)
    return "\n".join(out)

# --------- Filtro extra: impedir fala pelo usu√°rio ---------
def silenciar_fala_do_usuario(txt: str) -> str:
    uname = (st.session_state.get("user_name") or "").strip()
    pats: List[re.Pattern] = []
    if uname:
        pats.append(re.compile(rf"(?im)^\s*{re.escape(uname)}\s*:\s*.*$"))
        pats.append(re.compile(rf"(?im)^.*‚Äî\s*[\"‚Äú].*[\"‚Äù]\s*‚Äî\s*(?:disse|fala|respondeu)\s+{re.escape(uname)}\b.*$"))
    pats.append(re.compile(r"(?im)^\s*(?:voc√™|voce|usu√°rio|usuario)\s*:\s*.*$"))
    out: List[str] = []
    for line in txt.splitlines():
        if any(p.match(line) for p in pats):
            out.append("_[A fala do usu√°rio √© escrita pelo pr√≥prio usu√°rio.]_")
            continue
        out.append(line)
    return "\n".join(out)

# Combina filtros (ordem importa)
def apply_filters(txt: str) -> str:
    return silenciar_fala_do_usuario(silenciar_janio(txt))

# =================================================================================
# Config Planilha
# =================================================================================
PLANILHA_ID = (
    st.secrets.get("JM_SHEET_ID")
    or st.secrets.get("SPREADSHEET_ID")
    or "1f7LBJFlhJvg3NGIWwpLTmJXxH9TH-MNn3F4SQkyfZNM"
).strip()
TAB_INTERACOES = "interacoes_jm"

# =================================================================================#
# Modelos (mantidos como no app original do Janio)
# =================================================================================
MODELOS_OPENROUTER = {
    "üí¨ DeepSeek V3 ‚òÖ‚òÖ‚òÖ‚òÖ ($)": "deepseek/deepseek-chat-v3-0324",
    "üß† DeepSeek R1 0528 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$)": "deepseek/deepseek-r1-0528",
    "üß† DeepSeek R1T2 Chimera ‚òÖ‚òÖ‚òÖ‚òÖ (free)": "tngtech/deepseek-r1t2-chimera:free",
    "üß† GPT-4.1 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (1M ctx)": "openai/gpt-4.1",
    "‚ö° Google Gemini 2.5 Pro": "google/gemini-2.5-pro",
    "üëë WizardLM 8x22B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ ($$$)": "microsoft/wizardlm-2-8x22b",
    "üëë Qwen 235B 2507 ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (PAID)": "qwen/qwen3-235b-a22b-07-25",
    "üëë EVA Qwen2.5 72B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-qwen-2.5-72b",
    "üëë EVA Llama 3.33 70B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (RP Pro)": "eva-unit-01/eva-llama-3.33-70b",
    "üé≠ Nous Hermes 2 Yi 34B ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ": "nousresearch/nous-hermes-2-yi-34b",
    "üî• MythoMax 13B ‚òÖ‚òÖ‚òÖ‚òÜ ($)": "gryphe/mythomax-l2-13b",
    "üíã LLaMA3 Lumimaid 8B ‚òÖ‚òÖ‚òÜ ($)": "neversleep/llama-3-lumimaid-8b",
    "üåπ Midnight Rose 70B ‚òÖ‚òÖ‚òÖ‚òÜ": "sophosympatheia/midnight-rose-70b",
    "üå∂Ô∏è Noromaid 20B ‚òÖ‚òÖ‚òÜ": "neversleep/noromaid-20b",
    "üíÄ Mythalion 13B ‚òÖ‚òÖ‚òÜ": "pygmalionai/mythalion-13b",
    "üêâ Anubis 70B ‚òÖ‚òÖ‚òÜ": "thedrummer/anubis-70b-v1.1",
    "üßö Rocinante 12B ‚òÖ‚òÖ‚òÜ": "thedrummer/rocinante-12b",
    "üç∑ Magnum v2 72B ‚òÖ‚òÖ‚òÜ": "anthracite-org/magnum-v2-72b",
}

MODELOS_TOGETHER_UI = {
    "üß† Qwen3 Coder 480B (Together)": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "üß† meta-llama/Meta-Llama-3.B (Together)": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    "üß† Qwen2.5-VL (72B) Instruct (Together)": "Qwen/Qwen2.5-VL-72B-Instruct",
    "üëë Mixtral 8x7B v0.1 (Together)": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "üëë Perplexity R1-1776 (Together)": "perplexity-ai/r1-1776",
    "üëë DeepSeek R1-0528 (Together)": "deepseek-ai/DeepSeek-R1",
}

MODELOS_HF = {
    "Llama 3.1 8B Instruct (HF)": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "meituan-longcat": "meituan-longcat/LongCat-Flash-Chat",
    "Qwen2.5 7B Instruct (HF)": "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "zai-org: GLM-4.5-Air (HF)": "zai-org/GLM-4.5-Air",
    "Mixtral 8x7B Instruct (HF)": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "DeepSeek R1 (HF)": "deepseek-ai/DeepSeek-R1",
}

# LM Studio (padr√£o: base local; pode ser editado no sidebar)
DEFAULT_LMS_BASE_URL = (
    st.secrets.get("LMS_BASE_URL") or "http://127.0.0.1:1234/v1"
).rstrip("/")

@st.cache_data(ttl=15, show_spinner=False)
def _lms_models_dict(base_url: str) -> Dict[str, str]:
    try:
        r = requests.get(f"{base_url}/models", timeout=8)
        r.raise_for_status()
        data = r.json()
        return {f"{m['id']} (LM Studio)": m["id"] for m in data.get("data", []) if m.get("id")}
    except Exception:
        return {"<digite manualmente> (LM Studio)": "llama-3.1-8b-instruct"}

PERSONA_VITTA_PRIVE = """[BORDEL DE LUXO: VITTA PRIV√â]
O Vitta Priv√© √© um espa√ßo sofisticado em Vit√≥ria, com ambientes climatizados, decora√ß√£o refinada, espumantes e trilha sonora sensual. Cinco acompanhantes de alto padr√£o atendem com discri√ß√£o e profissionalismo, cada uma com estilo e especialidade √∫nica.
1) **Bianca Torres**
‚Äî Apar√™ncia: Morena alta (1,74m), corpo atl√©tico de academia, bunda empinada, pernas torneadas, seios m√©dios. Olhar marcante, cabelos pretos lisos.
‚Äî Especialidade: Fetiche com domina√ß√£o suave, massagens sensuais com √≥leos quentes, shows de pole dance.
‚Äî Temperamento: Dominadora sutil, segura, encanta pela presen√ßa forte e senso de humor malicioso.
‚Äî O que realiza: Sexo convencional, oral profundo (DT), invers√£o de pap√©is (light BDSM), banho a dois e experi√™ncias a tr√™s.
2) **Sabrina Gold**
‚Äî Apar√™ncia: Loira dos olhos verdes, pele clara, curvas acentuadas, seios fartos, cintura fina. Visual voluptuoso de capa de revista.
‚Äî Especialidade: Strip tease e dan√ßas burlescas, jogos er√≥ticos, sexo oral demorado, deep kissing.
‚Äî Temperamento: Extrovertida, afetiva, mestre em provocar e seduzir, sempre l√™ os desejos do cliente.
‚Äî O que realiza: Beijos de l√≠ngua intensos, pompoarismo, DP (se convidada), anal, banheira de hidromassagem.
3) **L√≠via Rangel**
‚Äî Apar√™ncia: Morena clara, tra√ßos ind√≠genas delicados, cabelos castanho-escuros, l√°bios carnudos, pouco busto, barriga chapada, tatuagens escondidas pelo corpo.
‚Äî Especialidade: Atendimentos de GFE (Girlfriend Experience), longos carinhos, conversas inteligentes, experi√™ncias sensoriais (venda, gelo, chocolate).
‚Äî Temperamento: Carinhosa, reservada, boa ouvinte e envolvente. Faz o cliente se sentir √∫nico.
‚Äî O que realiza: Sexo afetivo, simula romance, car√≠cias prolongadas, beijos na boca, oral cuidadoso, masturba√ß√£o m√∫tua.
4) **Ashley Machado**
‚Äî Apar√™ncia: Negra, pele reluzente, cabelos tran√ßados longos, corpo viol√£o, coxas grossas, olhos grandes e brilhantes, sorriso contagiante.
‚Äî Especialidade: Posi√ß√µes acrob√°ticas, resist√™ncia para longas sess√µes, sex massage, squirt.
‚Äî Temperamento: Energ√©tica, criativa, divertida, coloca o cliente para experimentar novidades, topa desafios e pedidos ex√≥ticos.
‚Äî O que realiza: S√£o permitidas quase todas as pr√°ticas seguras, inclusive sexo grupal, danceteria privativa, banhos de banheira.
5) **Paola Ferrari**
‚Äî Apar√™ncia: Ruiva natural, pele de porcelana, sardas discretas, busto m√©dio e firme, quadris largos, altura mediana, unhas feitas, perfume marcante.
‚Äî Especialidade: Fetiche com p√©s (podolatria), domina√ß√£o delicada (soft femdom), sexo oral caprichado, massagem t√¢ntrica.
‚Äî Temperamento: Discreta, sensual, olhar misterioso, cria conex√£o psicol√≥gica, controla clima e ritmo, fala pouco durante o ato.
‚Äî O que realiza: Pr√°ticas sensoriais, sexo t√¢ntrico, podolatria, facesitting, golden/shower (se negociado), bondage leve.
Ambiente sempre limpo, m√∫sica baixa, privacidade total. Todas se testam regularmente, oferecem bebidas, conversam se o cliente desejar, e prezam pelo sigilo absoluto.

[CONTINUIDADE E A√á√ïES]
‚Äî Nunca ofere√ßa op√ß√µes de menu, listas de escolhas ou alternativas enumeradas ao usu√°rio.
‚Äî Mantenha coer√™ncia absoluta com o que j√° aconteceu: n√£o reinicie intera√ß√µes encerradas, nem repita oportunidades que Mary ou o usu√°rio j√° encerraram ou decidiram.
‚Äî Se uma personagem saiu da cena, ela deixa de interagir at√© que outra a√ß√£o expl√≠cita do usu√°rio provoque seu retorno.
‚Äî N√£o crie nem sugira decis√µes para o usu√°rio; apenas avance a narrativa a partir do que est√° no hist√≥rico.

[REGRAS DE REALISMO]
‚Äî Sem onisci√™ncia: ningu√©m sabe o que n√£o foi dito, visto ou lembrado no hist√≥rico.
‚Äî Conhecimento plaus√≠vel s√≥ por: di√°logo expl√≠cito, pistas observ√°veis ou algo j√° estabelecido.
‚Äî Sem atalhos milagrosos: nada de ‚Äúresolveu em 5 minutos‚Äù ou trocas instant√¢neas sob press√£o.
‚Äî Conflitos evoluem em degraus: tens√£o > rea√ß√£o > consequ√™ncia.
‚Äî Mary mant√©m limites e seguran√ßa: recusa grosseria; busca apoio do ambiente quando preciso.
‚Äî Consist√™ncia temporal: propostas para mais tarde permanecem propostas at√© marcador expl√≠cito.
‚Äî Convite ‚â† presen√ßa: encontros s√≥ viram evento ap√≥s aceita√ß√£o e transi√ß√£o clara.
‚Äî Contatos (insta/telefone) exigem gesto plaus√≠vel (troca combinada, QR, anota√ß√£o).


[NARRA√á√ÉO EM 3¬™ PESSOA ‚Äî TOM SUTILMENTE SENSUAL]
‚Äî Utilize a terceira pessoa para narrar todas as a√ß√µes, falas e pensamentos, com sensualidade elegante, nunca vulgar.
‚Äî Recorra sempre a um detalhe f√≠sico marcante de cada garota por par√°grafo, escolhendo entre seus dotes listados (corpo, pele, cabelo, curvas, perfume...).
‚Äî N√£o cite movimento de luz, tecido, clima ou decora√ß√£o do bordel, exceto quando for essencial para a sensualidade da cena.
‚Äî Evite listas; foque em pequenos detalhes corporais, trocas de olhares, tens√µes sensoriais e emo√ß√µes despertadas.
‚Äî Traga √† tona rea√ß√µes e o efeito que o cliente exerce sobre cada garota, ou sobre o ambiente do bordel, de forma subjetiva.
‚Äî M√°x. um detalhe f√≠sico e um elemento emocional por par√°grafo, priorize concis√£o e impacto sensual.

[NARRA√á√ÉO ‚Äî SENSORIAL FEMININO]
‚Äî Ao descrever as garotas, d√™ destaque para texturas, cheiro, calor do toque, vibra√ß√£o do corpo, voz, suor, respira√ß√£o, express√£o, mencionando sempre um atributo √∫nico de cada acompanhante por par√°grafo.
‚Äî Evite repeti√ß√µes de atributos e n√£o trate todas igualmente: varia√ß√£o gera riqueza.
‚Äî Atenha-se a impress√µes sensoriais, jamais a descri√ß√µes frias ou t√©cnicas.

[CONDU√á√ÉO PELO CLIENTE]
‚Äî O cliente conduz os rumos da cena; as garotas reagem de acordo, jamais tomam controle total da decis√£o.
‚Äî Nunca coloque falas ou desejos na boca do cliente; apenas reaja ao que ele transcrever ou insinuar.
‚Äî Rea√ß√µes das garotas podem ser proativas no flerte, mas esperam sempre o consentimento, o limite e o ritmo do cliente.
‚Äî Se o cliente escolher mais de uma garota, descreva a intera√ß√£o de cada uma segundo seu temperamento, especialidade e diferencial.

[PROGRESS√ÉO DE INTIMIDADE ‚Äî BORDEL]
‚Äî O clima evolui de aproxima√ß√£o e flerte, para toques, massagens, beijos, car√≠cias e sexo expl√≠cito, conforme os servi√ßos, desejos e limites do cliente.
‚Äî Detalhe passagens de tempo e mudan√ßa de ambiente (‚Äúnoutra sala privativa...‚Äù, ‚Äúj√° na banheira com espumante...‚Äù) marcando sempre a transi√ß√£o.
‚Äî N√£o h√° fade-to-black: descreva os atos sexuais, posi√ß√µes e experi√™ncias sensuais graficamente, respeitando o limite do cliente.

[ESTILO DE RESPOSTA ‚Äî BORDEL]
‚Äî Redobre a concis√£o: at√© 4 par√°grafos por resposta, 1 ou 2 frases por par√°grafo, riqueza sensorial, m√°xima objetividade.
‚Äî Foque sempre na a√ß√£o relevante, no detalhe singular, e na resposta emocional e corporal das garotas ao contexto ou cliente.

[CONTINUIDADE E CEN√ÅRIOS]
‚Äî Mantenha sempre no sum√°rio e no prompt, a indica√ß√£o das garotas presentes no quarto/sala, seus nomes e o cen√°rio (‚Äúainda no quarto do bordel‚Äù, ‚Äúna jacuzzi privativa‚Äù).
‚Äî Mudan√ßas de ambiente ou entrada/sa√≠da de garotas s√£o narradas explicitamente, com marca de transi√ß√£o (‚Äúquando Bianca deixou o quarto, Sabrina ocupou seu lugar junto ao cliente‚Ä¶‚Äù).
‚Äî N√£o permitir que detalhes de cen√°rio ou presen√ßa de personagens se ‚Äúpercam‚Äù durante o roleplay: retome-os no in√≠cio de cada bloco sensorial.
"""
# =================================================================================
# Conector Google Sheets (apenas interacoes_jm)
# =================================================================================

# =================================================================================
# Conector Google Sheets (apenas interacoes_jm)
# =================================================================================
def _load_google_creds_dict() -> dict:
    raw = st.secrets.get("GOOGLE_CREDS_JSON")
    if raw is None:
        raise RuntimeError("Faltando GOOGLE_CREDS_JSON no secrets.")
    creds = json.loads(raw) if isinstance(raw, str) else dict(raw)
    if isinstance(creds.get("private_key"), str):
        creds["private_key"] = creds["private_key"].replace("\\n", "\n")
    return creds

@st.cache_resource(show_spinner=False)
def _open_ws_interacoes():
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive",
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(_load_google_creds_dict(), scope)
    gc = gspread.authorize(creds)
    sh = gc.open_by_key(PLANILHA_ID)
    return sh.worksheet(TAB_INTERACOES)

try:
    WS_INTERACOES = _open_ws_interacoes()
except Exception as e:
    WS_INTERACOES = None
    st.error(f"N√£o foi poss√≠vel abrir a aba '{TAB_INTERACOES}'. Verifique permiss√µes/ID. Detalhe: {e}")

def salvar_interacao(ts: str, session_id: str, provider: str, model: str, role: str, content: str):
    if not WS_INTERACOES:
        return
    try:
        WS_INTERACOES.append_row(
            [ts, session_id, provider, model, role, content],
            value_input_option="USER_ENTERED"
        )
    except (APIError, GSpreadException) as e:
        st.warning(f"Falha ao salvar intera√ß√£o: {e}")

# =================================================================================
# Carregamento de hist√≥rico persistente (√∫ltimas intera√ß√µes)
# =================================================================================

from typing import Tuple

def carregar_ultimas_interacoes(n_min: int = 5) -> list[dict]:
    """Carrega ao menos n_min intera√ß√µes da √∫ltima sess√£o registrada na aba interacoes_jm.
    Retorna uma lista de mensagens no formato [{"role": "user|assistant", "content": str}, ...].
    Limita implicitamente a 30 ao aplicar na tela."""
    if not WS_INTERACOES:
        return []
    try:
        valores = WS_INTERACOES.get_all_values()  # [[timestamp, session_id, provider, model, role, content], ...]
        if not valores or len(valores) < 2:
            return []
        linhas = [r for r in valores[1:] if len(r) >= 6]
        if not linhas:
            return []
        # Usa a √∫ltima session_id registrada na planilha
        last_sid = linhas[-1][1].strip()
        sess = [r for r in linhas if r[1].strip() == last_sid and r[4] in ("user", "assistant")]
        if not sess:
            return []
        recortes = sess[-max(n_min, 1):]
        chat = [{"role": r[4].strip(), "content": (r[5] or "").strip()} for r in recortes]
        return chat
    except Exception:
        return []

def resumir_chat(chat_msgs: list[dict], call_model_func, model_id: str) -> str:
    """
    Usa o modelo LLM para gerar um resumo robusto das mensagens antigas, preservando cen√°rio e contexto.
    """
    texto = "\n".join(
        f"[{m['role']}]: {m['content']}"
        for m in chat_msgs if m['role'] in ('user', 'assistant') and m['content'].strip()
    )
    prompt = (
        "Resuma o di√°logo abaixo destacando sempre: 1) o local/situa√ß√£o atual dos personagens, "
        "2) mudan√ßas de ambiente ou cen√°rio (se ocorreram), 3) estado emocional predominante, "
        "e 4) decis√µes ou fatos relevantes para o desenvolvimento da hist√≥ria. "
        "Seja breve e preserve o tom do roleplay. Se houve sa√≠da do motel, viagem, chegada a outro lugar, cite explicitamente.\n\n"
        + texto
    )
    resumo = call_model_func(model_id, [{"role": "user", "content": prompt}])
    return resumo.strip()



# =============================================================================
# Build minimal messages (override) ‚Äî injeta nome do usu√°rio, cen√°rio e enredo
# =============================================================================
def build_minimal_messages(chat: List[Dict[str, str]]) -> List[Dict[str, str]]:
    # 1) Ler inputs da UI
    user_name = (st.session_state.get("user_name") or "").strip()
    scenario  = (st.session_state.get("scenario_init") or "").strip()
    plot      = (st.session_state.get("plot_init") or "").strip()
    fala_mods = st.session_state.get("fala_mods") or []
    # 2) Sanitiza√ß√£o leve + limite de tamanho (evita system gigante)
    def _clean(s: str, maxlen: int = 1200) -> str:
        s = re.sub(r"\s+", " ", s).strip()
        return s[:maxlen]
    user_name = _clean(user_name, 80)
    scenario  = _clean(scenario, 1000)
    plot      = _clean(plot, 1000)
    # 3) Parts extras
    extra_parts = []
    if user_name:
        extra_parts.append(f"[USU√ÅRIO]\n‚Äî Nome a ser reconhecido pelo personagem: {user_name}.")
    if scenario or plot:
        extra_parts.append("[CEN√ÅRIO/ENREDO INICIAL]")
        if scenario:
            extra_parts.append(f"‚Äî Cen√°rio: {scenario}")
        if plot:
            extra_parts.append(f"‚Äî Enredo: {plot}")
    fala_block = build_fala_block(fala_mods)
    if fala_block:
        extra_parts.append(fala_block)
    # 4) Monta system final
    system_text = PERSONA_VITTA_PRIVE
    if extra_parts:
        system_text += "\n\n" + "\n".join(extra_parts)
    # 5) Sumariza√ß√£o autom√°tica do hist√≥rico extenso
    HIST_THRESHOLD = 10  # limite m√°ximo de mensagens detalhadas no hist√≥rico
    mensagens_chat = [m for m in chat if m.get("role") in ("user", "assistant")]
    if len(mensagens_chat) > HIST_THRESHOLD:
        qtd_resumir = len(mensagens_chat) - HIST_THRESHOLD + 1
        parte_antiga = mensagens_chat[:qtd_resumir]
        parte_recente = mensagens_chat[qtd_resumir:]
        prov = st.session_state.get("prov")
        model_id = st.session_state.get("model_id")
        if prov == "OpenRouter":
            resumo = resumir_chat(parte_antiga, call_openrouter, model_id)
        elif prov == "Together":
            resumo = resumir_chat(parte_antiga, call_together, model_id)
        elif prov == "Hugging Face":
            resumo = resumir_chat(parte_antiga, call_huggingface, model_id)
        else:
            # Ajuste aqui: passa base_url pelo lambda
            base_url = st.session_state.get("lms_base_url") or DEFAULT_LMS_BASE_URL
            resumo = resumir_chat(
                parte_antiga,
                lambda model, messages: call_lmstudio(base_url, model, messages),
                model_id
            )
        chat_resumido = [{"role": "user", "content": f"Resumo da hist√≥ria at√© aqui: {resumo}"}] + parte_recente
    else:
        chat_resumido = mensagens_chat
    # 6) Constr√≥i mensagens m√≠nimas finais
    msgs: List[Dict[str, str]] = [{"role": "system", "content": system_text}]
    for m in chat_resumido:
        role = (m.get("role") or "").strip()
        if role == "system":
            continue
        content = (m.get("content") or "").strip()
        if content:
            msgs.append({"role": role, "content": content})
    return msgs

# =================================================================================
# Chamadas por provedor ‚Äî sem par√¢metros extras
# =================================================================================

def call_openrouter(model: str, messages: List[Dict[str, str]]) -> str:
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {st.secrets.get('OPENROUTER_API_KEY', '')}",
        "Content-Type": "application/json",
        "HTTP-Referer": st.secrets.get("APP_URL", ""),
        "X-Title": st.secrets.get("APP_TITLE", "Narrador JM"),
    }
    payload = {"model": model, "messages": messages, "max_tokens": 680}
    r = requests.post(url, headers=headers, json=payload, timeout=120)
    r.raise_for_status()
    data = r.json()
    return data["choices"][0]["message"]["content"].strip()

def call_together(model: str, messages: List[Dict[str, str]]) -> str:
    url = "https://api.together.xyz/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {st.secrets.get('TOGETHER_API_KEY', '')}",
        "Content-Type": "application/json"
    }
    payload = {"model": model, "messages": messages, "max_tokens": 680}
    try:
        r = requests.post(url, headers=headers, json=payload, timeout=120)
        r.raise_for_status()  # Levanta erro para status != 2xx
        data = r.json()
        return data["choices"][0]["message"]["content"].strip()
    except requests.HTTPError as http_err:
        msg = f"Erro HTTP Together: {r.status_code} - {r.text}"
        print(msg)  # Ou log para depura√ß√£o
        return f"[Erro Together: {r.status_code}] {r.text}"
    except Exception as e:
        return f"[Erro ao chamar Together: {e}]"


def call_lmstudio(base_url: str, model: str, messages: List[Dict[str, str]]) -> str:
    url = f"{base_url.rstrip('/')}/chat/completions"
    headers = {"Content-Type": "application/json"}
    payload = {"model": model, "messages": messages, "max_tokens": 680}
    r = requests.post(url, headers=headers, json=payload, timeout=120)
    r.raise_for_status()
    data = r.json()
    return data["choices"][0]["message"]["content"].strip()


from huggingface_hub import InferenceClient

def call_huggingface(model: str, messages: List[Dict[str, str]]) -> str:
    client = InferenceClient(api_key=st.secrets.get("HUGGINGFACE_API_KEY", ""))
    # Modelos preferencialmente "chat", adapte a lista conforme surgirem novos modelos
    CHAT_COMPLETION_MODELS = [
        "deepseek-ai/DeepSeek-R1",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "Qwen/Qwen2.5-7B-Instruct-1M",
        "zai-org/GLM-4.5-Air",
        # Adicione outros se testar e garantir que s√£o chat-completion
    ]
    try:
        if model in CHAT_COMPLETION_MODELS:
            response = client.chat_completion(model=model, messages=messages)
            return response.choices[0].message.content.strip()
        else:
            prompt = "\n".join(
                f"[{m['role'].upper()}]\n{m['content']}\n" for m in messages
                if m.get("content")
            )
            text = client.text_generation(model=model, prompt=prompt, max_new_tokens=512)
            return text
    except Exception as e:
        return f"[Erro ao chamar o modelo Hugging Face: {e}]"

# =================================================================================
# Streaming helpers ‚Äî envia em peda√ßos para a UI
# =================================================================================

import time

def _sse_stream(url: str, headers: Dict[str, str], payload: Dict[str, Any]):
    """Itera eventos SSE de /chat/completions com stream=True e retorna trechos de texto."""
    payload_stream = dict(payload)
    payload_stream["stream"] = True
    with requests.post(url, headers=headers, json=payload_stream, stream=True, timeout=300) as r:
        r.raise_for_status()
        for raw in r.iter_lines(decode_unicode=False):
            if not raw:
                continue
            line = raw.decode("utf-8", errors="ignore").strip()
            if not line.startswith("data:"):
                continue
            data = line[5:].strip()
            if data == "[DONE]":
                break
            try:
                j = json.loads(data)
                ch = j.get("choices", [{}])[0]
                delta = (ch.get("delta") or {}).get("content") or (ch.get("message") or {}).get("content")
                if delta:
                    yield delta
            except Exception:
                continue

def stream_openrouter(model: str, messages: List[Dict[str, str]]):
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {st.secrets.get('OPENROUTER_API_KEY', '')}",
        "Content-Type": "application/json",
        "HTTP-Referer": st.secrets.get("APP_URL", ""),
        "X-Title": st.secrets.get("APP_TITLE", "Narrador JM"),
    }
    payload = {"model": model, "messages": messages, "max_tokens": 680}
    yield from _sse_stream(url, headers, payload)

def stream_together(model: str, messages: List[Dict[str, str]]):
    url = "https://api.together.xyz/v1/chat/completions"
    headers = {"Authorization": f"Bearer {st.secrets.get('TOGETHER_API_KEY', '')}", "Content-Type": "application/json"}
    payload = {"model": model, "messages": messages, "max_tokens": 680}
    yield from _sse_stream(url, headers, payload)

def stream_lmstudio(base_url: str, model: str, messages: List[Dict[str, str]]):
    url = f"{base_url.rstrip('/')}/chat/completions"
    headers = {"Content-Type": "application/json"}
    payload = {"model": model, "messages": messages, "max_tokens": 680}
    yield from _sse_stream(url, headers, payload)

def _chunker(txt: str, n: int = 48):
    """Quebra texto em peda√ßos de ~n caracteres, respeitando espa√ßos quando poss√≠vel."""
    buf = []
    cur = 0
    while cur < len(txt):
        end = min(len(txt), cur + n)
        slice_ = txt[cur:end]
        if end < len(txt) and " " in slice_:
            last_sp = slice_.rfind(" ")
            if last_sp > 0:
                end = cur + last_sp + 1
                slice_ = txt[cur:end]
        buf.append(slice_)
        cur = end
    return buf

def stream_huggingface(model: str, messages: List[Dict[str, str]]):
    """HF Inference API nem sempre fornece SSE; simulamos streaming dividindo o texto."""
    full = call_huggingface(model, messages)
    for piece in _chunker(full, 48):
        yield piece
        time.sleep(0.02)  # leve suaviza√ß√£o visual

# =================================================================================
# UI
# =================================================================================
if "session_id" not in st.session_state:
    st.session_state.session_id = datetime.now().strftime("%Y%m%d-%H%M%S")
if "chat" not in st.session_state:
    st.session_state.chat: List[Dict[str, str]] = []
    # üîÅ Carrega as 5 √∫ltimas intera√ß√µes salvas da sess√£o anterior (se houver)
    try:
        _loaded = carregar_ultimas_interacoes(5)
        if _loaded:
            st.session_state.chat = _loaded[-30:]
    except Exception:
        pass

st.title("Narrador JM ‚Äî Clean Messages üé¨")

with st.sidebar:
    prov = st.radio("üåê Provedor", ["OpenRouter", "Together", "LM Studio", "Hugging Face"], index=0)
    st.session_state["prov"] = prov  # <-- ADICIONE ESTA LINHA
    if prov == "OpenRouter":
        modelo = st.selectbox("Modelo (OpenRouter)", list(MODELOS_OPENROUTER.keys()), index=0)
        model_id = MODELOS_OPENROUTER[modelo]
    elif prov == "Together":
        modelo = st.selectbox("Modelo (Together)", list(MODELOS_TOGETHER_UI.keys()), index=0)
        model_id = MODELOS_TOGETHER_UI[modelo]
    elif prov == "Hugging Face":
        modelo = st.selectbox("Modelo (HF)", list(MODELOS_HF.keys()), index=0)
        model_id = MODELOS_HF[modelo]
    else:
        base = st.text_input("LM Studio base URL", value=DEFAULT_LMS_BASE_URL)
        st.session_state.setdefault("lms_base_url", base)
        st.session_state.lms_base_url = base or DEFAULT_LMS_BASE_URL
        lms_models = _lms_models_dict(st.session_state.lms_base_url)
        modelo = st.selectbox("Modelo (LM Studio)", list(lms_models.keys()), index=0)
        model_id = lms_models[modelo]
    st.session_state["model_id"] = model_id  # <-- ADICIONE ESTA LINHA

    
    

    if st.button("üóëÔ∏è Resetar chat"):
        st.session_state.chat.clear()
        st.rerun()

# Render hist√≥rico
for m in st.session_state.chat:
    with st.chat_message(m["role"]).container():
        st.markdown(apply_filters(m["content"]))  # sem filtros extras

# Entrada
if user_msg := st.chat_input("Fale com a Mary..."):
    ts = datetime.now().isoformat(sep=" ", timespec="seconds")
    st.session_state.chat.append({"role": "user", "content": user_msg})
    # Mant√©m apenas as √∫ltimas 30 intera√ß√µes na tela
    if len(st.session_state.chat) > 30:
        st.session_state.chat = st.session_state.chat[-30:]
    salvar_interacao(ts, st.session_state.session_id, prov, model_id, "user", user_msg)

    messages = build_minimal_messages(st.session_state.chat)

    with st.chat_message("assistant"):
        ph = st.empty()
        answer = ""
        try:
            if prov == "OpenRouter":
                gen = stream_openrouter(model_id, messages)
            elif prov == "Together":
                gen = stream_together(model_id, messages)
            elif prov == "Hugging Face":
                gen = stream_huggingface(model_id, messages)
            else:
                gen = stream_lmstudio(st.session_state.lms_base_url, model_id, messages)

            for delta in gen:
                answer += delta
                # Mostra texto em tempo real j√° filtrado (J√¢nio + fala do usu√°rio)
                ph.markdown(apply_filters(answer) + "‚ñå")
        except Exception as e:
            answer = f"[Erro ao chamar o modelo: {e}]"
            ph.markdown(apply_filters(answer))

        # Render final (sem cursor), aplica filtros e o tom carinhoso se ativo
        _ans_clean = apply_filters(answer)
        _ans_clean = inject_carinhosa(
            _ans_clean,
            user_msg,
            ativo=("Carinhosa" in (st.session_state.get("fala_mods") or []))
        )
        ph.markdown(_ans_clean)

    # Salva exatamente essa vers√£o
    st.session_state.chat.append({"role": "assistant", "content": _ans_clean})
    if len(st.session_state.chat) > 30:
        st.session_state.chat = st.session_state.chat[-30:]
    ts2 = datetime.now().isoformat(sep=" ", timespec="seconds")
    salvar_interacao(ts2, st.session_state.session_id, prov, model_id, "assistant", _ans_clean)

    st.rerun()
















































